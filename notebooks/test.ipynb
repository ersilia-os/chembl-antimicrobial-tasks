{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0359bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89adaef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \".\"\n",
    "\n",
    "pathogen_code = \"mtuberculosis\"\n",
    "\n",
    "OUTPUT = os.path.join(root, \"..\", \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45aaff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_relation(ASSAY_DATA: pd.DataFrame, DIRECTION: int, CUT: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adjust relations in an assay DataFrame according to the biological direction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pd.DataFrame\n",
    "        Must contain the columns 'relation' and 'value'.\n",
    "    DIRECTION : int\n",
    "        +1 → higher = more active (e.g. % inhibition)\n",
    "        -1 → lower = more active (e.g. IC50, MIC)\n",
    "    CUT : float\n",
    "        Extreme value used to replace censored measurements\n",
    "        on the wrong side of the direction (min-1 or max+1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Copy of ASSAY_DATA with adjusted relation and value.\n",
    "    \"\"\"\n",
    "\n",
    "    df = ASSAY_DATA.copy()\n",
    "    rel = df[\"relation\"].astype(str)\n",
    "\n",
    "    if DIRECTION == +1:\n",
    "\n",
    "        # Higher = more active\n",
    "        mask_gt = rel == \">\"  # greater than\n",
    "        mask_lt = rel == \"<\"  # lower than\n",
    "\n",
    "        df.loc[mask_gt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_lt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_lt, \"value\"] = CUT\n",
    "\n",
    "    elif DIRECTION == -1:\n",
    "\n",
    "        # Lower = more active\n",
    "        mask_lt = rel == \"<\"  # lower than\n",
    "        mask_gt = rel == \">\"  # greater than\n",
    "\n",
    "        df.loc[mask_lt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_gt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_gt, \"value\"] = CUT\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise ValueError(f\"Invalid DIRECTION={DIRECTION}. Expected +1 or -1.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def disambiguate_compounds(ASSAY_DATA: pd.DataFrame, DIRECTION: int) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Select a single measurement per compound according to the biological direction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pd.DataFrame\n",
    "        Must contain the columns 'compound_chembl_id' and 'value'.\n",
    "        Assumes all relations have already been adjusted.\n",
    "    DIRECTION : int\n",
    "        +1 → higher = more active (e.g. % inhibition)\n",
    "        -1 → lower = more active (e.g. IC50, MIC)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A copy of ASSAY_DATA in which duplicated compounds \n",
    "        ('compound_chembl_id') are removed, keeping only the \n",
    "        most active measurement per compound (highest or lowest \n",
    "        depending on DIRECTION).\n",
    "    \"\"\"\n",
    "\n",
    "    if DIRECTION not in [1, -1]:\n",
    "        raise ValueError(\"DIRECTION must be +1 (higher = more active) or -1 (lower = more active).\")\n",
    "        \n",
    "    df = ASSAY_DATA.copy()\n",
    "\n",
    "    # Choose best measurement based on direction\n",
    "    if DIRECTION == -1:\n",
    "        # Lower = more active → keep minimum\n",
    "        df_sorted = df.sort_values(by=\"value\", ascending=True)\n",
    "    elif DIRECTION == 1:\n",
    "        # Higher = more active → keep maximum\n",
    "        df_sorted = df.sort_values(by=\"value\", ascending=False)\n",
    "\n",
    "    # Keep the best row per compound_chembl_id\n",
    "    df_best = df_sorted.drop_duplicates(subset=\"compound_chembl_id\", keep=\"first\")\n",
    "\n",
    "    return df_best.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33bc56a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned assays\n",
    "ASSAYS_CLEANED = pd.read_csv(os.path.join(root, \"..\", \"output\", pathogen_code, \"assays_cleaned.csv\"))\n",
    "\n",
    "# Define PATH to parameters\n",
    "PATH_TO_PARAMETERS = os.path.join(root, \"..\", \"output\", pathogen_code, 'parameters')\n",
    "\n",
    "ORGNISM_CURATED, TARGET_TYPE_CURATED, STRAIN = [], [], []\n",
    "ATCC_ID, MUTATIONS, KDR, MEDIA = [], [], [], []\n",
    "\n",
    "# Iterating over assays\n",
    "for assay_id, activity_type, unit in ASSAYS_CLEANED[['assay_id', 'activity_type', 'unit']].values:\n",
    "\n",
    "    # Prepare filename\n",
    "    filename = \"_\".join([str(assay_id), str(activity_type), str(unit), 'parameters']) + \".json\"\n",
    "    \n",
    "    # Read JSON file\n",
    "    with open(os.path.join(PATH_TO_PARAMETERS, filename), \"r\") as file:\n",
    "        par = json.load(file)\n",
    "\n",
    "    # Store results\n",
    "    ORGNISM_CURATED.append(par['organism'])\n",
    "    TARGET_TYPE_CURATED.append(par['target_type'])\n",
    "    STRAIN.append(par['strain'])\n",
    "    # ATCC_ID.append(par['atcc_id'])\n",
    "    MUTATIONS.append(\";\".join(par['mutations']))\n",
    "    KDR.append(\";\".join(par['known_drug_resistances']))\n",
    "    MEDIA.append(par['media'])\n",
    "\n",
    "# Complete table\n",
    "ASSAYS_CLEANED['organism_curated'] = ORGNISM_CURATED\n",
    "ASSAYS_CLEANED['target_type_curated'] = TARGET_TYPE_CURATED\n",
    "ASSAYS_CLEANED['strain'] = STRAIN\n",
    "# assays_cleaned['atcc_id'] = ATCC_ID\n",
    "ASSAYS_CLEANED['mutations'] = MUTATIONS\n",
    "ASSAYS_CLEANED['known_drug_resistances'] = KDR\n",
    "ASSAYS_CLEANED['media'] = MEDIA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23d9486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ChEMBL cleaned data for mtuberculosis...\n",
      "Number of activities for mtuberculosis: 702477\n",
      "Number of compounds for mtuberculosis: 131442\n",
      "Cleaned number of assays: 10521\n"
     ]
    }
   ],
   "source": [
    "# Loading pathogen data\n",
    "os.makedirs(os.path.join(OUTPUT, pathogen_code, 'datasets'), exist_ok=True)\n",
    "print(f\"Loading ChEMBL cleaned data for {pathogen_code}...\")\n",
    "ChEMBL_pathogen = pd.read_csv(os.path.join(OUTPUT, pathogen_code, f\"{pathogen_code}_ChEMBL_cleaned_data.csv.gz\"), low_memory=False)\n",
    "print(f\"Number of activities for {pathogen_code}: {len(ChEMBL_pathogen)}\")\n",
    "print(f\"Number of compounds for {pathogen_code}: {len(set(ChEMBL_pathogen['compound_chembl_id']))}\")\n",
    "print(f\"Cleaned number of assays: {len(ASSAYS_CLEANED)}\")\n",
    "\n",
    "# Load expert cut-offs\n",
    "EXPERT_CUTOFFS = pd.read_csv(os.path.join(root, \"..\", \"config\", \"manual_curation\", \"expert_cutoffs.csv\"))\n",
    "EXPERT_CUTOFFS = {\n",
    "    (a, b, c, d): e\n",
    "    for a, b, c, d, e in EXPERT_CUTOFFS[\n",
    "        [\"activity_type\", \"unit\", \"target_type\", \"pathogen_code\", \"expert_cutoff\"]\n",
    "    ].values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ab34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10521 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define data ranges\n",
    "DATA_RANGES = []\n",
    "\n",
    "for assay_chembl_id, activity_type, unit, target_type, target_type_curated, activities, cpds, direction in tqdm(ASSAYS_CLEANED[['assay_id', 'activity_type', 'unit', 'target_type',\n",
    "                                                                                                        'target_type_curated', 'activities', 'cpds', 'direction']].values):\n",
    "\n",
    "    # Loading assay data\n",
    "    cols = ['compound_chembl_id', 'canonical_smiles', 'activity_type', 'value', 'relation', 'unit', 'activity_comment', 'standard_text']\n",
    "    if type(unit) == str:\n",
    "        ASSAY_DATA = ChEMBL_pathogen[(ChEMBL_pathogen['assay_chembl_id'] == assay_chembl_id) & \n",
    "                                    (ChEMBL_pathogen['activity_type'] == activity_type) & \n",
    "                                    (ChEMBL_pathogen['unit'] == unit)].reset_index(drop=True)[cols]\n",
    "    else:\n",
    "        ASSAY_DATA = ChEMBL_pathogen[(ChEMBL_pathogen['assay_chembl_id'] == assay_chembl_id) & \n",
    "                                    (ChEMBL_pathogen['activity_type'] == activity_type) & \n",
    "                                    (ChEMBL_pathogen['unit'].isna())].reset_index(drop=True)[cols]\n",
    "    \n",
    "    # Counter relations\n",
    "    counter_relations = Counter(ASSAY_DATA['relation'].tolist())\n",
    "\n",
    "    # Get value to adjust relations\n",
    "    if direction == 1:\n",
    "        CUT = min(ASSAY_DATA['value'])\n",
    "    elif direction == -1:\n",
    "        CUT = max(ASSAY_DATA['value'])\n",
    "    else:\n",
    "        CUT = np.nan\n",
    "\n",
    "    # Get expert cut-off if exists\n",
    "    key = (activity_type, unit, target_type_curated, pathogen_code)\n",
    "    expert_cutoff = EXPERT_CUTOFFS[key] if key in EXPERT_CUTOFFS else np.nan\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb7fa779",
   "metadata": {},
   "outputs": [],
   "source": [
    "if direction in [+1, -1]:\n",
    "\n",
    "    # Adjust relation\n",
    "    ASSAY_DATA = adjust_relation(ASSAY_DATA, direction, CUT)\n",
    "\n",
    "    # Disambiguate duplicated compounds and returns 'sorted' data (depending on direction)\n",
    "    ASSAY_DATA = disambiguate_compounds(ASSAY_DATA, direction)\n",
    "\n",
    "    # Remove nans\n",
    "    assay_activities = [i for i in ASSAY_DATA['value'].tolist() if np.isnan(i) == False]\n",
    "\n",
    "    # Fully qualitative assay\n",
    "    if len(assay_activities) == 0:\n",
    "        assay_activities = [np.nan]\n",
    "        type_ = 'qualitative'\n",
    "    elif len(assay_activities) < len(ASSAY_DATA):\n",
    "        type_ = 'qualitative'\n",
    "    else:\n",
    "        type = 'quantitative'\n",
    "\n",
    "    # Binarization with expert cut-off\n",
    "    if np.isnan(expert_cutoff) == False:\n",
    "        if direction == +1:\n",
    "            ASSAY_DATA[\"bin\"] = (ASSAY_DATA[\"value\"] >= expert_cutoff).astype(int)\n",
    "        else:\n",
    "            ASSAY_DATA[\"bin\"] = (ASSAY_DATA[\"value\"] <= expert_cutoff).astype(int)\n",
    "        positives = Counter(ASSAY_DATA['bin'].tolist())[1]\n",
    "        ratio = round(positives / len(ASSAY_DATA), 5)\n",
    "    else:\n",
    "        # Dataset could not be binarized using values due to missing expert cut-off\n",
    "        ASSAY_DATA['bin'] = [np.nan] * len(ASSAY_DATA)\n",
    "        positives = np.nan\n",
    "        ratio = np.nan\n",
    "\n",
    "else:\n",
    "\n",
    "    # Qualitative assay\n",
    "    type_ = 'qualitative'    \n",
    "\n",
    "    # Not binarizing a null-direction assay\n",
    "    ASSAY_DATA['bin'] = [np.nan] * len(ASSAY_DATA)\n",
    "    positives = np.nan\n",
    "    ratio = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06fde140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate data\n",
    "min_ = round(np.min(assay_activities), 3)\n",
    "p1 = round(np.percentile(assay_activities, 1), 3)\n",
    "p25 = round(np.percentile(assay_activities, 25), 3)\n",
    "p50 = round(np.percentile(assay_activities, 50), 3)\n",
    "p75 = round(np.percentile(assay_activities, 75), 3)\n",
    "p99 = round(np.percentile(assay_activities, 99), 3)\n",
    "max_ = round(np.max(assay_activities), 3)\n",
    "\n",
    "# Relations\n",
    "equal = counter_relations[\"=\"]\n",
    "lower = counter_relations[\"<\"]\n",
    "higher = counter_relations[\">\"]\n",
    "\n",
    "# Store data range\n",
    "DATA_RANGES.append([assay_chembl_id, activity_type, unit, target_type, activities, cpds, direction, equal, higher, \n",
    "                    lower, min_, p1, p25, p50, p75, p99, max_, expert_cutoff, positives, ratio])\n",
    "\n",
    "# Save data\n",
    "if cpds > 100:\n",
    "    ASSAY_DATA.to_csv(os.path.join(OUTPUT, pathogen_code, 'datasets', f\"{assay_chembl_id}_{activity_type}_{str(unit).replace('/', 'FwdS')}.csv.gz\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2efe6873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CHEMBL4649948',\n",
       "  'PERCENTEFFECT',\n",
       "  '%',\n",
       "  'ORGANISM',\n",
       "  93555,\n",
       "  86589,\n",
       "  1.0,\n",
       "  93555,\n",
       "  0,\n",
       "  0,\n",
       "  -1122.89,\n",
       "  -39.791,\n",
       "  -10.3,\n",
       "  -1.066,\n",
       "  7.879,\n",
       "  58.95,\n",
       "  120.27,\n",
       "  50.0,\n",
       "  1268,\n",
       "  0.01464]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_RANGES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
