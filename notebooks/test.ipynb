{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03708bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ChEMBL cleaned data for abaumannii...\n",
      "Number of activities for abaumannii: 42839\n",
      "Number of compounds for abaumannii: 32458\n",
      "Number of cleaned assays: 3007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3007/3007 [00:29<00:00, 101.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def adjust_relation(ASSAY_DATA: pd.DataFrame, DIRECTION: int, CUT: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adjust relations in an assay DataFrame according to the biological direction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pd.DataFrame\n",
    "        Must contain the columns 'relation' and 'value'.\n",
    "    DIRECTION : int\n",
    "        +1 → higher = more active (e.g. % inhibition)\n",
    "        -1 → lower = more active (e.g. IC50, MIC)\n",
    "    CUT : float\n",
    "        Extreme value used to replace censored measurements\n",
    "        on the wrong side of the direction (min or max)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Copy of ASSAY_DATA with adjusted relation and value.\n",
    "    \"\"\"\n",
    "\n",
    "    df = ASSAY_DATA.copy()\n",
    "    rel = df[\"relation\"].astype(str)\n",
    "\n",
    "    if DIRECTION == +1:\n",
    "\n",
    "        # Higher = more active\n",
    "        mask_gt = rel == \">\"  # greater than\n",
    "        mask_lt = rel == \"<\"  # lower than\n",
    "\n",
    "        df.loc[mask_gt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_lt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_lt, \"value\"] = CUT\n",
    "\n",
    "    elif DIRECTION == -1:\n",
    "\n",
    "        # Lower = more active\n",
    "        mask_lt = rel == \"<\"  # lower than\n",
    "        mask_gt = rel == \">\"  # greater than\n",
    "\n",
    "        df.loc[mask_lt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_gt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_gt, \"value\"] = CUT\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise ValueError(f\"Invalid DIRECTION={DIRECTION}. Expected +1 or -1.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def disambiguate_compounds(ASSAY_DATA: pd.DataFrame, DIRECTION: int) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Select a single measurement per compound according to the biological direction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pd.DataFrame\n",
    "        Must contain the columns 'compound_chembl_id' and 'value'.\n",
    "        Assumes all relations have already been adjusted.\n",
    "    DIRECTION : int\n",
    "        +1 → higher = more active (e.g. % inhibition)\n",
    "        -1 → lower = more active (e.g. IC50, MIC)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A copy of ASSAY_DATA in which duplicated compounds \n",
    "        ('compound_chembl_id') are removed, keeping only the \n",
    "        most active measurement per compound (highest or lowest \n",
    "        depending on DIRECTION).\n",
    "    \"\"\"\n",
    "\n",
    "    if DIRECTION not in [1, -1]:\n",
    "        raise ValueError(\"DIRECTION must be +1 (higher = more active) or -1 (lower = more active).\")\n",
    "        \n",
    "    df = ASSAY_DATA.copy()\n",
    "\n",
    "    # Choose best measurement based on direction\n",
    "    if DIRECTION == -1:\n",
    "        # Lower = more active → keep minimum\n",
    "        df_sorted = df.sort_values(by=\"value\", ascending=True)\n",
    "    elif DIRECTION == 1:\n",
    "        # Higher = more active → keep maximum\n",
    "        df_sorted = df.sort_values(by=\"value\", ascending=False)\n",
    "\n",
    "    # Keep the best row per compound_chembl_id\n",
    "    df_best = df_sorted.drop_duplicates(subset=\"compound_chembl_id\", keep=\"first\")\n",
    "\n",
    "    return df_best.reset_index(drop=True)\n",
    "\n",
    "def get_pathogen_code(pathogen):\n",
    "    return str(pathogen.split()[0][0] + pathogen.split()[1]).lower() if len(pathogen.split()) > 1 else pathogen.lower()\n",
    "\n",
    "def add_target_type_curated(ASSAYS_CLEANED, PATH_TO_PARAMETERS):\n",
    "    \"\"\"\n",
    "    Add a `target_type_curated` column to ASSAYS_CLEANED by reading parameter JSON files.\n",
    "\n",
    "    For each row in ASSAYS_CLEANED, a JSON file is opened using the pattern:\n",
    "        \"{assay_id}_{activity_type}_{unit}_parameters.json\"\n",
    "\n",
    "    The value stored under the key `\"target_type_curated\"` is extracted and appended\n",
    "    to a list, which is then assigned as a new column in the dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAYS_CLEANED : pandas.DataFrame\n",
    "        DataFrame containing at least the columns: `assay_id`, `activity_type`, `unit`.\n",
    "    PATH_TO_PARAMETERS : str\n",
    "        Path to the directory containing the JSON parameter files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The same dataframe with an added `target_type_curated` column.\n",
    "    \"\"\"\n",
    "    TARGET_TYPE_CURATED = []\n",
    "\n",
    "    # Iterating over assays\n",
    "    for assay_id, activity_type, unit in ASSAYS_CLEANED[['assay_id', 'activity_type', 'unit']].values:\n",
    "\n",
    "        # Prepare filename\n",
    "        filename = \"_\".join([str(assay_id), str(activity_type), str(unit), 'parameters']) + \".json\"\n",
    "        \n",
    "        # Read JSON file\n",
    "        with open(os.path.join(PATH_TO_PARAMETERS, filename), \"r\") as file:\n",
    "            par = json.load(file)\n",
    "\n",
    "        # Store results\n",
    "        TARGET_TYPE_CURATED.append(par['target_type_curated'])\n",
    "\n",
    "    # Complete table\n",
    "    ASSAYS_CLEANED['target_type_curated'] = TARGET_TYPE_CURATED\n",
    "\n",
    "    return ASSAYS_CLEANED\n",
    "\n",
    "def load_expert_cutoffs(root):\n",
    "    \"\"\"\n",
    "    Load expert cutoffs from the manual curation CSV and return them as a dictionary.\n",
    "\n",
    "    The CSV is expected at:\n",
    "        {root}/../config/manual_curation/expert_cutoffs.csv\n",
    "\n",
    "    The returned dictionary maps:\n",
    "        (activity_type, unit, target_type, pathogen_code) -> expert_cutoff\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root : str\n",
    "        Base path used to locate the config folder.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary of expert cutoffs keyed by\n",
    "        (activity_type, unit, target_type, pathogen_code).\n",
    "    \"\"\"\n",
    "    # Load expert cut-offs\n",
    "    EXPERT_CUTOFFS = pd.read_csv(\n",
    "        os.path.join(root, \"..\", \"config\", \"manual_curation\", \"expert_cutoffs.csv\")\n",
    "    )\n",
    "\n",
    "    EXPERT_CUTOFFS = {\n",
    "        (a, b, c, d): e\n",
    "        for a, b, c, d, e in EXPERT_CUTOFFS[\n",
    "            [\"activity_type\", \"unit\", \"target_type\", \"pathogen_code\", \"expert_cutoff\"]\n",
    "        ].values\n",
    "    }\n",
    "\n",
    "    return EXPERT_CUTOFFS\n",
    "\n",
    "def get_assay_data(ChEMBL_pathogen, assay_chembl_id, activity_type, unit, cols):\n",
    "    \"\"\"\n",
    "    Extract assay activity data for a given assay_chembl_id, activity_type, and unit.\n",
    "\n",
    "    If `unit` is a string, the function filters rows where `unit` matches exactly.\n",
    "    Otherwise, it filters rows where `unit` is missing (NaN).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ChEMBL_pathogen : pandas.DataFrame\n",
    "        DataFrame containing ChEMBL pathogen activity records.\n",
    "    assay_chembl_id : str\n",
    "        Assay ChEMBL ID to filter on.\n",
    "    activity_type : str\n",
    "        Activity type to filter on (e.g., IC50, MIC).\n",
    "    unit : str or None\n",
    "        Unit to filter on; if not a string, NaN units are selected.\n",
    "    cols : list\n",
    "        List of columns to return.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Filtered assay activity data with only the requested columns.\n",
    "    \"\"\"\n",
    "    if type(unit) == str:\n",
    "        ASSAY_DATA = ChEMBL_pathogen[\n",
    "            (ChEMBL_pathogen['assay_chembl_id'] == assay_chembl_id) &\n",
    "            (ChEMBL_pathogen['activity_type'] == activity_type) &\n",
    "            (ChEMBL_pathogen['unit'] == unit)\n",
    "        ].reset_index(drop=True)[cols]\n",
    "    else:\n",
    "        ASSAY_DATA = ChEMBL_pathogen[\n",
    "            (ChEMBL_pathogen['assay_chembl_id'] == assay_chembl_id) &\n",
    "            (ChEMBL_pathogen['activity_type'] == activity_type) &\n",
    "            (ChEMBL_pathogen['unit'].isna())\n",
    "        ].reset_index(drop=True)[cols]\n",
    "\n",
    "    return ASSAY_DATA\n",
    "\n",
    "def get_cut_value(ASSAY_DATA, direction):\n",
    "    \"\"\"\n",
    "    Get a cutoff value from ASSAY_DATA to adjust relations based on direction.\n",
    "\n",
    "    If direction == 1, returns the minimum value in ASSAY_DATA['value'].\n",
    "    If direction == -1, returns the maximum value in ASSAY_DATA['value'].\n",
    "    Otherwise, returns np.nan.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pandas.DataFrame\n",
    "        DataFrame containing a 'value' column with numeric assay values.\n",
    "    direction : int\n",
    "        Direction indicator:\n",
    "        - 1  -> use minimum value\n",
    "        - -1 -> use maximum value\n",
    "        - else -> np.nan\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Cutoff value computed from the 'value' column or np.nan.\n",
    "    \"\"\"\n",
    "    if direction == 1:\n",
    "        CUT = min(ASSAY_DATA['value'])\n",
    "    elif direction == -1:\n",
    "        CUT = max(ASSAY_DATA['value'])\n",
    "    else:\n",
    "        CUT = np.nan\n",
    "\n",
    "    return CUT\n",
    "\n",
    "def count_relations(ASSAY_DATA):\n",
    "    \"\"\"\n",
    "    Count relation operators in ASSAY_DATA['relation'].\n",
    "\n",
    "    Counts how many times each of the following appears:\n",
    "        \"=\" , \"<\" , \">\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pandas.DataFrame\n",
    "        DataFrame containing a 'relation' column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (equal, lower, higher) counts corresponding to \"=\", \"<\", \">\".\n",
    "    \"\"\"\n",
    "    counter_relations = Counter(ASSAY_DATA['relation'].tolist())\n",
    "    equal = counter_relations[\"=\"]\n",
    "    lower = counter_relations[\"<\"]\n",
    "    higher = counter_relations[\">\"]\n",
    "\n",
    "    return equal, lower, higher\n",
    "\n",
    "def get_assay_data_quantitative(ASSAY_DATA):\n",
    "    \"\"\"\n",
    "    Return only rows in ASSAY_DATA with non-missing quantitative values.\n",
    "\n",
    "    Filters ASSAY_DATA to keep rows where `value` is not NaN, and resets the index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pandas.DataFrame\n",
    "        DataFrame containing a 'value' column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Filtered dataframe containing only rows with non-null `value`.\n",
    "    \"\"\"\n",
    "    ASSAY_DATA_QUANTITATIVE = ASSAY_DATA[ASSAY_DATA['value'].isna() == False].reset_index(drop=True)\n",
    "    return ASSAY_DATA_QUANTITATIVE\n",
    "\n",
    "def get_assay_data_qualitative(ASSAY_DATA):\n",
    "    \"\"\"\n",
    "    Generate qualitative labels for assay data based on `activity_comment` and `standard_text`.\n",
    "\n",
    "    This function:\n",
    "    - Detects row-level conflicts where a row is simultaneously positive (1) and negative (-1).\n",
    "    - Assigns a row-level qualitative label (1, -1, or 0).\n",
    "    - Aggregates labels at the compound level to ensure each compound has a single consistent label.\n",
    "    - Detects compound-level conflicts where the same compound is labeled both 1 and -1 across rows.\n",
    "    - Assigns a final compound-level label to all rows.\n",
    "    - Keeps only one row per compound.\n",
    "    - Removes compounds with final label 0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pandas.DataFrame\n",
    "        DataFrame containing at least:\n",
    "        - compound_chembl_id\n",
    "        - activity_comment\n",
    "        - standard_text\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Filtered dataframe with one row per compound and `qualitative_label` in {1, -1}.\n",
    "    \"\"\"\n",
    "    # Qualitative view\n",
    "    ASSAY_DATA = ASSAY_DATA.copy()\n",
    "    cond_nan = (ASSAY_DATA['activity_comment'] == 0) & (ASSAY_DATA['standard_text'] == 0)\n",
    "    cond_pos = (ASSAY_DATA['activity_comment'] == 1) | (ASSAY_DATA['standard_text'] == 1)\n",
    "    cond_neg = (ASSAY_DATA['activity_comment'] == -1) | (ASSAY_DATA['standard_text'] == -1)\n",
    "\n",
    "    # Detect row-level conflicts\n",
    "    conflict = cond_pos & cond_neg\n",
    "    if conflict.any():\n",
    "        raise ValueError(\n",
    "            \"Conflicting labels (contains both 1 and -1):\\n\"\n",
    "            + ASSAY_DATA.loc[conflict, [\"compound_chembl_id\", \"activity_comment\", \"standard_text\"]].head(20).to_string())\n",
    "\n",
    "    # Assign row-level label\n",
    "    ASSAY_DATA[\"qualitative_label_row\"] = np.nan\n",
    "    ASSAY_DATA.loc[cond_pos, \"qualitative_label_row\"] = 1\n",
    "    ASSAY_DATA.loc[cond_neg, \"qualitative_label_row\"] = -1\n",
    "    ASSAY_DATA.loc[cond_nan, \"qualitative_label_row\"] = 0\n",
    "\n",
    "    # Aggregate to compound-level label\n",
    "    compound_labels = ASSAY_DATA.groupby(\"compound_chembl_id\")[\"qualitative_label_row\"].apply(set)\n",
    "\n",
    "    # Detect compound-level conflicts (same compound has 1 and -1)\n",
    "    compound_ids = compound_labels.index.tolist()\n",
    "    label_sets = compound_labels.tolist()\n",
    "    compound_conflict = [((1 in s) and (-1 in s)) for s in label_sets]\n",
    "    if any(compound_conflict):\n",
    "        bad = [(cid, s) for cid, s, c in zip(compound_ids, label_sets, compound_conflict) if c][:20]\n",
    "        raise ValueError(\n",
    "            \"Conflicting compound labels (same compound has both 1 and -1 across rows):\\n\"\n",
    "            + \"\\n\".join([f\"{cid}: {s}\" for cid, s in bad]))\n",
    "\n",
    "    # Final compound label: 1 > -1 > 0\n",
    "    compound_final = [1 if 1 in s else (-1 if -1 in s else 0) for s in label_sets]\n",
    "    compound_final = dict(zip(compound_ids, compound_final))\n",
    "\n",
    "    # Assign back to all rows\n",
    "    ASSAY_DATA[\"qualitative_label\"] = ASSAY_DATA[\"compound_chembl_id\"].map(compound_final)\n",
    "\n",
    "    # Keep only one row per compound\n",
    "    ASSAY_DATA = ASSAY_DATA.drop_duplicates(subset=[\"compound_chembl_id\"]).reset_index(drop=True)\n",
    "\n",
    "    # Remove compounds labeled as 0\n",
    "    ASSAY_DATA = ASSAY_DATA[ASSAY_DATA[\"qualitative_label\"] != 0].reset_index(drop=True)\n",
    "\n",
    "    # Binary label\n",
    "    ASSAY_DATA[\"bin\"] = [0 if x == -1 else 1 for x in ASSAY_DATA[\"qualitative_label\"].tolist()]\n",
    "\n",
    "    # Take only interesting columns\n",
    "    cols = [\"compound_chembl_id\", \"canonical_smiles\", \"activity_type\", \"unit\", \"activity_comment\", \"standard_text\", \"qualitative_label\", 'bin'] \n",
    "    ASSAY_DATA = ASSAY_DATA[cols]\n",
    "\n",
    "    return ASSAY_DATA\n",
    "\n",
    "def set_variables_quantitative(ASSAY_DATA_QUANTITATIVE):\n",
    "    \"\"\"\n",
    "    Compute summary variables for quantitative assay data.\n",
    "\n",
    "    Returns number of positives, positive ratio, and number of compounds (rows).\n",
    "    If the dataframe is empty, returns np.nan for all values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA_QUANTITATIVE : pandas.DataFrame\n",
    "        DataFrame containing a 'bin' column (0/1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (positives_quantitative, ratio_quantitative, compounds_quantitative)\n",
    "    \"\"\"\n",
    "    if len(ASSAY_DATA_QUANTITATIVE) > 0:\n",
    "        positives_quantitative = (ASSAY_DATA_QUANTITATIVE[\"bin\"] == 1).sum()\n",
    "        ratio_quantitative = round(positives_quantitative / len(ASSAY_DATA_QUANTITATIVE), 3)\n",
    "        compounds_quantitative = len(ASSAY_DATA_QUANTITATIVE)\n",
    "        activities_quantitative = ASSAY_DATA_QUANTITATIVE['value'].tolist()\n",
    "    else:\n",
    "        positives_quantitative = np.nan\n",
    "        ratio_quantitative = np.nan\n",
    "        compounds_quantitative = np.nan\n",
    "        activities_quantitative = [np.nan]\n",
    "\n",
    "    return positives_quantitative, ratio_quantitative, compounds_quantitative, activities_quantitative\n",
    "\n",
    "def set_variables_qualitative(ASSAY_DATA_QUALITATIVE):\n",
    "    \"\"\"\n",
    "    Compute summary variables for qualitative assay data.\n",
    "\n",
    "    Returns number of positives, positive ratio, and number of compounds (rows).\n",
    "    If the dataframe is empty, returns np.nan for all values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA_QUALITATIVE : pandas.DataFrame\n",
    "        DataFrame containing a 'bin' column (0/1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (positives_qualitative, ratio_qualitative, compounds_qualitative)\n",
    "    \"\"\"\n",
    "    if len(ASSAY_DATA_QUALITATIVE) > 0:\n",
    "        positives_qualitative = (ASSAY_DATA_QUALITATIVE[\"bin\"] == 1).sum()\n",
    "        ratio_qualitative = round(positives_qualitative / len(ASSAY_DATA_QUALITATIVE), 3)\n",
    "        compounds_qualitative = len(ASSAY_DATA_QUALITATIVE)\n",
    "    else:\n",
    "        positives_qualitative = np.nan\n",
    "        ratio_qualitative = np.nan\n",
    "        compounds_qualitative = np.nan\n",
    "\n",
    "    return positives_qualitative, ratio_qualitative, compounds_qualitative\n",
    "\n",
    "def binarize_with_expert_cutoff(ASSAY_DATA_QUANTITATIVE, expert_cutoff, direction):\n",
    "    \"\"\"\n",
    "    Binarize quantitative assay values using an expert cutoff.\n",
    "\n",
    "    If `expert_cutoff` is not NaN:\n",
    "      - direction == +1 -> bin = 1 if value >= expert_cutoff else 0\n",
    "      - direction != +1 -> bin = 1 if value <= expert_cutoff else 0\n",
    "\n",
    "    If `expert_cutoff` is NaN:\n",
    "      - bin is set to NaN for all rows.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA_QUANTITATIVE : pandas.DataFrame\n",
    "        DataFrame containing a numeric 'value' column.\n",
    "    expert_cutoff : float\n",
    "        Expert-defined cutoff value (may be NaN).\n",
    "    direction : int\n",
    "        Direction of binarization (+1 or -1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The same dataframe with a new column 'bin'.\n",
    "    \"\"\"\n",
    "    if np.isnan(expert_cutoff) == False:\n",
    "        if direction == +1:\n",
    "            ASSAY_DATA_QUANTITATIVE[\"bin\"] = (ASSAY_DATA_QUANTITATIVE[\"value\"] >= expert_cutoff).astype(int)\n",
    "        else:\n",
    "            ASSAY_DATA_QUANTITATIVE[\"bin\"] = (ASSAY_DATA[\"value\"] <= expert_cutoff).astype(int)\n",
    "    else:\n",
    "        ASSAY_DATA_QUANTITATIVE[\"bin\"] = [np.nan] * len(ASSAY_DATA_QUANTITATIVE)\n",
    "\n",
    "    return ASSAY_DATA_QUANTITATIVE\n",
    "\n",
    "def get_activity_stats_quantitative(activities_quantitative):\n",
    "    \"\"\"\n",
    "    Compute summary statistics for quantitative activities.\n",
    "\n",
    "    Calculates min, 1st percentile, 25th percentile, median (50th),\n",
    "    75th percentile, 99th percentile, and max, rounded to 3 decimals.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    activities_quantitative : array-like\n",
    "        Iterable of numeric activity values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (min_, p1, p25, p50, p75, p99, max_)\n",
    "    \"\"\"\n",
    "    min_ = round(np.min(activities_quantitative), 3)\n",
    "    p1 = round(np.percentile(activities_quantitative, 1), 3)\n",
    "    p25 = round(np.percentile(activities_quantitative, 25), 3)\n",
    "    p50 = round(np.percentile(activities_quantitative, 50), 3)\n",
    "    p75 = round(np.percentile(activities_quantitative, 75), 3)\n",
    "    p99 = round(np.percentile(activities_quantitative, 99), 3)\n",
    "    max_ = round(np.max(activities_quantitative), 3)\n",
    "\n",
    "    return min_, p1, p25, p50, p75, p99, max_\n",
    "\n",
    "\n",
    "# Define root directory\n",
    "# root = os.path.dirname(os.path.abspath(__file__))\n",
    "root = \".\"\n",
    "\n",
    "# List of pathogens to process\n",
    "pathogens = [\"Acinetobacter baumannii\", \"Candida albicans\", \"Campylobacter\", \"Escherichia coli\", \"Enterococcus faecium\", \"Enterobacter\",\n",
    "             \"Helicobacter pylori\", \"Klebsiella pneumoniae\", \"Mycobacterium tuberculosis\", \"Neisseria gonorrhoeae\", \"Pseudomonas aeruginosa\",\n",
    "             \"Plasmodium falciparum\", \"Staphylococcus aureus\", \"Schistosoma mansoni\", \"Streptococcus pneumoniae\"]\n",
    "pathogens = [\"Acinetobacter baumannii\", \"Mycobacterium tuberculosis\", \"Klebsiella pneumoniae\"]\n",
    "\n",
    "\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT = os.path.join(root, \"..\", \"output\")\n",
    "\n",
    "# For each pathogen\n",
    "for pathogen in pathogens:\n",
    "\n",
    "    # Get pathogen code\n",
    "    pathogen_code = get_pathogen_code(pathogen)\n",
    "\n",
    "    # Load cleaned assays\n",
    "    ASSAYS_CLEANED = pd.read_csv(os.path.join(root, \"..\", \"output\", pathogen_code, \"assays_cleaned.csv\"))\n",
    "\n",
    "    # Define PATH to parameters\n",
    "    PATH_TO_PARAMETERS = os.path.join(root, \"..\", \"output\", pathogen_code, 'parameters')\n",
    "\n",
    "    # Get curated target type\n",
    "    ASSAYS_CLEANED = add_target_type_curated(ASSAYS_CLEANED, PATH_TO_PARAMETERS)\n",
    "\n",
    "    # Loading pathogen data\n",
    "    os.makedirs(os.path.join(OUTPUT, pathogen_code, 'datasets'), exist_ok=True)\n",
    "    print(f\"Loading ChEMBL cleaned data for {pathogen_code}...\")\n",
    "    ChEMBL_pathogen = pd.read_csv(os.path.join(OUTPUT, pathogen_code, f\"{pathogen_code}_ChEMBL_cleaned_data.csv.gz\"), low_memory=False)\n",
    "    print(f\"Number of activities for {pathogen_code}: {len(ChEMBL_pathogen)}\")\n",
    "    print(f\"Number of compounds for {pathogen_code}: {len(set(ChEMBL_pathogen['compound_chembl_id']))}\")\n",
    "    print(f\"Number of cleaned assays: {len(ASSAYS_CLEANED)}\")\n",
    "\n",
    "    # Load expert cut-offs\n",
    "    EXPERT_CUTOFFS = load_expert_cutoffs(root)\n",
    "\n",
    "    # Define data ranges\n",
    "    DATA_RANGES = []\n",
    "\n",
    "    for assay_chembl_id, activity_type, unit, target_type, target_type_curated, activities, cpds, direction in tqdm(ASSAYS_CLEANED[['assay_id', 'activity_type', 'unit', 'target_type',\n",
    "                                                                                                            'target_type_curated', 'activities', 'cpds', 'direction']].values):\n",
    "\n",
    "        # Filtering [assay, activity_type, unit] data\n",
    "        cols = ['compound_chembl_id', 'canonical_smiles', 'activity_type', 'value', 'relation', 'unit', 'activity_comment', 'standard_text']\n",
    "        ASSAY_DATA = get_assay_data(ChEMBL_pathogen, assay_chembl_id, activity_type, unit, cols)\n",
    "        \n",
    "        # Count relations\n",
    "        equal, lower, higher = count_relations(ASSAY_DATA)\n",
    "\n",
    "        # Get expert cut-off if it exists\n",
    "        key = (activity_type, unit, target_type_curated, pathogen_code)\n",
    "        expert_cutoff = EXPERT_CUTOFFS[key] if key in EXPERT_CUTOFFS else np.nan\n",
    "\n",
    "        # Quantitative view\n",
    "        ASSAY_DATA_QUANTITATIVE = get_assay_data_quantitative(ASSAY_DATA)\n",
    "\n",
    "        # Qualitative view\n",
    "        ASSAY_DATA_QUALITATIVE = get_assay_data_qualitative(ASSAY_DATA)\n",
    "\n",
    "        # Setting up some variables\n",
    "        positives_qualitative, ratio_qualitative, compounds_qualitative = set_variables_qualitative(ASSAY_DATA_QUALITATIVE)\n",
    "\n",
    "        # If direction is 1 or -1\n",
    "        if direction in [+1, -1]:\n",
    "\n",
    "            # Get value to adjust relations\n",
    "            CUT = get_cut_value(ASSAY_DATA, direction)\n",
    "\n",
    "            # Adjust relation\n",
    "            ASSAY_DATA_QUANTITATIVE = adjust_relation(ASSAY_DATA_QUANTITATIVE, direction, CUT)\n",
    "\n",
    "            # Disambiguate duplicated compounds and returns 'sorted' data (depending on direction)\n",
    "            ASSAY_DATA_QUANTITATIVE = disambiguate_compounds(ASSAY_DATA_QUANTITATIVE, direction)\n",
    "\n",
    "            # Binarization with expert cut-off\n",
    "            ASSAY_DATA_QUANTITATIVE = binarize_with_expert_cutoff(ASSAY_DATA_QUANTITATIVE, expert_cutoff, direction)\n",
    "\n",
    "            # Setting up some variables\n",
    "            positives_quantitative, ratio_quantitative, compounds_quantitative, activities_quantitative = set_variables_quantitative(ASSAY_DATA_QUANTITATIVE)\n",
    "\n",
    "            # Set the dataset type\n",
    "            if compounds_qualitative == 0:\n",
    "                dataset_type = 'quantitative'\n",
    "            else:\n",
    "                dataset_type = 'mixed'\n",
    "        else:\n",
    "\n",
    "            assert len(ASSAY_DATA_QUANTITATIVE) == 0\n",
    "\n",
    "            # Qualitative assay\n",
    "            dataset_type = 'qualitative'    \n",
    "\n",
    "            # Setting up some variables\n",
    "            positives_quantitative, ratio_quantitative, compounds_quantitative, activities_quantitative = set_variables_quantitative(ASSAY_DATA_QUANTITATIVE)\n",
    "\n",
    "        # Get activity stats\n",
    "        min_, p1, p25, p50, p75, p99, max_ = get_activity_stats_quantitative(activities_quantitative)\n",
    "\n",
    "        # Store data range\n",
    "        DATA_RANGES.append([assay_chembl_id, activity_type, unit, target_type, target_type_curated, activities, cpds, direction, equal, higher, lower, dataset_type, \n",
    "                            expert_cutoff, positives_quantitative, ratio_quantitative, compounds_quantitative, min_, p1, p25, p50, p75, p99, max_, positives_qualitative, \n",
    "                            ratio_qualitative, compounds_qualitative])\n",
    "\n",
    "        # Save data only if number of compounds is >= 100\n",
    "        dataset_name = f\"{assay_chembl_id}_{activity_type}_{str(unit).replace('/', 'FwdS')}\"\n",
    "        if compounds_quantitative >= 100:\n",
    "            ASSAY_DATA_QUANTITATIVE.to_csv(os.path.join(OUTPUT, pathogen_code, 'datasets', f\"{dataset_name}_qt.csv.gz\"), index=False)\n",
    "        if compounds_qualitative >= 100:\n",
    "            ASSAY_DATA_QUANTITATIVE.to_csv(os.path.join(OUTPUT, pathogen_code, 'datasets', f\"{dataset_name}_ql.csv.gz\"), index=False)\n",
    "\n",
    "\n",
    "    DATA_RANGES = pd.DataFrame(DATA_RANGES, columns=[\"assay_id\", \"activity_type\", \"unit\", \"target_type\", \"target_type_curated\", \"activities\", \"cpds\", \"direction\", \n",
    "                                                    \"equal\", \"higher\", \"lower\", \"dataset_type\", \"expert_cutoff\", \"pos_qt\", \"ratio_qt\", \"cpds_qt\", \"min_\", \"p1\", \"p25\", \n",
    "                                                    \"p50\", \"p75\", \"p99\", \"max_\", \"pos_ql\", \"ratio_ql\", \"cpds_ql\"])\n",
    "    DATA_RANGES.to_csv(os.path.join(OUTPUT, pathogen_code, 'assays_data.csv'), index=False)\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
