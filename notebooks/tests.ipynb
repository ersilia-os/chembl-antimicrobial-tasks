{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6d4ba5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12\n",
      "Loading ChEMBL cleaned data for mtuberculosis...\n",
      "Number of activities for mtuberculosis: 716150\n",
      "Number of compounds for mtuberculosis: 137607\n",
      "Number of cleaned assays: 10532\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "\n",
    "def adjust_relation(ASSAY_DATA: pd.DataFrame, DIRECTION: int, CUT: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adjust relations in an assay DataFrame according to the biological direction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pd.DataFrame\n",
    "        Must contain the columns 'relation' and 'value'.\n",
    "    DIRECTION : int\n",
    "        +1 → higher = more active (e.g. % inhibition)\n",
    "        -1 → lower = more active (e.g. IC50, MIC)\n",
    "    CUT : float\n",
    "        Extreme value used to replace censored measurements\n",
    "        on the wrong side of the direction (min or max)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Copy of ASSAY_DATA with adjusted relation and value.\n",
    "    \"\"\"\n",
    "\n",
    "    df = ASSAY_DATA.copy()\n",
    "    rel = df[\"relation\"].astype(str)\n",
    "\n",
    "    if DIRECTION == +1:\n",
    "\n",
    "        # Higher = more active\n",
    "        mask_gt = rel == \">\"  # greater than\n",
    "        mask_lt = rel == \"<\"  # lower than\n",
    "\n",
    "        df.loc[mask_gt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_lt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_lt, \"value\"] = CUT\n",
    "\n",
    "    elif DIRECTION == -1:\n",
    "\n",
    "        # Lower = more active\n",
    "        mask_lt = rel == \"<\"  # lower than\n",
    "        mask_gt = rel == \">\"  # greater than\n",
    "\n",
    "        df.loc[mask_lt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_gt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_gt, \"value\"] = CUT\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise ValueError(f\"Invalid DIRECTION={DIRECTION}. Expected +1 or -1.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def disambiguate_compounds(ASSAY_DATA: pd.DataFrame, DIRECTION: int) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Select a single measurement per compound according to the biological direction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pd.DataFrame\n",
    "        Must contain the columns 'compound_chembl_id' and 'value'.\n",
    "        Assumes all relations have already been adjusted.\n",
    "    DIRECTION : int\n",
    "        +1 → higher = more active (e.g. % inhibition)\n",
    "        -1 → lower = more active (e.g. IC50, MIC)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A copy of ASSAY_DATA in which duplicated compounds \n",
    "        ('compound_chembl_id') are removed, keeping only the \n",
    "        most active measurement per compound (highest or lowest \n",
    "        depending on DIRECTION).\n",
    "    \"\"\"\n",
    "\n",
    "    if DIRECTION not in [1, -1]:\n",
    "        raise ValueError(\"DIRECTION must be +1 (higher = more active) or -1 (lower = more active).\")\n",
    "        \n",
    "    df = ASSAY_DATA.copy()\n",
    "\n",
    "    # Choose best measurement based on direction\n",
    "    if DIRECTION == -1:\n",
    "        # Lower = more active → keep minimum\n",
    "        df_sorted = df.sort_values(by=\"value\", ascending=True)\n",
    "    elif DIRECTION == 1:\n",
    "        # Higher = more active → keep maximum\n",
    "        df_sorted = df.sort_values(by=\"value\", ascending=False)\n",
    "\n",
    "    # Keep the best row per compound_chembl_id\n",
    "    df_best = df_sorted.drop_duplicates(subset=\"compound_chembl_id\", keep=\"first\")\n",
    "\n",
    "    return df_best.reset_index(drop=True)\n",
    "\n",
    "def add_target_type_curated(ASSAYS_CLEANED, PARAMETERS):\n",
    "    \"\"\"\n",
    "    Add a `target_type_curated` column to ASSAYS_CLEANED using curated assay parameters.\n",
    "\n",
    "    For each row in ASSAYS_CLEANED, the function matches on:\n",
    "        [`assay_id`, `activity_type`, `unit`]\n",
    "\n",
    "    and pulls the corresponding value from the `target_type_curated` column in PARAMETERS.\n",
    "\n",
    "    The function enforces that:\n",
    "      - all keys in PARAMETERS exist in ASSAYS_CLEANED\n",
    "      - all keys in ASSAYS_CLEANED exist in PARAMETERS\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAYS_CLEANED : pandas.DataFrame\n",
    "        DataFrame containing at least the columns:\n",
    "        `assay_id`, `activity_type`, `unit`.\n",
    "    PARAMETERS : pandas.DataFrame\n",
    "        DataFrame containing curated assay parameters, including\n",
    "        `assay_id`, `activity_type`, `unit`, and `target_type_curated`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        ASSAYS_CLEANED with an added `target_type_curated` column.\n",
    "    \"\"\"\n",
    "    # Load only the columns we need from the parameters table\n",
    "    PARAMETERS = PARAMETERS[[\"assay_id\", \"activity_type\", \"unit\", \"target_type_curated\"]].copy()\n",
    "\n",
    "    # Match writer behavior from Step 11: missing units are stored as empty strings\n",
    "    ASSAYS_CLEANED = ASSAYS_CLEANED.copy()\n",
    "    ASSAYS_CLEANED[\"unit\"] = ASSAYS_CLEANED[\"unit\"].fillna(\"\")\n",
    "    PARAMETERS[\"unit\"] = PARAMETERS[\"unit\"].fillna(\"\")\n",
    "\n",
    "    # Check that everything in PARAMETERS actually maps to ASSAYS_CLEANED\n",
    "    if not PARAMETERS[[\"assay_id\",\"activity_type\",\"unit\"]].merge(\n",
    "        ASSAYS_CLEANED[[\"assay_id\",\"activity_type\",\"unit\"]],\n",
    "        on=[\"assay_id\",\"activity_type\",\"unit\"],\n",
    "        how=\"left\",\n",
    "        indicator=True\n",
    "    )[\"_merge\"].eq(\"both\").all():\n",
    "        raise ValueError(\"PARAMETERS contains keys not present in ASSAYS_CLEANED\")\n",
    "    \n",
    "    # Check that everything in ASSAYS_CLEANED actually maps to PARAMETERS\n",
    "    if not ASSAYS_CLEANED[[\"assay_id\",\"activity_type\",\"unit\"]].merge(\n",
    "        PARAMETERS[[\"assay_id\",\"activity_type\",\"unit\"]],\n",
    "        on=[\"assay_id\",\"activity_type\",\"unit\"],\n",
    "        how=\"left\",\n",
    "        indicator=True\n",
    "    )[\"_merge\"].eq(\"both\").all():\n",
    "        raise ValueError(\"ASSAYS_CLEANED contains keys not present in PARAMETERS\")\n",
    "\n",
    "    # Merge curated target type onto the cleaned assays table\n",
    "    ASSAYS_CLEANED = ASSAYS_CLEANED.merge(PARAMETERS, on=[\"assay_id\", \"activity_type\", \"unit\"], how=\"left\", validate=\"1:1\")\n",
    "\n",
    "    # Unit \"\" back to nans\n",
    "    ASSAYS_CLEANED[\"unit\"] = ASSAYS_CLEANED[\"unit\"].replace(\"\", np.nan)\n",
    "\n",
    "    return ASSAYS_CLEANED\n",
    "\n",
    "def load_expert_cutoffs(CONFIGPATH):\n",
    "    \"\"\"\n",
    "    Load expert cutoffs from the manual curation CSV and return them as a dictionary.\n",
    "\n",
    "    The CSV is expected at:\n",
    "        {CONFIGPATH}/manual_curation/expert_cutoffs.csv\n",
    "\n",
    "    The returned dictionary maps:\n",
    "        (activity_type, unit, target_type, pathogen_code) -> expert_cutoff\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    CONFIGPATH : str\n",
    "        Path to the config folder.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary of expert cutoffs keyed by\n",
    "        (activity_type, unit, target_type, pathogen_code).\n",
    "    \"\"\"\n",
    "    # Load expert cut-offs\n",
    "    EXPERT_CUTOFFS = pd.read_csv(os.path.join(CONFIGPATH, \"expert_cutoffs.csv\"))\n",
    "\n",
    "    EXPERT_CUTOFFS = {\n",
    "        (a, b, c, d): [float(k) for k in e.split(\";\")]\n",
    "        for a, b, c, d, e in EXPERT_CUTOFFS[\n",
    "            [\"activity_type\", \"unit\", \"target_type\", \"pathogen_code\", \"expert_cutoff\"]\n",
    "        ].values\n",
    "    }\n",
    "\n",
    "    return EXPERT_CUTOFFS\n",
    "\n",
    "def get_assay_data(ChEMBL_pathogen, assay_chembl_id, activity_type, unit, cols):\n",
    "    \"\"\"\n",
    "    Extract assay activity data for a given assay_chembl_id, activity_type, and unit.\n",
    "\n",
    "    If `unit` is a string, the function filters rows where `unit` matches exactly.\n",
    "    Otherwise, it filters rows where `unit` is missing (NaN).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ChEMBL_pathogen : pandas.DataFrame\n",
    "        DataFrame containing ChEMBL pathogen activity records.\n",
    "    assay_chembl_id : str\n",
    "        Assay ChEMBL ID to filter on.\n",
    "    activity_type : str\n",
    "        Activity type to filter on (e.g., IC50, MIC).\n",
    "    unit : str or None\n",
    "        Unit to filter on; if not a string, NaN units are selected.\n",
    "    cols : list\n",
    "        List of columns to return.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Filtered assay activity data with only the requested columns.\n",
    "    \"\"\"\n",
    "    if type(unit) == str:\n",
    "        ASSAY_DATA = ChEMBL_pathogen[\n",
    "            (ChEMBL_pathogen['assay_chembl_id'] == assay_chembl_id) &\n",
    "            (ChEMBL_pathogen['activity_type'] == activity_type) &\n",
    "            (ChEMBL_pathogen['unit'] == unit)\n",
    "        ].reset_index(drop=True)[cols]\n",
    "    else:\n",
    "        ASSAY_DATA = ChEMBL_pathogen[\n",
    "            (ChEMBL_pathogen['assay_chembl_id'] == assay_chembl_id) &\n",
    "            (ChEMBL_pathogen['activity_type'] == activity_type) &\n",
    "            (ChEMBL_pathogen['unit'].isna())\n",
    "        ].reset_index(drop=True)[cols]\n",
    "\n",
    "    return ASSAY_DATA\n",
    "\n",
    "def get_cut_value(ASSAY_DATA, direction):\n",
    "    \"\"\"\n",
    "    Get a cutoff value from ASSAY_DATA to adjust relations based on direction.\n",
    "\n",
    "    If direction == 1, returns the minimum value in ASSAY_DATA['value'].\n",
    "    If direction == -1, returns the maximum value in ASSAY_DATA['value'].\n",
    "    Otherwise, returns np.nan.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pandas.DataFrame\n",
    "        DataFrame containing a 'value' column with numeric assay values.\n",
    "    direction : int\n",
    "        Direction indicator:\n",
    "        - 1  -> use minimum value\n",
    "        - -1 -> use maximum value\n",
    "        - else -> np.nan\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Cutoff value computed from the 'value' column or np.nan.\n",
    "    \"\"\"\n",
    "    if direction == 1:\n",
    "        CUT = min(ASSAY_DATA['value'])\n",
    "    elif direction == -1:\n",
    "        CUT = max(ASSAY_DATA['value'])\n",
    "    else:\n",
    "        CUT = np.nan\n",
    "\n",
    "    return CUT\n",
    "\n",
    "def count_relations(ASSAY_DATA):\n",
    "    \"\"\"\n",
    "    Count relation operators in ASSAY_DATA['relation'].\n",
    "\n",
    "    Counts how many times each of the following appears:\n",
    "        \"=\" , \"<\" , \">\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pandas.DataFrame\n",
    "        DataFrame containing a 'relation' column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (equal, lower, higher) counts corresponding to \"=\", \"<\", \">\".\n",
    "    \"\"\"\n",
    "    counter_relations = Counter(ASSAY_DATA['relation'].tolist())\n",
    "    equal = counter_relations[\"=\"]\n",
    "    lower = counter_relations[\"<\"]\n",
    "    higher = counter_relations[\">\"]\n",
    "\n",
    "    return equal, lower, higher\n",
    "\n",
    "def get_assay_data_quantitative(ASSAY_DATA):\n",
    "    \"\"\"\n",
    "    Return only rows in ASSAY_DATA with non-missing quantitative values.\n",
    "\n",
    "    Filters ASSAY_DATA to keep rows where `value` is not NaN, and resets the index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pandas.DataFrame\n",
    "        DataFrame containing a 'value' column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Filtered dataframe containing only rows with non-null `value`.\n",
    "    \"\"\"\n",
    "    ASSAY_DATA_QUANTITATIVE = ASSAY_DATA[ASSAY_DATA['value'].isna() == False].reset_index(drop=True)\n",
    "    ASSAY_DATA_QUANTITATIVE = ASSAY_DATA_QUANTITATIVE.drop(columns=['text_flag'])\n",
    "    return ASSAY_DATA_QUANTITATIVE\n",
    "\n",
    "def get_assay_data_qualitative(ASSAY_DATA):\n",
    "    \"\"\"\n",
    "    Build a compound-level qualitative dataset from assay text flags.\n",
    "\n",
    "    Aggregates `text_flag` values per compound, checks for conflicting\n",
    "    qualitative labels, assigns a final compound-level label, and\n",
    "    returns one row per compound with a binary activity label.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pandas.DataFrame\n",
    "        DataFrame containing at least `compound_chembl_id` and `text_flag`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Qualitative dataset with one row per compound and a binary label.\n",
    "    \"\"\"\n",
    "\n",
    "    ASSAY_DATA_QUALITATIVE = ASSAY_DATA.copy()\n",
    "\n",
    "    # Aggregate to compound-level label\n",
    "    compound_labels = ASSAY_DATA_QUALITATIVE.groupby(\"compound_chembl_id\")[\"text_flag\"].apply(set)\n",
    "\n",
    "    # Detect compound-level conflicts (same compound has 1 and -1)\n",
    "    compound_ids = compound_labels.index.tolist()\n",
    "    label_sets = compound_labels.tolist()\n",
    "    compound_conflict = [((1 in s) and (-1 in s)) for s in label_sets]\n",
    "    if any(compound_conflict):\n",
    "        bad = [(cid, s) for cid, s, c in zip(compound_ids, label_sets, compound_conflict) if c][:20]\n",
    "        raise ValueError(\n",
    "            \"Conflicting compound labels (same compound has both 1 and -1 across rows):\\n\"\n",
    "            + \"\\n\".join([f\"{cid}: {s}\" for cid, s in bad]))\n",
    "\n",
    "    # Final compound label: 1 > -1 > 0\n",
    "    compound_final = [1 if 1 in s else (-1 if -1 in s else 0) for s in label_sets]\n",
    "    compound_final = dict(zip(compound_ids, compound_final))\n",
    "\n",
    "    # Assign back to all rows\n",
    "    ASSAY_DATA_QUALITATIVE[\"qualitative_label\"] = ASSAY_DATA_QUALITATIVE[\"compound_chembl_id\"].map(compound_final)\n",
    "\n",
    "    # Keep only one row per compound\n",
    "    ASSAY_DATA_QUALITATIVE = ASSAY_DATA_QUALITATIVE.drop_duplicates(subset=[\"compound_chembl_id\"]).reset_index(drop=True)\n",
    "\n",
    "    # Remove compounds labeled as 0\n",
    "    ASSAY_DATA_QUALITATIVE = ASSAY_DATA_QUALITATIVE[ASSAY_DATA_QUALITATIVE[\"qualitative_label\"] != 0].reset_index(drop=True)\n",
    "\n",
    "    # Binary label\n",
    "    ASSAY_DATA_QUALITATIVE[\"bin\"] = [0 if x == -1 else 1 for x in ASSAY_DATA_QUALITATIVE[\"qualitative_label\"].tolist()]\n",
    "\n",
    "    # Take only interesting columns\n",
    "    cols = [\"compound_chembl_id\", \"canonical_smiles\", \"activity_type\", \"unit\", \"text_flag\", \"qualitative_label\", 'bin'] \n",
    "    ASSAY_DATA_QUALITATIVE = ASSAY_DATA_QUALITATIVE[cols]\n",
    "\n",
    "    return ASSAY_DATA_QUALITATIVE\n",
    "    \n",
    "def set_variables_quantitative(ASSAY_DATA_QUANTITATIVE):\n",
    "    \"\"\"\n",
    "    Compute basic statistics for a quantitative, binarized assay dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA_QUANTITATIVE : pandas.DataFrame\n",
    "        Quantitative assay data containing one row per compound and a\n",
    "        binary `bin` column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (positives_quantitative, ratio_quantitative,\n",
    "         compounds_quantitative, activities_quantitative)\n",
    "    \"\"\"\n",
    "    positives_quantitative = (ASSAY_DATA_QUANTITATIVE[\"bin\"] == 1).sum()\n",
    "    ratio_quantitative = round(positives_quantitative / len(ASSAY_DATA_QUANTITATIVE), 5)\n",
    "    compounds_quantitative = len(set(ASSAY_DATA_QUANTITATIVE['compound_chembl_id']))\n",
    "    activities_quantitative = ASSAY_DATA_QUANTITATIVE['value'].tolist()\n",
    "    assert compounds_quantitative == len(activities_quantitative)\n",
    "\n",
    "    return positives_quantitative, ratio_quantitative, compounds_quantitative, activities_quantitative\n",
    "\n",
    "def set_variables_qualitative(ASSAY_DATA_QUALITATIVE):\n",
    "    \"\"\"\n",
    "    Compute basic statistics for a qualitative assay dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA_QUALITATIVE : pandas.DataFrame\n",
    "        Qualitative assay data containing one row per compound and a\n",
    "        binary `bin` column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (positives_qualitative, ratio_qualitative, compounds_qualitative)\n",
    "    \"\"\"\n",
    "    positives_qualitative = (ASSAY_DATA_QUALITATIVE[\"bin\"] == 1).sum()\n",
    "    ratio_qualitative = round(positives_qualitative / len(ASSAY_DATA_QUALITATIVE), 5)\n",
    "    compounds_qualitative = len(set(ASSAY_DATA_QUALITATIVE['compound_chembl_id']))\n",
    "    assert compounds_qualitative == len(ASSAY_DATA_QUALITATIVE)\n",
    "\n",
    "    return positives_qualitative, ratio_qualitative, compounds_qualitative\n",
    "\n",
    "def binarize_with_expert_cutoff(ASSAY_DATA_QUANTITATIVE, expert_cutoff, direction):\n",
    "    \"\"\"\n",
    "    Binarize quantitative assay values using an expert-defined cutoff.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA_QUANTITATIVE : pandas.DataFrame\n",
    "        Quantitative assay data containing a numeric `value` column.\n",
    "    expert_cutoff : float\n",
    "        Expert-defined activity threshold.\n",
    "    direction : int\n",
    "        +1 → higher values are more active\n",
    "        -1 → lower values are more active\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Input dataframe with an added binary `bin` column.\n",
    "    \"\"\"\n",
    "    if direction == +1:\n",
    "        ASSAY_DATA_QUANTITATIVE[\"bin\"] = (ASSAY_DATA_QUANTITATIVE[\"value\"] >= expert_cutoff).astype(int)\n",
    "    else:\n",
    "        ASSAY_DATA_QUANTITATIVE[\"bin\"] = (ASSAY_DATA_QUANTITATIVE[\"value\"] <= expert_cutoff).astype(int)\n",
    "\n",
    "    return ASSAY_DATA_QUANTITATIVE\n",
    "\n",
    "def get_activity_stats_quantitative(activities_quantitative):\n",
    "    \"\"\"\n",
    "    Compute summary statistics for quantitative activities.\n",
    "\n",
    "    Calculates min, 1st percentile, 25th percentile, median (50th),\n",
    "    75th percentile, 99th percentile, and max, rounded to 3 decimals.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    activities_quantitative : array-like\n",
    "        Iterable of numeric activity values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (min_, p1, p25, p50, p75, p99, max_)\n",
    "    \"\"\"\n",
    "    min_ = round(np.min(activities_quantitative), 3)\n",
    "    p1 = round(np.percentile(activities_quantitative, 1), 3)\n",
    "    p25 = round(np.percentile(activities_quantitative, 25), 3)\n",
    "    p50 = round(np.percentile(activities_quantitative, 50), 3)\n",
    "    p75 = round(np.percentile(activities_quantitative, 75), 3)\n",
    "    p99 = round(np.percentile(activities_quantitative, 99), 3)\n",
    "    max_ = round(np.max(activities_quantitative), 3)\n",
    "\n",
    "    return min_, p1, p25, p50, p75, p99, max_\n",
    "\n",
    "def extra_curation_target_type(target_type, target_type_curated):\n",
    "    \"\"\"\n",
    "    Post-process and enforce simple curation rules for ChEMBL assay target types.\n",
    "\n",
    "    This function normalizes `target_type` and `target_type_curated` (strip + uppercase)\n",
    "    and returns a constrained/standardized `target_type_curated` according to rules:\n",
    "\n",
    "    - If target_type == \"UNCHECKED\": allow only {\"ORGANISM\", \"SINGLE PROTEIN\", \"DISCARDED\"};\n",
    "      otherwise force \"DISCARDED\".\n",
    "    - If target_type == \"NOT-MOLECULAR\": allow only {\"ORGANISM\", \"DISCARDED\"};\n",
    "      otherwise force \"DISCARDED\".\n",
    "    - If target_type is protein-related ({\"SINGLE PROTEIN\",\"PROTEIN COMPLEX\",\"PROTEIN FAMILY\"}):\n",
    "      collapse to \"SINGLE PROTEIN\".\n",
    "    - If target_type == \"ORGANISM\": return \"ORGANISM\".\n",
    "    - All other target types are mapped to \"DISCARDED\".\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target_type : str\n",
    "        Raw ChEMBL \"Target type\" value.\n",
    "    target_type_curated : str\n",
    "        LLM- or human-proposed curated target type.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The finalized curated target type: \"SINGLE PROTEIN\", \"ORGANISM\", or \"DISCARDED\".\n",
    "    \"\"\"\n",
    "\n",
    "    if type(target_type_curated) != str:\n",
    "        return 'DISCARDED'\n",
    "\n",
    "    target_type = target_type.strip().upper()\n",
    "    target_type_curated = target_type_curated.strip().upper()\n",
    "\n",
    "    if target_type == 'UNCHECKED':\n",
    "        if target_type_curated in ['ORGANISM', 'SINGLE PROTEIN', 'DISCARDED']:\n",
    "            return target_type_curated\n",
    "        else:\n",
    "            return 'DISCARDED'\n",
    "        \n",
    "    elif target_type == 'NOT-MOLECULAR':\n",
    "        if target_type_curated in ['ORGANISM', 'DISCARDED']:\n",
    "            return target_type_curated\n",
    "        else:\n",
    "            return 'DISCARDED'\n",
    "        \n",
    "    elif target_type in ['SINGLE PROTEIN', 'PROTEIN COMPLEX', 'PROTEIN FAMILY']:\n",
    "        return 'SINGLE PROTEIN'\n",
    "\n",
    "    elif target_type in ['ORGANISM']:\n",
    "        return 'ORGANISM'\n",
    "    \n",
    "    else:\n",
    "        return 'DISCARDED'\n",
    "\n",
    "def zip_and_remove(datasets_dir):\n",
    "    \"\"\"\n",
    "    Create three zip archives in `datasets_dir`:\n",
    "      - datasets_qt.zip containing all files ending with \"_qt.csv.gz\"\n",
    "      - datasets_ql.zip containing all files ending with \"_ql.csv.gz\"\n",
    "      - datasets_mx.zip containing all files ending with \"_mx.csv.gz\"\n",
    "\n",
    "    After zipping, remove the original *_qt.csv.gz, *_ql.csv.gz, and *_mx.csv.gz files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    datasets_dir : str\n",
    "        Directory containing the dataset files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[int, int, int]\n",
    "        (n_qt_files, n_ql_files, n_mx_files)\n",
    "    \"\"\"\n",
    "    qt_zip = os.path.join(datasets_dir, \"datasets_qt.zip\")\n",
    "    ql_zip = os.path.join(datasets_dir, \"datasets_ql.zip\")\n",
    "    mx_zip = os.path.join(datasets_dir, \"datasets_mx.zip\")\n",
    "\n",
    "    if os.path.exists(qt_zip):\n",
    "        os.remove(qt_zip)\n",
    "    if os.path.exists(ql_zip):\n",
    "        os.remove(ql_zip)\n",
    "    if os.path.exists(mx_zip):\n",
    "        os.remove(mx_zip)\n",
    "\n",
    "    qt_files = [os.path.join(datasets_dir, i) for i in os.listdir(datasets_dir) if \"_qt_\" in i]  # cutoff specified in file name\n",
    "    ql_files = [os.path.join(datasets_dir, i) for i in os.listdir(datasets_dir) if i.endswith(\"_ql.csv.gz\")]\n",
    "    mx_files = [os.path.join(datasets_dir, i) for i in os.listdir(datasets_dir) if \"_mx_\" in i]  # cutoff specified in file name\n",
    "\n",
    "    with zipfile.ZipFile(qt_zip, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
    "        for fp in qt_files:\n",
    "            z.write(fp, arcname=os.path.basename(fp))\n",
    "\n",
    "    with zipfile.ZipFile(ql_zip, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
    "        for fp in ql_files:\n",
    "            z.write(fp, arcname=os.path.basename(fp))\n",
    "\n",
    "    with zipfile.ZipFile(mx_zip, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
    "        for fp in mx_files:\n",
    "            z.write(fp, arcname=os.path.basename(fp))\n",
    "\n",
    "    for fp in qt_files + ql_files + mx_files:\n",
    "        os.remove(fp)\n",
    "\n",
    "    return len(qt_files), len(ql_files), len(mx_files)\n",
    "\n",
    "\n",
    "# Define root directory\n",
    "# root = os.path.dirname(os.path.abspath(__file__))\n",
    "root = '.'\n",
    "sys.path.append(os.path.join(root, \"..\", \"src\"))\n",
    "from default import DATAPATH, CONFIGPATH\n",
    "\n",
    "# Load pathogen info\n",
    "# pathogen_code = sys.argv[1]\n",
    "pathogen_code = 'mtuberculosis'\n",
    "df = pd.read_csv(os.path.join(CONFIGPATH, 'pathogens.csv'))\n",
    "row = df.loc[df[\"code\"].eq(pathogen_code)]\n",
    "if row.empty: \n",
    "    raise SystemExit(f\"Unknown code: {pathogen_code}\")\n",
    "pathogen = row.iloc[0][\"pathogen\"]\n",
    "\n",
    "print(\"Step 12\")\n",
    "\n",
    "# Define output directory\n",
    "OUTPUT = os.path.join(root, \"..\", \"output\")\n",
    "\n",
    "# Load cleaned assays\n",
    "ASSAYS_CLEANED = pd.read_csv(os.path.join(OUTPUT, pathogen_code, \"assays_cleaned.csv\"))\n",
    "\n",
    "# Define PATH to parameters\n",
    "PARAMETERS = pd.read_csv(os.path.join(OUTPUT, pathogen_code, 'assays_parameters.csv'))\n",
    "\n",
    "# Get curated target type\n",
    "ASSAYS_CLEANED = add_target_type_curated(ASSAYS_CLEANED, PARAMETERS)\n",
    "\n",
    "# Extra curation\n",
    "ASSAYS_CLEANED['target_type_curated_extra'] = [extra_curation_target_type(i,j) for i,j in zip(ASSAYS_CLEANED['target_type'], ASSAYS_CLEANED['target_type_curated'])]\n",
    "\n",
    "# Loading pathogen data\n",
    "os.makedirs(os.path.join(OUTPUT, pathogen_code, 'datasets'), exist_ok=True)\n",
    "print(f\"Loading ChEMBL cleaned data for {pathogen_code}...\")\n",
    "ChEMBL_pathogen = pd.read_csv(os.path.join(OUTPUT, pathogen_code, f\"{pathogen_code}_ChEMBL_cleaned_data.csv.gz\"), low_memory=False)\n",
    "print(f\"Number of activities for {pathogen_code}: {len(ChEMBL_pathogen)}\")\n",
    "print(f\"Number of compounds for {pathogen_code}: {len(set(ChEMBL_pathogen['compound_chembl_id']))}\")\n",
    "print(f\"Number of cleaned assays: {len(ASSAYS_CLEANED)}\")\n",
    "\n",
    "# Load expert cut-offs\n",
    "EXPERT_CUTOFFS = load_expert_cutoffs(CONFIGPATH)\n",
    "\n",
    "# Get assay to index mapping\n",
    "assay_to_idx = defaultdict(list)\n",
    "for i, assay_id in enumerate(ChEMBL_pathogen[\"assay_chembl_id\"].to_numpy()):\n",
    "    assay_to_idx[assay_id].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b8c29302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing datasets for each assay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10532 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 126/10532 [00:27<37:10,  4.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of assays: 127\n",
      "Types of assays: {'quantitative': 99, 'mixed': 15, 'qualitative': 10, 'none': 3}\n",
      "Total number of datasets: 355\n",
      "Types of datasets: {'quantitative': 297, 'mixed': 45, 'qualitative': 10, 'none': 3}\n"
     ]
    }
   ],
   "source": [
    "# Define data ranges\n",
    "DATASETS, ASSAY_DATA_INFO = [], []\n",
    "\n",
    "print(\"Preparing datasets for each assay\")\n",
    "\n",
    "for assay_chembl_id, activity_type, unit, target_type, target_type_curated_extra, activities, nan_values, cpds, direction, act_flag, inact_flag in tqdm(ASSAYS_CLEANED[['assay_id', \n",
    "                                    'activity_type', 'unit', 'target_type','target_type_curated_extra', 'activities', 'nan_values', 'cpds', 'direction', \n",
    "                                    'act_flag', 'inact_flag']].values[:]):\n",
    "\n",
    "    # Filtering [assay, activity_type, unit] data\n",
    "    cols = ['compound_chembl_id', 'canonical_smiles', 'activity_type', 'value', 'relation', 'unit', 'text_flag']\n",
    "    tmp_df = ChEMBL_pathogen.iloc[assay_to_idx[assay_chembl_id]]    \n",
    "    ASSAY_DATA = get_assay_data(tmp_df, assay_chembl_id, activity_type, unit, cols)\n",
    "\n",
    "    # Get dataset name\n",
    "    dataset_name = f\"{assay_chembl_id}_{activity_type}_{str(unit).replace('/', 'FwdS')}\"\n",
    "    \n",
    "    # Count relations\n",
    "    equal, lower, higher = count_relations(ASSAY_DATA)\n",
    "\n",
    "    # Mixed data, nan by default\n",
    "    positives_mixed, ratio_mixed, compounds_mixed, overlap_mixed = [np.nan] * 4\n",
    "\n",
    "    # Qualitative view\n",
    "    ASSAY_DATA_QUALITATIVE = get_assay_data_qualitative(ASSAY_DATA)\n",
    "\n",
    "    # Setting up some variables\n",
    "    if len(ASSAY_DATA_QUALITATIVE) > 0:\n",
    "        positives_qualitative, ratio_qualitative, compounds_qualitative = set_variables_qualitative(ASSAY_DATA_QUALITATIVE)\n",
    "    else:\n",
    "        positives_qualitative, ratio_qualitative, compounds_qualitative = [np.nan] * 3\n",
    "\n",
    "    # Quantitative view\n",
    "    ASSAY_DATA_QUANTITATIVE = get_assay_data_quantitative(ASSAY_DATA)\n",
    "\n",
    "    # Get expert cut-offs if existing\n",
    "    key = (activity_type, unit, target_type_curated_extra, pathogen_code)\n",
    "    expert_cutoffs = EXPERT_CUTOFFS[key] if key in EXPERT_CUTOFFS else [np.nan]\n",
    "\n",
    "    if len(ASSAY_DATA_QUANTITATIVE) == 0:\n",
    "\n",
    "        if np.isnan(compounds_qualitative):\n",
    "            raise ValueError(\"Dataset does not have numerical values nor activity flags. By definition, this is not possible at this stage. Please revise.\")\n",
    "        else:\n",
    "            dataset_type = 'qualitative'\n",
    "\n",
    "            # Quantitative binarization is not possible\n",
    "            positives_quantitative, ratio_quantitative, compounds_quantitative, activities_quantitative = [np.nan] * 4\n",
    "            min_, p1, p25, p50, p75, p99, max_ = [np.nan] * 7\n",
    "            expert_cutoff = np.nan\n",
    "\n",
    "            # Store data range\n",
    "            DATASETS.append([assay_chembl_id, activity_type, unit, target_type, target_type_curated_extra, activities, nan_values, cpds, direction, act_flag, \n",
    "                                inact_flag, dataset_type, expert_cutoff, positives_quantitative, ratio_quantitative, compounds_quantitative, positives_qualitative, \n",
    "                                ratio_qualitative, compounds_qualitative, overlap_mixed, positives_mixed, ratio_mixed, compounds_mixed])\n",
    "            \n",
    "            # Store dataset\n",
    "            ASSAY_DATA_QUALITATIVE.to_csv(os.path.join(OUTPUT, pathogen_code, 'datasets', f\"{dataset_name}_ql.csv.gz\"), index=False)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # For each expert_cutoff\n",
    "        for expert_cutoff in expert_cutoffs:\n",
    "\n",
    "            # If expert cutoff is nan\n",
    "            if np.isnan(expert_cutoff) == True or direction not in [-1, +1]:\n",
    "\n",
    "                # Quantitative binarization is not possible\n",
    "                positives_quantitative = np.nan\n",
    "                ratio_quantitative = np.nan\n",
    "                compounds_quantitative = len(set(ASSAY_DATA_QUANTITATIVE['compound_chembl_id']))\n",
    "                activities_quantitative = ASSAY_DATA_QUANTITATIVE['value'].tolist()\n",
    "                min_, p1, p25, p50, p75, p99, max_ = get_activity_stats_quantitative(activities_quantitative)\n",
    "\n",
    "                # Assess qualitative compounds\n",
    "                if np.isnan(compounds_qualitative):\n",
    "                    dataset_type = 'none'\n",
    "                else:\n",
    "                    dataset_type = 'qualitative'\n",
    "                    \n",
    "                    # Store dataset\n",
    "                    ASSAY_DATA_QUALITATIVE.to_csv(os.path.join(OUTPUT, pathogen_code, 'datasets', f\"{dataset_name}_ql.csv.gz\"), index=False)\n",
    "\n",
    "            else:\n",
    "                \n",
    "                # Get value to adjust relations\n",
    "                CUT = get_cut_value(ASSAY_DATA, direction)\n",
    "\n",
    "                # Adjust relation\n",
    "                ASSAY_DATA_QUANTITATIVE = adjust_relation(ASSAY_DATA_QUANTITATIVE, direction, CUT)\n",
    "\n",
    "                # Disambiguate duplicated compounds and returns 'sorted' data (depending on direction)\n",
    "                ASSAY_DATA_QUANTITATIVE = disambiguate_compounds(ASSAY_DATA_QUANTITATIVE, direction)\n",
    "\n",
    "                # Binarization with expert cut-off\n",
    "                ASSAY_DATA_QUANTITATIVE = binarize_with_expert_cutoff(ASSAY_DATA_QUANTITATIVE, expert_cutoff, direction)\n",
    "\n",
    "                # Setting up some variables\n",
    "                positives_quantitative, ratio_quantitative, compounds_quantitative, activities_quantitative = set_variables_quantitative(ASSAY_DATA_QUANTITATIVE)\n",
    "\n",
    "                # Get activity stats\n",
    "                min_, p1, p25, p50, p75, p99, max_ = get_activity_stats_quantitative(activities_quantitative)\n",
    "\n",
    "                if np.isnan(compounds_qualitative):\n",
    "                    dataset_type = 'quantitative'\n",
    "\n",
    "                    # Store dataset\n",
    "                    ASSAY_DATA_QUANTITATIVE.to_csv(os.path.join(OUTPUT, pathogen_code, 'datasets', f\"{dataset_name}_qt_{expert_cutoff}.csv.gz\"), index=False)\n",
    "\n",
    "                else:\n",
    "                    dataset_type = 'mixed'\n",
    "\n",
    "                    # Get overlap mixed\n",
    "                    overlap_mixed = set(ASSAY_DATA_QUANTITATIVE['compound_chembl_id']).intersection(set(ASSAY_DATA_QUALITATIVE['compound_chembl_id']))\n",
    "                    overlap_mixed = round(len(overlap_mixed) / min(len(ASSAY_DATA_QUANTITATIVE), len(ASSAY_DATA_QUALITATIVE)), 3)\n",
    "\n",
    "                    # Get compounds in quantitative\n",
    "                    qt_compounds = set(ASSAY_DATA_QUANTITATIVE['compound_chembl_id'])\n",
    "\n",
    "                    # Prepare qualitative inactives\n",
    "                    ASSAY_DATA_QUALITATIVE_MIXED = ASSAY_DATA_QUALITATIVE[(ASSAY_DATA_QUALITATIVE['compound_chembl_id'].isin(qt_compounds) == False) & \n",
    "                                                (ASSAY_DATA_QUALITATIVE['bin'] == 0)].reset_index(drop=True).copy()\n",
    "                    ASSAY_DATA_QUALITATIVE_MIXED['value'] = np.nan\n",
    "                    ASSAY_DATA_QUALITATIVE_MIXED['relation'] = np.nan\n",
    "\n",
    "                    # Prepare quantitative compounds\n",
    "                    ASSAY_DATA_QUANTITATIVE_MIXED = ASSAY_DATA_QUANTITATIVE.copy()\n",
    "                    ASSAY_DATA_QUANTITATIVE_MIXED['text_flag'] = np.nan\n",
    "                    ASSAY_DATA_QUANTITATIVE_MIXED['qualitative_label'] = np.nan\n",
    "\n",
    "                    # Append inactive qualitatives to quantitative dataset [mixed dataset]\n",
    "                    ASSAY_DATA_MIXED = pd.concat([ASSAY_DATA_QUANTITATIVE_MIXED, ASSAY_DATA_QUALITATIVE_MIXED], axis=0).reset_index(drop=True)\n",
    "\n",
    "                    # Get metadata\n",
    "                    positives_mixed, ratio_mixed, compounds_mixed, activities_mixed = set_variables_quantitative(ASSAY_DATA_MIXED)\n",
    "\n",
    "                    # Store dataset\n",
    "                    ASSAY_DATA_MIXED.to_csv(os.path.join(OUTPUT, pathogen_code, 'datasets', f\"{dataset_name}_mx_{expert_cutoff}.csv.gz\"), index=False)\n",
    "\n",
    "            # Store data range\n",
    "            DATASETS.append([assay_chembl_id, activity_type, unit, target_type, target_type_curated_extra, activities, nan_values, cpds, direction, act_flag, \n",
    "                                inact_flag, dataset_type, expert_cutoff, positives_quantitative, ratio_quantitative, compounds_quantitative, positives_qualitative, \n",
    "                                ratio_qualitative, compounds_qualitative, overlap_mixed, positives_mixed, ratio_mixed, compounds_mixed])\n",
    "            \n",
    "    # Store assay data type and range\n",
    "    ASSAY_DATA_INFO.append([assay_chembl_id, activity_type, unit, target_type, target_type_curated_extra, activities, cpds, dataset_type, equal, higher, lower, min_, p1, p25, p50, p75, p99, max_])\n",
    "            \n",
    "    if dataset_type == 'mixed' and assay_chembl_id == 'CHEMBL2350721':\n",
    "        break\n",
    "\n",
    "        \n",
    "# Store data results\n",
    "DATASETS = pd.DataFrame(DATASETS, columns=[\"assay_id\", \"activity_type\", \"unit\", \"target_type\", \"target_type_curated_extra\", \"activities\", \"nan_values\", \"cpds\", \"direction\", \n",
    "                                                    'act_flag', 'inact_flag', \"dataset_type\", \"expert_cutoff\", \"pos_qt\", \"ratio_qt\", \"cpds_qt\", \"pos_ql\", \"ratio_ql\", \"cpds_ql\", \n",
    "                                                    \"overlap_mx\", \"pos_mx\", \"ratio_mx\", \"cpds_mx\"])\n",
    "\n",
    "ASSAY_DATA_INFO = pd.DataFrame(ASSAY_DATA_INFO, columns=[\"assay_id\", \"activity_type\", \"unit\", \"target_type\", \"target_type_curated_extra\", \"activities\", \"cpds\", \"dataset_type\", \n",
    "                                                         \"equal\", \"higher\", \"lower\", \"min_\", \"p1\", \"p25\", \"p50\", \"p75\", \"p99\", \"max_\"])\n",
    "\n",
    "DATASETS.to_csv(os.path.join(OUTPUT, pathogen_code, 'datasets.csv'), index=False)\n",
    "ASSAY_DATA_INFO.to_csv(os.path.join(OUTPUT, pathogen_code, 'assay_data_info.csv'), index=False)\n",
    "\n",
    "# Zip and remove datasets\n",
    "datasets_dir = os.path.join(OUTPUT, pathogen_code, \"datasets\")\n",
    "qt, ql, mx = zip_and_remove(datasets_dir)\n",
    "\n",
    "# Counting datasets and assays data types\n",
    "counter_datasets = dict(Counter(DATASETS['dataset_type']))\n",
    "counter_assays = dict(Counter(ASSAY_DATA_INFO['dataset_type']))\n",
    "# assert len(ASSAYS_CLEANED) == int(counter['quantitative'] / 3 + counter['qualitative'] + counter['none'] + counter['mixed'] / 3)\n",
    "\n",
    "print(f\"Total number of assays: {len(ASSAY_DATA_INFO)}\")\n",
    "print(f\"Types of assays: {counter_assays}\")\n",
    "print(f\"Total number of datasets: {len(DATASETS)}\")\n",
    "print(f\"Types of datasets: {counter_datasets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462117b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
