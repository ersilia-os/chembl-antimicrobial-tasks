{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633e40c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import gzip\n",
    "import sys\n",
    "import os\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.width\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ad8111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_expert_cutoffs(CONFIGPATH):\n",
    "    \"\"\"\n",
    "    Load expert cutoffs from the manual curation CSV and return them as a dictionary.\n",
    "\n",
    "    The CSV is expected at:\n",
    "        {CONFIGPATH}/expert_cutoffs.csv\n",
    "\n",
    "    The returned dictionary maps:\n",
    "        (activity_type, unit, target_type, pathogen_code) -> expert_cutoff\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    CONFIGPATH : str\n",
    "        Path to the config folder.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary of expert cutoffs keyed by\n",
    "        (activity_type, unit, target_type, pathogen_code).\n",
    "    \"\"\"\n",
    "    # Load expert cut-offs\n",
    "    EXPERT_CUTOFFS = pd.read_csv(os.path.join(CONFIGPATH, \"expert_cutoffs.csv\"))\n",
    "\n",
    "    EXPERT_CUTOFFS = {\n",
    "        (a, b, c, d): [float(k) for k in e.split(\";\")]\n",
    "        for a, b, c, d, e in EXPERT_CUTOFFS[\n",
    "            [\"activity_type\", \"unit\", \"target_type\", \"pathogen_code\", \"expert_cutoff\"]\n",
    "        ].values\n",
    "    }\n",
    "\n",
    "    return EXPERT_CUTOFFS\n",
    "\n",
    "def get_filtered_data(individual_LM_LABEL, assay_id, activity_type, unit):\n",
    "    if type(unit) == str:\n",
    "        df = individual_LM_LABEL[(individual_LM_LABEL['assay_id'] == assay_id) & \n",
    "                                 (individual_LM_LABEL['activity_type'] == activity_type) & \n",
    "                                 (individual_LM_LABEL['unit'] == unit)].reset_index(drop=True)\n",
    "    else:\n",
    "        df = individual_LM_LABEL[(individual_LM_LABEL['assay_id'] == assay_id) & \n",
    "                                 (individual_LM_LABEL['activity_type'] == activity_type) & \n",
    "                                 (individual_LM_LABEL['unit'].isna())].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def load_data_from_zip(zip_path, filename):\n",
    "    \"\"\"Load a gzipped CSV file from a ZIP archive into a pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    zip_path : str\n",
    "        Path to the ZIP archive.\n",
    "    filename : str\n",
    "        Name of the gzipped CSV file inside the ZIP.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Loaded data.\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zip_path) as z:\n",
    "        with z.open(filename) as raw:\n",
    "            with gzip.open(raw, mode=\"rt\") as f:\n",
    "                df = pd.read_csv(f)\n",
    "    return df\n",
    "\n",
    "def get_assay_data(ChEMBL_pathogen, assay_chembl_id, activity_type, unit, cols):\n",
    "    \"\"\"\n",
    "    Extract assay activity data for a given assay_chembl_id, activity_type, and unit.\n",
    "\n",
    "    If `unit` is a string, the function filters rows where `unit` matches exactly.\n",
    "    Otherwise, it filters rows where `unit` is missing (NaN).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ChEMBL_pathogen : pandas.DataFrame\n",
    "        DataFrame containing ChEMBL pathogen activity records.\n",
    "    assay_chembl_id : str\n",
    "        Assay ChEMBL ID to filter on.\n",
    "    activity_type : str\n",
    "        Activity type to filter on (e.g., IC50, MIC).\n",
    "    unit : str or None\n",
    "        Unit to filter on; if not a string, NaN units are selected.\n",
    "    cols : list\n",
    "        List of columns to return.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Filtered assay activity data with only the requested columns.\n",
    "    \"\"\"\n",
    "    if type(unit) == str:\n",
    "        ASSAY_DATA = ChEMBL_pathogen[\n",
    "            (ChEMBL_pathogen['assay_chembl_id'] == assay_chembl_id) &\n",
    "            (ChEMBL_pathogen['activity_type'] == activity_type) &\n",
    "            (ChEMBL_pathogen['unit'] == unit)\n",
    "        ].reset_index(drop=True)[cols]\n",
    "    else:\n",
    "        ASSAY_DATA = ChEMBL_pathogen[\n",
    "            (ChEMBL_pathogen['assay_chembl_id'] == assay_chembl_id) &\n",
    "            (ChEMBL_pathogen['activity_type'] == activity_type) &\n",
    "            (ChEMBL_pathogen['unit'].isna())\n",
    "        ].reset_index(drop=True)[cols]\n",
    "\n",
    "    return ASSAY_DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ad7918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define root directory\n",
    "# root = os.path.dirname(os.path.abspath(__file__))\n",
    "root = \".\"\n",
    "sys.path.append(os.path.join(root, \"..\", \"src\"))\n",
    "from default import DATAPATH, CONFIGPATH\n",
    "\n",
    "# Load pathogen info\n",
    "# pathogen_code = sys.argv[1]\n",
    "pathogen_code = 'mtuberculosis'\n",
    "df = pd.read_csv(os.path.join(CONFIGPATH, 'pathogens.csv'))\n",
    "row = df.loc[df[\"code\"].eq(pathogen_code)]\n",
    "if row.empty: \n",
    "    raise SystemExit(f\"Unknown code: {pathogen_code}\")\n",
    "pathogen = row.iloc[0][\"pathogen\"]\n",
    "\n",
    "# Define output directory\n",
    "OUTPUT = os.path.join(root, \"..\", \"output\")\n",
    "\n",
    "# Load ChEMBL data for pathogen\n",
    "ChEMBL_pathogen = pd.read_csv(os.path.join(OUTPUT, pathogen_code, f\"{pathogen_code}_ChEMBL_cleaned_data.csv.gz\"), low_memory=False)\n",
    "\n",
    "# Get assay to index mapping\n",
    "assay_to_idx = defaultdict(list)\n",
    "for i, assay_id in enumerate(ChEMBL_pathogen[\"assay_chembl_id\"].to_numpy()):\n",
    "    assay_to_idx[assay_id].append(i)\n",
    "\n",
    "# Load expert cut-offs\n",
    "EXPERT_CUTOFFS = load_expert_cutoffs(CONFIGPATH)\n",
    "\n",
    "# Load individual LM data\n",
    "individual_LM = pd.read_csv(os.path.join(OUTPUT, pathogen_code, \"individual_LM.csv\"))\n",
    "\n",
    "# Dict mapping assay_id, activity_type and unit to a set of compound ChEMBL IDs\n",
    "ASSAY_TO_COMPOUNDS = defaultdict(set)\n",
    "for assay_id, activity_type, unit, compound_chembl_id in ChEMBL_pathogen[[\"assay_chembl_id\", \"activity_type\", \"unit\", \"compound_chembl_id\"]].values:\n",
    "    ASSAY_TO_COMPOUNDS[(assay_id, activity_type, unit)].add(compound_chembl_id)\n",
    "del ChEMBL_pathogen\n",
    "\n",
    "# Get all compounds for pathogen\n",
    "compounds = pd.read_csv(os.path.join(OUTPUT, pathogen_code, \"compound_counts.csv.gz\"))\n",
    "compounds = set(compounds['compound_chembl_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5df34480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: from 67.8% to 66.8%\n",
      "B: from 5.4% to 2.9%\n",
      "Overall: from 69.3% to 69.3%\n",
      "Number of selected datasets (A): 12\n",
      "Number of selected datasets (B): 15\n",
      "Number of datasets with middle cut-off: 18/27\n"
     ]
    }
   ],
   "source": [
    "LABELS = ['A', 'B']\n",
    "COLS_TO_KEEP = [\"dataset_type\", \"pos_qt\", \"ratio_qt\", \"cpds_qt\", \"pos_ql\", \"ratio_ql\", \"cpds_ql\", 'overlap_mx', \"pos_mx\", \"ratio_mx\", \"cpds_mx\"]\n",
    "KEYS = [\"assay_id\", \"activity_type\", \"unit\", \"target_type_curated_extra\"]\n",
    "\n",
    "SELECTED = []\n",
    "ORIGINAL_COMPOUNDS = {i: set() for i in LABELS}\n",
    "SELECTED_COMPOUNDS = {i: set() for i in LABELS}\n",
    "\n",
    "for LABEL in LABELS:\n",
    "\n",
    "    # Filter assays considered in label\n",
    "    individual_LM_LABEL = individual_LM[individual_LM['label'] == LABEL]\n",
    "    assays_LABEL = set([tuple(i) for i in individual_LM_LABEL[KEYS].values])\n",
    "\n",
    "    for assay in assays_LABEL:\n",
    "\n",
    "        # Get assay info\n",
    "        assay_id, activity_type, unit, target_type = assay\n",
    "        key = (assay_id, activity_type, unit)\n",
    "        ORIGINAL_COMPOUNDS[LABEL].update(ASSAY_TO_COMPOUNDS[key])\n",
    "\n",
    "        # If not selected previously\n",
    "        if key not in set([tuple([sel[1], sel[2], sel[3]]) for sel in SELECTED]):\n",
    "\n",
    "            # Define mid cutoff (available by definition)\n",
    "            mid_cutoff = EXPERT_CUTOFFS[(activity_type, unit, target_type, pathogen_code)][1]\n",
    "\n",
    "            # Filter results for that assay\n",
    "            df = get_filtered_data(individual_LM_LABEL, assay_id, activity_type, unit)\n",
    "\n",
    "            # Sort by average AUROC\n",
    "            df = df.sort_values(\"avg\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "            # Get best auroc and best cutoff\n",
    "            best_auroc = df[\"avg\"].tolist()[0]\n",
    "            best_cutoff = df[\"expert_cutoff\"].tolist()[0]\n",
    "\n",
    "            # Get mid auroc (if available)\n",
    "            if mid_cutoff in df['expert_cutoff'].tolist():\n",
    "                mid_auroc = df[df['expert_cutoff'] == mid_cutoff][\"avg\"].tolist()[0]\n",
    "            else:\n",
    "                mid_auroc = np.nan\n",
    "\n",
    "            # If the best dataset is modelable\n",
    "            if best_auroc > 0.7:\n",
    "\n",
    "                # If difference is quite high, keep best\n",
    "                if np.isnan(mid_auroc) or (best_auroc - mid_auroc) > 0.1:\n",
    "                    INFO = df[COLS_TO_KEEP].values.tolist()[0]\n",
    "                    SELECTED.append([LABEL, assay_id, activity_type, unit, best_cutoff, best_auroc, False] + INFO)\n",
    "                    SELECTED_COMPOUNDS[LABEL].update(ASSAY_TO_COMPOUNDS[key])\n",
    "\n",
    "                # Otherwise, keep mid\n",
    "                else:\n",
    "                    INFO = df[df['expert_cutoff'] == mid_cutoff][COLS_TO_KEEP].values.tolist()[0]\n",
    "                    SELECTED.append([LABEL, assay_id, activity_type, unit, mid_cutoff, mid_auroc, True] + INFO)\n",
    "                    SELECTED_COMPOUNDS[LABEL].update(ASSAY_TO_COMPOUNDS[key])\n",
    "  \n",
    "# To pandas dataframe\n",
    "SELECTED = pd.DataFrame(SELECTED, columns=['label', 'assay_id', 'activity_type', 'unit', 'cutoff', 'AUROC', \"is_mid_cutoff\", \"dataset_type\", \n",
    "                                           \"pos_qt\", \"ratio_qt\", \"cpds_qt\", \"pos_ql\", \"ratio_ql\", \"cpds_ql\", 'overlap_mx', \"pos_mx\", \"ratio_mx\", \"cpds_mx\"])\n",
    "\n",
    "# Save \n",
    "SELECTED.to_csv(os.path.join(OUTPUT, pathogen_code, \"individual_selected_LM.csv\"), index=False)\n",
    "\n",
    "# Check that only one dataset per assay is selected\n",
    "assert len(set([tuple(i) for i in SELECTED[[\"assay_id\", \"activity_type\", \"unit\"]].values])) == len(SELECTED)\n",
    "\n",
    "print(f\"A: from {round(100 * len(ORIGINAL_COMPOUNDS['A']) / len(compounds), 1)}% to {round(100 * len(SELECTED_COMPOUNDS['A']) / len(compounds), 1)}%\")\n",
    "print(f\"B: from {round(100 * len(ORIGINAL_COMPOUNDS['B']) / len(compounds), 1)}% to {round(100 * len(SELECTED_COMPOUNDS['B']) / len(compounds), 1)}%\")\n",
    "print(f\"Overall: from {round(100 * len(ORIGINAL_COMPOUNDS['A'].union(ORIGINAL_COMPOUNDS['B'])) / len(compounds), 1)}% to {round(100 * len(SELECTED_COMPOUNDS['A'].union(SELECTED_COMPOUNDS['B'])) / len(compounds), 1)}%\")\n",
    "print(f\"Number of selected datasets (A): {len(SELECTED[SELECTED['label'] == 'A'])}\")\n",
    "print(f\"Number of selected datasets (B): {len(SELECTED[SELECTED['label'] == 'B'])}\")\n",
    "print(f\"Number of datasets with middle cut-off: {len(SELECTED[SELECTED['is_mid_cutoff'] == True])}/{len(SELECTED)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
