{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03708bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ChEMBL cleaned data for abaumannii...\n",
      "Number of activities for abaumannii: 42839\n",
      "Number of compounds for abaumannii: 32458\n",
      "Number of cleaned assays: 3007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 143.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def adjust_relation(ASSAY_DATA: pd.DataFrame, DIRECTION: int, CUT: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adjust relations in an assay DataFrame according to the biological direction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pd.DataFrame\n",
    "        Must contain the columns 'relation' and 'value'.\n",
    "    DIRECTION : int\n",
    "        +1 → higher = more active (e.g. % inhibition)\n",
    "        -1 → lower = more active (e.g. IC50, MIC)\n",
    "    CUT : float\n",
    "        Extreme value used to replace censored measurements\n",
    "        on the wrong side of the direction (min or max)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Copy of ASSAY_DATA with adjusted relation and value.\n",
    "    \"\"\"\n",
    "\n",
    "    df = ASSAY_DATA.copy()\n",
    "    rel = df[\"relation\"].astype(str)\n",
    "\n",
    "    if DIRECTION == +1:\n",
    "\n",
    "        # Higher = more active\n",
    "        mask_gt = rel == \">\"  # greater than\n",
    "        mask_lt = rel == \"<\"  # lower than\n",
    "\n",
    "        df.loc[mask_gt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_lt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_lt, \"value\"] = CUT\n",
    "\n",
    "    elif DIRECTION == -1:\n",
    "\n",
    "        # Lower = more active\n",
    "        mask_lt = rel == \"<\"  # lower than\n",
    "        mask_gt = rel == \">\"  # greater than\n",
    "\n",
    "        df.loc[mask_lt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_gt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_gt, \"value\"] = CUT\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise ValueError(f\"Invalid DIRECTION={DIRECTION}. Expected +1 or -1.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def disambiguate_compounds(ASSAY_DATA: pd.DataFrame, DIRECTION: int) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Select a single measurement per compound according to the biological direction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pd.DataFrame\n",
    "        Must contain the columns 'compound_chembl_id' and 'value'.\n",
    "        Assumes all relations have already been adjusted.\n",
    "    DIRECTION : int\n",
    "        +1 → higher = more active (e.g. % inhibition)\n",
    "        -1 → lower = more active (e.g. IC50, MIC)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A copy of ASSAY_DATA in which duplicated compounds \n",
    "        ('compound_chembl_id') are removed, keeping only the \n",
    "        most active measurement per compound (highest or lowest \n",
    "        depending on DIRECTION).\n",
    "    \"\"\"\n",
    "\n",
    "    if DIRECTION not in [1, -1]:\n",
    "        raise ValueError(\"DIRECTION must be +1 (higher = more active) or -1 (lower = more active).\")\n",
    "        \n",
    "    df = ASSAY_DATA.copy()\n",
    "\n",
    "    # Choose best measurement based on direction\n",
    "    if DIRECTION == -1:\n",
    "        # Lower = more active → keep minimum\n",
    "        df_sorted = df.sort_values(by=\"value\", ascending=True)\n",
    "    elif DIRECTION == 1:\n",
    "        # Higher = more active → keep maximum\n",
    "        df_sorted = df.sort_values(by=\"value\", ascending=False)\n",
    "\n",
    "    # Keep the best row per compound_chembl_id\n",
    "    df_best = df_sorted.drop_duplicates(subset=\"compound_chembl_id\", keep=\"first\")\n",
    "\n",
    "    return df_best.reset_index(drop=True)\n",
    "\n",
    "def get_pathogen_code(pathogen):\n",
    "    return str(pathogen.split()[0][0] + pathogen.split()[1]).lower() if len(pathogen.split()) > 1 else pathogen.lower()\n",
    "\n",
    "def add_target_type_curated(ASSAYS_CLEANED, PATH_TO_PARAMETERS):\n",
    "    \"\"\"\n",
    "    Add a `target_type_curated` column to ASSAYS_CLEANED by reading parameter JSON files.\n",
    "\n",
    "    For each row in ASSAYS_CLEANED, a JSON file is opened using the pattern:\n",
    "        \"{assay_id}_{activity_type}_{unit}_parameters.json\"\n",
    "\n",
    "    The value stored under the key `\"target_type_curated\"` is extracted and appended\n",
    "    to a list, which is then assigned as a new column in the dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAYS_CLEANED : pandas.DataFrame\n",
    "        DataFrame containing at least the columns: `assay_id`, `activity_type`, `unit`.\n",
    "    PATH_TO_PARAMETERS : str\n",
    "        Path to the directory containing the JSON parameter files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The same dataframe with an added `target_type_curated` column.\n",
    "    \"\"\"\n",
    "    TARGET_TYPE_CURATED = []\n",
    "\n",
    "    # Iterating over assays\n",
    "    for assay_id, activity_type, unit in ASSAYS_CLEANED[['assay_id', 'activity_type', 'unit']].values:\n",
    "\n",
    "        # Prepare filename\n",
    "        filename = \"_\".join([str(assay_id), str(activity_type), str(unit), 'parameters']) + \".json\"\n",
    "        \n",
    "        # Read JSON file\n",
    "        with open(os.path.join(PATH_TO_PARAMETERS, filename), \"r\") as file:\n",
    "            par = json.load(file)\n",
    "\n",
    "        # Store results\n",
    "        TARGET_TYPE_CURATED.append(par['target_type_curated'])\n",
    "\n",
    "    # Complete table\n",
    "    ASSAYS_CLEANED['target_type_curated'] = TARGET_TYPE_CURATED\n",
    "\n",
    "    return ASSAYS_CLEANED\n",
    "\n",
    "def load_expert_cutoffs(root):\n",
    "    \"\"\"\n",
    "    Load expert cutoffs from the manual curation CSV and return them as a dictionary.\n",
    "\n",
    "    The CSV is expected at:\n",
    "        {root}/../config/manual_curation/expert_cutoffs.csv\n",
    "\n",
    "    The returned dictionary maps:\n",
    "        (activity_type, unit, target_type, pathogen_code) -> expert_cutoff\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root : str\n",
    "        Base path used to locate the config folder.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary of expert cutoffs keyed by\n",
    "        (activity_type, unit, target_type, pathogen_code).\n",
    "    \"\"\"\n",
    "    # Load expert cut-offs\n",
    "    EXPERT_CUTOFFS = pd.read_csv(\n",
    "        os.path.join(root, \"..\", \"config\", \"manual_curation\", \"expert_cutoffs.csv\")\n",
    "    )\n",
    "\n",
    "    EXPERT_CUTOFFS = {\n",
    "        (a, b, c, d): e\n",
    "        for a, b, c, d, e in EXPERT_CUTOFFS[\n",
    "            [\"activity_type\", \"unit\", \"target_type\", \"pathogen_code\", \"expert_cutoff\"]\n",
    "        ].values\n",
    "    }\n",
    "\n",
    "    return EXPERT_CUTOFFS\n",
    "\n",
    "def get_assay_data(ChEMBL_pathogen, assay_chembl_id, activity_type, unit, cols):\n",
    "    \"\"\"\n",
    "    Extract assay activity data for a given assay_chembl_id, activity_type, and unit.\n",
    "\n",
    "    If `unit` is a string, the function filters rows where `unit` matches exactly.\n",
    "    Otherwise, it filters rows where `unit` is missing (NaN).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ChEMBL_pathogen : pandas.DataFrame\n",
    "        DataFrame containing ChEMBL pathogen activity records.\n",
    "    assay_chembl_id : str\n",
    "        Assay ChEMBL ID to filter on.\n",
    "    activity_type : str\n",
    "        Activity type to filter on (e.g., IC50, MIC).\n",
    "    unit : str or None\n",
    "        Unit to filter on; if not a string, NaN units are selected.\n",
    "    cols : list\n",
    "        List of columns to return.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Filtered assay activity data with only the requested columns.\n",
    "    \"\"\"\n",
    "    if type(unit) == str:\n",
    "        ASSAY_DATA = ChEMBL_pathogen[\n",
    "            (ChEMBL_pathogen['assay_chembl_id'] == assay_chembl_id) &\n",
    "            (ChEMBL_pathogen['activity_type'] == activity_type) &\n",
    "            (ChEMBL_pathogen['unit'] == unit)\n",
    "        ].reset_index(drop=True)[cols]\n",
    "    else:\n",
    "        ASSAY_DATA = ChEMBL_pathogen[\n",
    "            (ChEMBL_pathogen['assay_chembl_id'] == assay_chembl_id) &\n",
    "            (ChEMBL_pathogen['activity_type'] == activity_type) &\n",
    "            (ChEMBL_pathogen['unit'].isna())\n",
    "        ].reset_index(drop=True)[cols]\n",
    "\n",
    "    return ASSAY_DATA\n",
    "\n",
    "def get_cut_value(ASSAY_DATA, direction):\n",
    "    \"\"\"\n",
    "    Get a cutoff value from ASSAY_DATA to adjust relations based on direction.\n",
    "\n",
    "    If direction == 1, returns the minimum value in ASSAY_DATA['value'].\n",
    "    If direction == -1, returns the maximum value in ASSAY_DATA['value'].\n",
    "    Otherwise, returns np.nan.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pandas.DataFrame\n",
    "        DataFrame containing a 'value' column with numeric assay values.\n",
    "    direction : int\n",
    "        Direction indicator:\n",
    "        - 1  -> use minimum value\n",
    "        - -1 -> use maximum value\n",
    "        - else -> np.nan\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Cutoff value computed from the 'value' column or np.nan.\n",
    "    \"\"\"\n",
    "    if direction == 1:\n",
    "        CUT = min(ASSAY_DATA['value'])\n",
    "    elif direction == -1:\n",
    "        CUT = max(ASSAY_DATA['value'])\n",
    "    else:\n",
    "        CUT = np.nan\n",
    "\n",
    "    return CUT\n",
    "\n",
    "def count_relations(ASSAY_DATA):\n",
    "    \"\"\"\n",
    "    Count relation operators in ASSAY_DATA['relation'].\n",
    "\n",
    "    Counts how many times each of the following appears:\n",
    "        \"=\" , \"<\" , \">\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pandas.DataFrame\n",
    "        DataFrame containing a 'relation' column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (equal, lower, higher) counts corresponding to \"=\", \"<\", \">\".\n",
    "    \"\"\"\n",
    "    counter_relations = Counter(ASSAY_DATA['relation'].tolist())\n",
    "    equal = counter_relations[\"=\"]\n",
    "    lower = counter_relations[\"<\"]\n",
    "    higher = counter_relations[\">\"]\n",
    "\n",
    "    return equal, lower, higher\n",
    "\n",
    "def get_assay_data_quantitative(ASSAY_DATA):\n",
    "    \"\"\"\n",
    "    Return only rows in ASSAY_DATA with non-missing quantitative values.\n",
    "\n",
    "    Filters ASSAY_DATA to keep rows where `value` is not NaN, and resets the index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pandas.DataFrame\n",
    "        DataFrame containing a 'value' column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Filtered dataframe containing only rows with non-null `value`.\n",
    "    \"\"\"\n",
    "    ASSAY_DATA_QUANTITATIVE = ASSAY_DATA[ASSAY_DATA['value'].isna() == False].reset_index(drop=True)\n",
    "    return ASSAY_DATA_QUANTITATIVE\n",
    "\n",
    "# Define root directory\n",
    "# root = os.path.dirname(os.path.abspath(__file__))\n",
    "root = \".\"\n",
    "\n",
    "# List of pathogens to process\n",
    "pathogens = [\"Acinetobacter baumannii\", \"Candida albicans\", \"Campylobacter\", \"Escherichia coli\", \"Enterococcus faecium\", \"Enterobacter\",\n",
    "             \"Helicobacter pylori\", \"Klebsiella pneumoniae\", \"Mycobacterium tuberculosis\", \"Neisseria gonorrhoeae\", \"Pseudomonas aeruginosa\",\n",
    "             \"Plasmodium falciparum\", \"Staphylococcus aureus\", \"Schistosoma mansoni\", \"Streptococcus pneumoniae\"]\n",
    "pathogens = [\"Acinetobacter baumannii\", \"Mycobacterium tuberculosis\", \"Klebsiella pneumoniae\"]\n",
    "\n",
    "\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT = os.path.join(root, \"..\", \"output\")\n",
    "\n",
    "# For each pathogen\n",
    "for pathogen in pathogens:\n",
    "\n",
    "    # Get pathogen code\n",
    "    pathogen_code = get_pathogen_code(pathogen)\n",
    "\n",
    "    # Load cleaned assays\n",
    "    ASSAYS_CLEANED = pd.read_csv(os.path.join(root, \"..\", \"output\", pathogen_code, \"assays_cleaned.csv\"))\n",
    "\n",
    "    # Define PATH to parameters\n",
    "    PATH_TO_PARAMETERS = os.path.join(root, \"..\", \"output\", pathogen_code, 'parameters')\n",
    "\n",
    "    # Get curated target type\n",
    "    ASSAYS_CLEANED = add_target_type_curated(ASSAYS_CLEANED, PATH_TO_PARAMETERS)\n",
    "\n",
    "    # Loading pathogen data\n",
    "    os.makedirs(os.path.join(OUTPUT, pathogen_code, 'datasets'), exist_ok=True)\n",
    "    print(f\"Loading ChEMBL cleaned data for {pathogen_code}...\")\n",
    "    ChEMBL_pathogen = pd.read_csv(os.path.join(OUTPUT, pathogen_code, f\"{pathogen_code}_ChEMBL_cleaned_data.csv.gz\"), low_memory=False)\n",
    "    print(f\"Number of activities for {pathogen_code}: {len(ChEMBL_pathogen)}\")\n",
    "    print(f\"Number of compounds for {pathogen_code}: {len(set(ChEMBL_pathogen['compound_chembl_id']))}\")\n",
    "    print(f\"Number of cleaned assays: {len(ASSAYS_CLEANED)}\")\n",
    "\n",
    "    # Load expert cut-offs\n",
    "    EXPERT_CUTOFFS = load_expert_cutoffs(root)\n",
    "\n",
    "    # Define data ranges\n",
    "    DATA_RANGES = []\n",
    "\n",
    "    for assay_chembl_id, activity_type, unit, target_type, target_type_curated, activities, cpds, direction in tqdm(ASSAYS_CLEANED[['assay_id', 'activity_type', 'unit', 'target_type',\n",
    "                                                                                                            'target_type_curated', 'activities', 'cpds', 'direction']].values[:5]):\n",
    "\n",
    "        # Filtering [assay, activity_type, unit] data\n",
    "        cols = ['compound_chembl_id', 'canonical_smiles', 'activity_type', 'value', 'relation', 'unit', 'activity_comment', 'standard_text']\n",
    "        ASSAY_DATA = get_assay_data(ChEMBL_pathogen, assay_chembl_id, activity_type, unit, cols)\n",
    "        \n",
    "        # Count relations\n",
    "        equal, lower, higher = count_relations(ASSAY_DATA)\n",
    "\n",
    "        # Get value to adjust relations\n",
    "        CUT = get_cut_value(ASSAY_DATA, direction)\n",
    "\n",
    "        # Get expert cut-off if it exists\n",
    "        key = (activity_type, unit, target_type_curated, pathogen_code)\n",
    "        expert_cutoff = EXPERT_CUTOFFS[key] if key in EXPERT_CUTOFFS else np.nan\n",
    "\n",
    "        # if direction in [+1, -1]:\n",
    "\n",
    "        #     # Adjust relation\n",
    "        #     ASSAY_DATA = adjust_relation(ASSAY_DATA, direction, CUT)\n",
    "\n",
    "        #     # Disambiguate duplicated compounds and returns 'sorted' data (depending on direction)\n",
    "        #     # Numerical values are prioritized over nans\n",
    "        #     ASSAY_DATA = disambiguate_compounds(ASSAY_DATA, direction)\n",
    "\n",
    "        #     # Remove nans\n",
    "        #     assay_activities = [i for i in ASSAY_DATA['value'].tolist() if np.isnan(i) == False]\n",
    "\n",
    "        #     # Fully qualitative assay\n",
    "        #     if len(assay_activities) == 0:\n",
    "        #         assay_activities = [np.nan]\n",
    "        #         dataset_type = 'qualitative'\n",
    "        #     elif len(assay_activities) < len(ASSAY_DATA):\n",
    "        #         dataset_type = 'mixed'\n",
    "        #     else:\n",
    "        #         dataset_type = 'quantitative'\n",
    "\n",
    "        #     # Binarization with expert cut-off\n",
    "        #     if np.isnan(expert_cutoff) == False:\n",
    "        #         if direction == +1:\n",
    "        #             ASSAY_DATA[\"bin_quantitative\"] = (ASSAY_DATA[\"value\"] >= expert_cutoff).astype(int)\n",
    "        #         else:\n",
    "        #             ASSAY_DATA[\"bin_quantitative\"] = (ASSAY_DATA[\"value\"] <= expert_cutoff).astype(int)\n",
    "        #         positives = Counter(ASSAY_DATA['bin_quantitative'].tolist())[1]\n",
    "        #         ratio = round(positives / len(ASSAY_DATA), 5)\n",
    "        #     else:\n",
    "        #         # Dataset could not be binarized using values due to missing expert cut-off\n",
    "        #         ASSAY_DATA['bin_quantitative'] = [np.nan] * len(ASSAY_DATA)\n",
    "        #         positives = np.nan\n",
    "        #         ratio = np.nan\n",
    "\n",
    "        # else:\n",
    "\n",
    "        #     # Qualitative assay\n",
    "        #     dataset_type = 'qualitative'    \n",
    "\n",
    "        #     # Not binarizing a null-direction assay\n",
    "        #     ASSAY_DATA['bin_quantitative'] = [np.nan] * len(ASSAY_DATA)\n",
    "        #     positives = np.nan\n",
    "        #     ratio = np.nan\n",
    "        #     assay_activities = [np.nan]\n",
    "\n",
    "\n",
    "        # # Getting qualitative bin\n",
    "        # ASSAY_DATA['bin_qualitative'] = [np.nan for i in range(len(ASSAY_DATA))]\n",
    "        # cond_nan = (ASSAY_DATA['activity_comment'] == 0) & (ASSAY_DATA['standard_text'] == 0)\n",
    "        # cond_pos = (ASSAY_DATA['activity_comment'] == 1) | (ASSAY_DATA['standard_text'] == 1)\n",
    "        # cond_neg = (ASSAY_DATA['activity_comment'] == -1) | (ASSAY_DATA['standard_text'] == -1)\n",
    "        # conflict = cond_pos & cond_neg\n",
    "        # if conflict.any():\n",
    "        #     raise ValueError(\n",
    "        #         \"Conflicting labels (contains both 1 and -1):\\n\"\n",
    "        #         + ASSAY_DATA.loc[conflict, [\"activity_comment\", \"standard_text\"]].head(20).to_string())\n",
    "        # ASSAY_DATA.loc[cond_pos, \"bin_qualitative\"] = 1\n",
    "        # ASSAY_DATA.loc[cond_neg, \"bin_qualitative\"] = 0\n",
    "\n",
    "        # # Positives and negatives qualitative\n",
    "        # positives_qual = Counter(ASSAY_DATA['bin_qualitative'].tolist())[1]\n",
    "        # negatives_qual = Counter(ASSAY_DATA['bin_qualitative'].tolist())[0]\n",
    "\n",
    "        # # Calculate data\n",
    "        # min_ = round(np.min(assay_activities), 3)\n",
    "        # p1 = round(np.percentile(assay_activities, 1), 3)\n",
    "        # p25 = round(np.percentile(assay_activities, 25), 3)\n",
    "        # p50 = round(np.percentile(assay_activities, 50), 3)\n",
    "        # p75 = round(np.percentile(assay_activities, 75), 3)\n",
    "        # p99 = round(np.percentile(assay_activities, 99), 3)\n",
    "        # max_ = round(np.max(assay_activities), 3)\n",
    "\n",
    "        # # Store data range\n",
    "        # DATA_RANGES.append([assay_chembl_id, activity_type, unit, target_type, target_type_curated, activities, cpds, direction, equal, higher, \n",
    "        #                     lower, min_, p1, p25, p50, p75, p99, max_, expert_cutoff, positives, ratio, dataset_type, positives_qual, negatives_qual])\n",
    "\n",
    "        # # Save data\n",
    "        # if cpds >= 100:\n",
    "        #     ASSAY_DATA.to_csv(os.path.join(OUTPUT, pathogen_code, 'datasets', f\"{assay_chembl_id}_{activity_type}_{str(unit).replace('/', 'FwdS')}.csv.gz\"), index=False)\n",
    "\n",
    "        #\n",
    "\n",
    "    DATA_RANGES = pd.DataFrame(DATA_RANGES, columns=[\"assay_id\", \"activity_type\", \"unit\", \"target_type\", \"target_type_curated\", \"activities\", \"cpds\", \"direction\", \n",
    "                                                    \"equal\", \"higher\", \"lower\", \"min_\", \"p1\", \"p25\", \"p50\", \"p75\", \"p99\", \"max_\", 'expert_cutoff', 'positives_quant', 'ratio_quant', \n",
    "                                                    'dataset_type', 'positives_qual', 'negatives_qual'])\n",
    "    DATA_RANGES.to_csv(os.path.join(OUTPUT, pathogen_code, 'assays_data_ranges.csv'), index=False)\n",
    "\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbf9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantitative view\n",
    "ASSAY_DATA_QUANTITATIVE = ASSAY_DATA[ASSAY_DATA['value'].isna() == False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative view\n",
    "cond_nan = (ASSAY_DATA['activity_comment'] == 0) & (ASSAY_DATA['standard_text'] == 0)\n",
    "cond_pos = (ASSAY_DATA['activity_comment'] == 1) | (ASSAY_DATA['standard_text'] == 1)\n",
    "cond_neg = (ASSAY_DATA['activity_comment'] == -1) | (ASSAY_DATA['standard_text'] == -1)\n",
    "conflict = cond_pos & cond_neg  # If activity comment is 1/-1 and standard_text is -1/0\n",
    "if conflict.any():\n",
    "    raise ValueError(\n",
    "        \"Conflicting labels (contains both 1 and -1):\\n\"\n",
    "        + ASSAY_DATA.loc[conflict, [\"activity_comment\", \"standard_text\"]].head(20).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc61c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
