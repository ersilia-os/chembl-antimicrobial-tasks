{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ed46bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".dataframe td, .dataframe th {\n",
       "    white-space: nowrap !important;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from IPython.display import display, HTML\n",
    "from scipy.stats import spearmanr\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import random\n",
    "import gzip\n",
    "import sys\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "pd.set_option(\"display.width\", 2000)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    ".dataframe td, .dataframe th {\n",
    "    white-space: nowrap !important;\n",
    "}\n",
    "</style>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4166f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_set_compounds(compounds):\n",
    "    \"\"\"\n",
    "    Return a reference set of ChEMBL compound IDs from a compounds DataFrame.\n",
    "\n",
    "    If the DataFrame has more than 10,000 rows, this returns a reduced reference\n",
    "    set consisting of the first 5,000 and the last 5,000 `compound_chembl_id`\n",
    "    values (as a list). Otherwise, it returns the full `compound_chembl_id`\n",
    "    column.\n",
    "    \"\"\"\n",
    "    if len(compounds) > 10000:\n",
    "        return compounds['compound_chembl_id'][:5000].tolist() + compounds['compound_chembl_id'][-5000:].tolist()\n",
    "    else:\n",
    "        return compounds['compound_chembl_id']\n",
    "    \n",
    "def load_ecfp_subset_by_chembl_id(h5_path, chembl_id_set):\n",
    "    \"\"\"Load a subset of ECFP (Morgan count) fingerprints by ChEMBL ID.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    h5_path : str\n",
    "        Path to the HDF5 file containing datasets \"SMILES\" and \"X_morgan\".\n",
    "    chembl_id_set : set[str] | iterable[str]\n",
    "        ChEMBL IDs to keep.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, np.ndarray]\n",
    "        Mapping {chembl_id: fingerprint (shape (nBits,))} for IDs present in the file.\n",
    "        IDs in `chembl_id_set` that are not found are silently ignored.\n",
    "    \"\"\"\n",
    "    chembl_id_set = set(chembl_id_set)\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        ids = f[\"SMILES\"][:, 3].astype(str)\n",
    "        idx = np.flatnonzero(np.isin(ids, list(chembl_id_set)))\n",
    "        fps = f[\"X_morgan\"][idx]\n",
    "    return {ids[i]: fp for i, fp in zip(idx, fps)}\n",
    "\n",
    "def load_ecfp_all(h5_path):\n",
    "    \"\"\"Load all ECFP (Morgan count) fingerprints.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    h5_path : str\n",
    "        Path to the HDF5 file containing datasets \"SMILES\" and \"X_morgan\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, np.ndarray]\n",
    "        Mapping {chembl_id: fingerprint (np.int8, shape (nBits,))}.\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        meta = f[\"SMILES\"][:, 3].astype(str)\n",
    "        fps  = f[\"X_morgan\"][:]  # Load ALL\n",
    "\n",
    "    return {cid: fp for cid, fp in zip(meta, fps)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf386f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define root directory\n",
    "# root = os.path.dirname(os.path.abspath(__file__))\n",
    "root = \".\"\n",
    "sys.path.append(os.path.join(root, \"..\", \"src\"))\n",
    "from default import DATAPATH, CONFIGPATH\n",
    "\n",
    "# Load pathogen info\n",
    "# pathogen_code = sys.argv[1]\n",
    "pathogen_code = 'mtuberculosis'\n",
    "df = pd.read_csv(os.path.join(CONFIGPATH, 'pathogens.csv'))\n",
    "row = df.loc[df[\"code\"].eq(pathogen_code)]\n",
    "if row.empty: \n",
    "    raise SystemExit(f\"Unknown code: {pathogen_code}\")\n",
    "pathogen = row.iloc[0][\"pathogen\"]\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT = os.path.join(root, \"..\", \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9bfa2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_A(df):\n",
    "    return (\n",
    "        df[\"dataset_type\"].isin([\"quantitative\", \"mixed\"])\n",
    "        & (df[\"cpds_qt\"] >= 1000)\n",
    "        & (df[\"pos_qt\"] >= 50)\n",
    "        & (df[\"ratio_qt\"].between(0.001, 0.5, inclusive=\"both\")))\n",
    "\n",
    "def condition_B(df):\n",
    "    return (\n",
    "        df[\"dataset_type\"].isin([\"qualitative\", \"mixed\"])\n",
    "        & (df[\"cpds_ql\"] >= 1000)\n",
    "        & (df[\"pos_ql\"] >= 50)\n",
    "        & (df[\"ratio_ql\"].between(0.001, 0.5, inclusive=\"both\")))\n",
    "\n",
    "def condition_C(df):\n",
    "    return (\n",
    "        df[\"dataset_type\"].isin([\"quantitative\", \"mixed\"])\n",
    "        & (df[\"pos_qt\"] >= 100)\n",
    "        & (df[\"ratio_qt\"] >= 0.5))\n",
    "\n",
    "def condition_D(df):\n",
    "    return (\n",
    "        df[\"dataset_type\"].isin([\"qualitative\", \"mixed\"])\n",
    "        & (df[\"pos_ql\"] >= 100)\n",
    "        & (df[\"ratio_ql\"] >= 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fcb9304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ECFP6s...\n"
     ]
    }
   ],
   "source": [
    "# Create path to correlations\n",
    "PATH_TO_CORRELATIONS = os.path.join(OUTPUT, pathogen_code, \"correlations\")\n",
    "os.makedirs(PATH_TO_CORRELATIONS, exist_ok=True)\n",
    "\n",
    "# Load assay datasets\n",
    "COLS = [\"assay_id\", \"activity_type\", \"unit\", \"target_type\", \"target_type_curated_extra\", \"cpds\", \n",
    "        \"direction\", \"dataset_type\", \"expert_cutoff\", \"pos_qt\", \"ratio_qt\", \"cpds_qt\", \"pos_ql\", \"ratio_ql\", \"cpds_ql\"]\n",
    "ASSAYS_DATASETS = pd.read_csv(os.path.join(OUTPUT, pathogen_code, \"assays_datasets.csv\"))[COLS]\n",
    "\n",
    "# Create reference set of compounds per pathogen\n",
    "compounds = pd.read_csv(os.path.join(OUTPUT, pathogen_code, \"compound_counts.csv.gz\"))\n",
    "REFERENCE_SET = get_reference_set_compounds(compounds)\n",
    "pd.DataFrame(REFERENCE_SET, columns=['reference_smiles']).to_csv(os.path.join(OUTPUT, pathogen_code, \"reference_set.csv.gz\"))\n",
    "\n",
    "# Get all compounds for pathogen\n",
    "compounds = set(compounds['compound_chembl_id'])\n",
    "print(f\"Loading ECFP6s...\")\n",
    "\n",
    "# Loading Morgan fingerprints\n",
    "PATH_TO_ECFPs = os.path.join(DATAPATH, \"chembl_processed\", \"ChEMBL_ECFPs.h5\")\n",
    "ecfps = load_ecfp_all(PATH_TO_ECFPs)\n",
    "\n",
    "# Get ChEMBL compounds not tested against the pathogen\n",
    "DECOYS = set([i for i in ecfps if i not in compounds])\n",
    "\n",
    "# Prepare reference matrix of Morgan fingerprints\n",
    "X_REF = np.array([ecfps[cid] for cid in REFERENCE_SET if cid in ecfps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9f1a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KFoldTrain(X, Y, n_splits=4, n_estimators=100, random_state=42):\n",
    "    \"\"\"Stratified K-fold training/eval with RandomForest; returns mean AUROC and std.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        Feature matrix (n_samples, n_features).\n",
    "    Y : np.ndarray\n",
    "        Binary labels (n_samples,).\n",
    "    n_splits : int\n",
    "        Number of folds.\n",
    "    n_estimators : int\n",
    "        Number of trees in the random forest.\n",
    "    random_state : int\n",
    "        RNG seed (also used for fold shuffling).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[float, float]\n",
    "        (mean_auroc, std_auroc) rounded to 3 decimals.\n",
    "    \"\"\"\n",
    "    def init_RF():\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_features=\"sqrt\",\n",
    "            n_jobs=8,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    aurocs = []\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X, Y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "        rf = init_RF()\n",
    "        rf.fit(X_train, Y_train)\n",
    "        y_prob = rf.predict_proba(X_test)[:, 1]\n",
    "        aurocs.append(roc_auc_score(Y_test, y_prob))\n",
    "\n",
    "    return round(float(np.mean(aurocs)), 3), round(float(np.std(aurocs)), 3)\n",
    "\n",
    "def TrainRF(X, Y, n_estimators=100):\n",
    "    \"\"\"Train a RandomForestClassifier on all provided data and return the fitted model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        Feature matrix (n_samples, n_features).\n",
    "    Y : np.ndarray\n",
    "        Labels (n_samples,).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    RandomForestClassifier\n",
    "        Fitted classifier.\n",
    "    \"\"\"\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        max_features=\"sqrt\",\n",
    "        n_jobs=8,\n",
    "    )\n",
    "    rf.fit(X, Y)\n",
    "    return rf\n",
    "\n",
    "def load_data_from_zip(zip_path, filename):\n",
    "    \"\"\"Load a gzipped CSV file from a ZIP archive into a pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    zip_path : str\n",
    "        Path to the ZIP archive.\n",
    "    filename : str\n",
    "        Name of the gzipped CSV file inside the ZIP.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Loaded data.\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zip_path) as z:\n",
    "        with z.open(filename) as raw:\n",
    "            with gzip.open(raw, mode=\"rt\") as f:\n",
    "                df = pd.read_csv(f)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94300836",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG, STD, RESULTS = {}, {}, {}\n",
    "\n",
    "CONDITIONS = {\"A\": condition_A, \n",
    "              \"B\": condition_B, \n",
    "              \"C\": condition_C, \n",
    "              \"D\": condition_D}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1ce0619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating A datasets...\n",
      "Assay ID: CHEMBL4649948, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 25.0\n",
      "\tCompounds: 86589 Positives: 4405 (0.051%)\n",
      "\tMean AUROC: 0.632 ± 0.01\n",
      "Assay ID: CHEMBL4649948, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 50.0\n",
      "\tCompounds: 86589 Positives: 1268 (0.015%)\n",
      "\tMean AUROC: 0.59 ± 0.011\n",
      "Assay ID: CHEMBL4649948, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 75.0\n",
      "\tCompounds: 86589 Positives: 361 (0.004%)\n",
      "\tMean AUROC: 0.57 ± 0.011\n",
      "Assay ID: CHEMBL4649949, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 25.0\n",
      "\tCompounds: 86575 Positives: 10324 (0.119%)\n",
      "\tMean AUROC: 0.627 ± 0.003\n",
      "Assay ID: CHEMBL4649949, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 50.0\n",
      "\tCompounds: 86575 Positives: 2181 (0.025%)\n",
      "\tMean AUROC: 0.626 ± 0.019\n",
      "Assay ID: CHEMBL4649949, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 75.0\n",
      "\tCompounds: 86575 Positives: 463 (0.005%)\n",
      "\tMean AUROC: 0.577 ± 0.017\n",
      "Assay ID: CHEMBL4649971, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 25.0\n",
      "\tCompounds: 68613 Positives: 3160 (0.046%)\n",
      "\tMean AUROC: 0.67 ± 0.013\n",
      "Assay ID: CHEMBL4649971, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 50.0\n",
      "\tCompounds: 68613 Positives: 934 (0.014%)\n",
      "\tMean AUROC: 0.703 ± 0.005\n",
      "Assay ID: CHEMBL4649971, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 75.0\n",
      "\tCompounds: 68613 Positives: 516 (0.008%)\n",
      "\tMean AUROC: 0.681 ± 0.023\n",
      "Assay ID: CHEMBL4649972, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 25.0\n",
      "\tCompounds: 68610 Positives: 282 (0.004%)\n",
      "\tMean AUROC: 0.545 ± 0.012\n",
      "Assay ID: CHEMBL4649941, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 25.0\n",
      "\tCompounds: 66941 Positives: 230 (0.003%)\n",
      "\tMean AUROC: 0.521 ± 0.004\n",
      "Assay ID: CHEMBL4649965, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 25.0\n",
      "\tCompounds: 66591 Positives: 1365 (0.02%)\n",
      "\tMean AUROC: 0.605 ± 0.012\n",
      "Assay ID: CHEMBL4649965, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 50.0\n",
      "\tCompounds: 66591 Positives: 303 (0.005%)\n",
      "\tMean AUROC: 0.575 ± 0.008\n",
      "Assay ID: CHEMBL4649965, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 75.0\n",
      "\tCompounds: 66591 Positives: 98 (0.001%)\n",
      "\tMean AUROC: 0.532 ± 0.028\n",
      "Assay ID: CHEMBL4649957, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 25.0\n",
      "\tCompounds: 65027 Positives: 270 (0.004%)\n",
      "\tMean AUROC: 0.505 ± 0.006\n",
      "Assay ID: CHEMBL4649957, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 50.0\n",
      "\tCompounds: 65027 Positives: 64 (0.001%)\n",
      "\tMean AUROC: 0.505 ± 0.013\n",
      "Assay ID: CHEMBL4649961, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 25.0\n",
      "\tCompounds: 53165 Positives: 6425 (0.121%)\n",
      "\tMean AUROC: 0.635 ± 0.007\n",
      "Assay ID: CHEMBL4649961, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 50.0\n",
      "\tCompounds: 53165 Positives: 898 (0.017%)\n",
      "\tMean AUROC: 0.653 ± 0.008\n",
      "Assay ID: CHEMBL4649961, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 75.0\n",
      "\tCompounds: 53165 Positives: 376 (0.007%)\n",
      "\tMean AUROC: 0.677 ± 0.008\n",
      "Assay ID: CHEMBL4649949, Activity type: IC50, Unit: umol.L-1, Cutoff: 5.0\n",
      "\tCompounds: 2468 Positives: 50 (0.02%)\n",
      "\tMean AUROC: 0.558 ± 0.017\n",
      "Assay ID: CHEMBL4649949, Activity type: IC50, Unit: umol.L-1, Cutoff: 10.0\n",
      "\tCompounds: 2468 Positives: 90 (0.036%)\n",
      "\tMean AUROC: 0.601 ± 0.069\n",
      "Assay ID: CHEMBL4649949, Activity type: IC50, Unit: umol.L-1, Cutoff: 20.0\n",
      "\tCompounds: 2468 Positives: 209 (0.085%)\n",
      "\tMean AUROC: 0.682 ± 0.047\n",
      "Assay ID: CHEMBL4649948, Activity type: IC50, Unit: umol.L-1, Cutoff: 10.0\n",
      "\tCompounds: 2466 Positives: 68 (0.028%)\n",
      "\tMean AUROC: 0.553 ± 0.054\n",
      "Assay ID: CHEMBL4649948, Activity type: IC50, Unit: umol.L-1, Cutoff: 20.0\n",
      "\tCompounds: 2466 Positives: 207 (0.084%)\n",
      "\tMean AUROC: 0.689 ± 0.038\n",
      "Assay ID: CHEMBL1738598, Activity type: IC50, Unit: umol.L-1, Cutoff: 5.0\n",
      "\tCompounds: 2148 Positives: 758 (0.353%)\n",
      "\tMean AUROC: 0.655 ± 0.024\n",
      "Assay ID: CHEMBL1794349, Activity type: AC50, Unit: umol.L-1, Cutoff: 5.0\n",
      "\tCompounds: 2121 Positives: 237 (0.112%)\n",
      "\tMean AUROC: 0.755 ± 0.049\n",
      "Assay ID: CHEMBL1794426, Activity type: EC50, Unit: umol.L-1, Cutoff: 0.5\n",
      "\tCompounds: 2116 Positives: 173 (0.082%)\n",
      "\tMean AUROC: 0.758 ± 0.043\n",
      "Assay ID: CHEMBL1794426, Activity type: EC50, Unit: umol.L-1, Cutoff: 1.0\n",
      "\tCompounds: 2116 Positives: 316 (0.149%)\n",
      "\tMean AUROC: 0.774 ± 0.025\n",
      "Assay ID: CHEMBL1794426, Activity type: EC50, Unit: umol.L-1, Cutoff: 5.0\n",
      "\tCompounds: 2116 Positives: 988 (0.467%)\n",
      "\tMean AUROC: 0.73 ± 0.021\n",
      "Assay ID: CHEMBL1794324, Activity type: AC50, Unit: umol.L-1, Cutoff: 0.5\n",
      "\tCompounds: 2064 Positives: 81 (0.039%)\n",
      "\tMean AUROC: 0.791 ± 0.035\n",
      "Assay ID: CHEMBL1794324, Activity type: AC50, Unit: umol.L-1, Cutoff: 1.0\n",
      "\tCompounds: 2064 Positives: 118 (0.057%)\n",
      "\tMean AUROC: 0.76 ± 0.084\n",
      "Assay ID: CHEMBL1794324, Activity type: AC50, Unit: umol.L-1, Cutoff: 5.0\n",
      "\tCompounds: 2064 Positives: 686 (0.332%)\n",
      "\tMean AUROC: 0.694 ± 0.008\n",
      "Assay ID: CHEMBL1614183, Activity type: IC50, Unit: umol.L-1, Cutoff: 5.0\n",
      "\tCompounds: 2041 Positives: 608 (0.298%)\n",
      "\tMean AUROC: 0.7 ± 0.01\n",
      "Assay ID: CHEMBL1614183, Activity type: IC50, Unit: umol.L-1, Cutoff: 10.0\n",
      "\tCompounds: 2041 Positives: 945 (0.463%)\n",
      "\tMean AUROC: 0.684 ± 0.02\n",
      "Assay ID: CHEMBL1614289, Activity type: IC50, Unit: umol.L-1, Cutoff: 5.0\n",
      "\tCompounds: 1933 Positives: 386 (0.2%)\n",
      "\tMean AUROC: 0.579 ± 0.037\n",
      "Assay ID: CHEMBL1614289, Activity type: IC50, Unit: umol.L-1, Cutoff: 10.0\n",
      "\tCompounds: 1933 Positives: 651 (0.337%)\n",
      "\tMean AUROC: 0.631 ± 0.013\n",
      "Assay ID: CHEMBL1614266, Activity type: IC50, Unit: umol.L-1, Cutoff: 5.0\n",
      "\tCompounds: 1727 Positives: 181 (0.105%)\n",
      "\tMean AUROC: 0.552 ± 0.029\n",
      "Assay ID: CHEMBL1614266, Activity type: IC50, Unit: umol.L-1, Cutoff: 10.0\n",
      "\tCompounds: 1727 Positives: 330 (0.191%)\n",
      "\tMean AUROC: 0.594 ± 0.014\n",
      "Assay ID: CHEMBL1614266, Activity type: IC50, Unit: umol.L-1, Cutoff: 20.0\n",
      "\tCompounds: 1727 Positives: 630 (0.365%)\n",
      "\tMean AUROC: 0.562 ± 0.046\n",
      "Assay ID: CHEMBL1738696, Activity type: IC50, Unit: umol.L-1, Cutoff: 5.0\n",
      "\tCompounds: 1453 Positives: 397 (0.273%)\n",
      "\tMean AUROC: 0.728 ± 0.004\n",
      "Assay ID: CHEMBL1738696, Activity type: IC50, Unit: umol.L-1, Cutoff: 10.0\n",
      "\tCompounds: 1453 Positives: 667 (0.459%)\n",
      "\tMean AUROC: 0.718 ± 0.023\n",
      "Number of considered datasets: 41\n",
      "Number of accepted datasets: 9\n",
      "Number of accepted assays: 5\n"
     ]
    }
   ],
   "source": [
    "LABEL = \"A\"\n",
    "\n",
    "print(f\"Creating {LABEL} datasets...\")\n",
    "\n",
    "# Define some variables\n",
    "ASSAYS_DATASETS[LABEL] = CONDITIONS[LABEL](ASSAYS_DATASETS)\n",
    "AVG[LABEL] = []\n",
    "STD[LABEL] = []\n",
    "RESULTS[LABEL] = defaultdict(list)\n",
    "\n",
    "# Iterate over assays LABEL\n",
    "for c, assay in ASSAYS_DATASETS.iterrows():\n",
    "\n",
    "    # Load varibles\n",
    "    assay_id, activity_type, unit, expert_cutoff = assay.assay_id, assay.activity_type, assay.unit, assay.expert_cutoff\n",
    "\n",
    "    if assay[LABEL] is False:\n",
    "\n",
    "        AVG[LABEL].append(np.nan)\n",
    "        STD[LABEL].append(np.nan)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Load data\n",
    "        zip_path = os.path.join(OUTPUT, pathogen_code, \"datasets\", \"datasets_qt.zip\")\n",
    "        filename = \"_\".join([str(assay_id), str(activity_type), str(unit), \"qt\", f\"{expert_cutoff}.csv.gz\"])\n",
    "        df = load_data_from_zip(zip_path, filename)\n",
    "\n",
    "        # Prepare matrices\n",
    "        X = np.array(df['compound_chembl_id'].map(ecfps).to_list())\n",
    "        Y = np.array(df['bin'].tolist())\n",
    "\n",
    "        print(f\"Assay ID: {assay_id}, Activity type: {activity_type}, Unit: {unit}, Cutoff: {expert_cutoff}\")\n",
    "        print(f\"\\tCompounds: {len(X)}\", f\"Positives: {sum(Y)} ({round(sum(Y) / len(Y),3)}%)\")\n",
    "\n",
    "        # 4Fold Cros Validation\n",
    "        average_auroc, stds = KFoldTrain(X, Y, n_splits=4, n_estimators=10)\n",
    "        print(f\"\\tMean AUROC: {average_auroc} ± {stds}\")\n",
    "        AVG[LABEL].append(average_auroc)\n",
    "        STD[LABEL].append(stds)\n",
    "\n",
    "        # If performance is good enough, train on full data and predict on reference set\n",
    "        if average_auroc > 0.7:\n",
    "            RF = TrainRF(X, Y, n_estimators=10)\n",
    "            y_prob_ref = RF.predict_proba(X_REF)[:, 1]\n",
    "            os.makedirs(os.path.join(PATH_TO_CORRELATIONS, LABEL), exist_ok=True)\n",
    "            np.savez_compressed(os.path.join(PATH_TO_CORRELATIONS, LABEL, filename.replace(\".csv.gz\", \"_ref_probs.npz\")), y_prob_ref=y_prob_ref)\n",
    "\n",
    "ASSAYS_DATASETS[f'{LABEL}_AVG'] = AVG[LABEL]\n",
    "# ASSAYS_DATASETS[f'{LABEL}_STD'] = STD[LABEL]\n",
    "\n",
    "considered_datasets = len(ASSAYS_DATASETS[ASSAYS_DATASETS[LABEL]])\n",
    "accepted_datasets = len(ASSAYS_DATASETS[(ASSAYS_DATASETS[LABEL]) & (ASSAYS_DATASETS[f'{LABEL}_AVG'] > 0.7)])\n",
    "accepted_assays = len(set([tuple(i) for i in ASSAYS_DATASETS[(ASSAYS_DATASETS[LABEL]) & (ASSAYS_DATASETS[f'{LABEL}_AVG'] > 0.7)][['assay_id', 'activity_type', 'unit']].values]))\n",
    "\n",
    "print(f\"Number of considered datasets: {considered_datasets}\")\n",
    "print(f\"Number of accepted datasets: {accepted_datasets}\")\n",
    "print(f\"Number of accepted assays: {accepted_assays}\")\n",
    "\n",
    "rows = ASSAYS_DATASETS[ASSAYS_DATASETS[LABEL]][[\"assay_id\", \"activity_type\", \"unit\", \"expert_cutoff\", f\"{LABEL}_AVG\"]].values\n",
    "for assay_id, activity_type, unit, expert_cutoff, auroc in rows:\n",
    "    if auroc < 0.7:\n",
    "        continue\n",
    "    key = (assay_id, activity_type, unit)\n",
    "    if key not in RESULTS[LABEL] or auroc > RESULTS[LABEL][key][1]:\n",
    "            RESULTS[LABEL][key] = [expert_cutoff, auroc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad4483da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating B datasets...\n",
      "Number of considered datasets: 0\n",
      "Number of accepted datasets: 0\n",
      "Number of accepted assays: 0\n"
     ]
    }
   ],
   "source": [
    "LABEL = \"B\"\n",
    "\n",
    "print(f\"Creating {LABEL} datasets...\")\n",
    "\n",
    "# Define some variables\n",
    "ASSAYS_DATASETS[LABEL] = CONDITIONS[LABEL](ASSAYS_DATASETS)\n",
    "AVG[LABEL] = []\n",
    "STD[LABEL] = []\n",
    "RESULTS[LABEL] = defaultdict(list)\n",
    "\n",
    "# Iterate over assays LABEL\n",
    "for c, assay in ASSAYS_DATASETS.iterrows():\n",
    "\n",
    "    # Load varibles\n",
    "    assay_id, activity_type, unit, expert_cutoff = assay.assay_id, assay.activity_type, assay.unit, assay.expert_cutoff\n",
    "\n",
    "    if assay[LABEL] is False:\n",
    "\n",
    "        AVG[LABEL].append(np.nan)\n",
    "        STD[LABEL].append(np.nan)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Load data\n",
    "        zip_path = os.path.join(OUTPUT, pathogen_code, \"datasets\", \"datasets_qt.zip\")\n",
    "        filename = \"_\".join([str(assay_id), str(activity_type), str(unit), \"qt\", f\"{expert_cutoff}.csv.gz\"])\n",
    "        df = load_data_from_zip(zip_path, filename)\n",
    "\n",
    "        # Prepare matrices\n",
    "        X = np.array(df['compound_chembl_id'].map(ecfps).to_list())\n",
    "        Y = np.array(df['bin'].tolist())\n",
    "\n",
    "        print(f\"Assay ID: {assay_id}, Activity type: {activity_type}, Unit: {unit}, Cutoff: {expert_cutoff}\")\n",
    "        print(f\"\\tCompounds: {len(X)}\", f\"Positives: {sum(Y)} ({round(sum(Y) / len(Y),3)}%)\")\n",
    "\n",
    "        # 4Fold Cros Validation\n",
    "        average_auroc, stds = KFoldTrain(X, Y, n_splits=4, n_estimators=10)\n",
    "        print(f\"\\tMean AUROC: {average_auroc} ± {stds}\")\n",
    "        AVG[LABEL].append(average_auroc)\n",
    "        STD[LABEL].append(stds)\n",
    "\n",
    "        # If performance is good enough, train on full data and predict on reference set\n",
    "        if average_auroc > 0.7:\n",
    "            RF = TrainRF(X, Y, n_estimators=10)\n",
    "            y_prob_ref = RF.predict_proba(X_REF)[:, 1]\n",
    "            os.makedirs(os.path.join(PATH_TO_CORRELATIONS, LABEL), exist_ok=True)\n",
    "            np.savez_compressed(os.path.join(PATH_TO_CORRELATIONS, LABEL, filename.replace(\".csv.gz\", \"_ref_probs.npz\")), y_prob_ref=y_prob_ref)\n",
    "\n",
    "ASSAYS_DATASETS[f'{LABEL}_AVG'] = AVG[LABEL]\n",
    "# ASSAYS_DATASETS[f'{LABEL}_STD'] = STD[LABEL]\n",
    "\n",
    "considered_datasets = len(ASSAYS_DATASETS[ASSAYS_DATASETS[LABEL]])\n",
    "accepted_datasets = len(ASSAYS_DATASETS[(ASSAYS_DATASETS[LABEL]) & (ASSAYS_DATASETS[f'{LABEL}_AVG'] > 0.7)])\n",
    "accepted_assays = len(set([tuple(i) for i in ASSAYS_DATASETS[(ASSAYS_DATASETS[LABEL]) & (ASSAYS_DATASETS[f'{LABEL}_AVG'] > 0.7)][['assay_id', 'activity_type', 'unit']].values]))\n",
    "\n",
    "print(f\"Number of considered datasets: {considered_datasets}\")\n",
    "print(f\"Number of accepted datasets: {accepted_datasets}\")\n",
    "print(f\"Number of accepted assays: {accepted_assays}\")\n",
    "\n",
    "rows = ASSAYS_DATASETS[ASSAYS_DATASETS[LABEL]][[\"assay_id\", \"activity_type\", \"unit\", \"expert_cutoff\", f\"{LABEL}_AVG\"]].values\n",
    "for assay_id, activity_type, unit, expert_cutoff, auroc in rows:\n",
    "    if auroc < 0.7:\n",
    "        continue\n",
    "    key = (assay_id, activity_type, unit)\n",
    "    if key not in RESULTS[LABEL] or auroc > RESULTS[LABEL][key][1]:\n",
    "            RESULTS[LABEL][key] = [expert_cutoff, auroc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b2e7261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating C datasets...\n",
      "Assay ID: CHEMBL1738598, Activity type: IC50, Unit: umol.L-1, Cutoff: 10.0\n",
      "\tCompounds: 2148 Positives: 1277 (0.595%)\n",
      "\tAdding random compounds from ChEMBL as decoys\n",
      "\t11900 added negatives\n"
     ]
    }
   ],
   "source": [
    "LABEL = \"C\"\n",
    "\n",
    "print(f\"Creating {LABEL} datasets...\")\n",
    "\n",
    "# Define some variables\n",
    "ASSAYS_DATASETS[LABEL] = CONDITIONS[LABEL](ASSAYS_DATASETS)\n",
    "AVG[LABEL] = []\n",
    "STD[LABEL] = []\n",
    "RESULTS[LABEL] = defaultdict(list)\n",
    "RATIO = 0.1\n",
    "\n",
    "# Iterate over assays LABEL\n",
    "for c, assay in ASSAYS_DATASETS.iterrows():\n",
    "\n",
    "    # Load varibles\n",
    "    assay_id, activity_type, unit, expert_cutoff = assay.assay_id, assay.activity_type, assay.unit, assay.expert_cutoff\n",
    "\n",
    "    if assay[LABEL] is False:\n",
    "\n",
    "        AVG[LABEL].append(np.nan)\n",
    "        STD[LABEL].append(np.nan)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Load data\n",
    "        zip_path = os.path.join(OUTPUT, pathogen_code, \"datasets\", \"datasets_qt.zip\")\n",
    "        filename = \"_\".join([str(assay_id), str(activity_type), str(unit), \"qt\", f\"{expert_cutoff}.csv.gz\"])\n",
    "        df = load_data_from_zip(zip_path, filename)\n",
    "\n",
    "        # Prepare matrices\n",
    "        X = np.array(df['compound_chembl_id'].map(ecfps).to_list())\n",
    "        Y = np.array(df['bin'].tolist())\n",
    "\n",
    "        print(f\"Assay ID: {assay_id}, Activity type: {activity_type}, Unit: {unit}, Cutoff: {expert_cutoff}\")\n",
    "        print(f\"\\tCompounds: {len(X)}\", f\"Positives: {sum(Y)} ({round(sum(Y) / len(Y),3)}%)\")\n",
    "        print(f\"\\tAdding random compounds from ChEMBL as decoys\")\n",
    "\n",
    "        NEGATIVES = int(Counter(Y)[1] / RATIO - (Counter(Y)[0] - 1))\n",
    "        print(f\"\\t{NEGATIVES} added negatives\")\n",
    "\n",
    "        break\n",
    "\n",
    "        # 4Fold Cros Validation\n",
    "        average_auroc, stds = KFoldTrain(X, Y, n_splits=4, n_estimators=10)\n",
    "        print(f\"\\tMean AUROC: {average_auroc} ± {stds}\")\n",
    "        AVG[LABEL].append(average_auroc)\n",
    "        STD[LABEL].append(stds)\n",
    "\n",
    "        # If performance is good enough, train on full data and predict on reference set\n",
    "        if average_auroc > 0.7:\n",
    "            RF = TrainRF(X, Y, n_estimators=10)\n",
    "            y_prob_ref = RF.predict_proba(X_REF)[:, 1]\n",
    "            os.makedirs(os.path.join(PATH_TO_CORRELATIONS, LABEL), exist_ok=True)\n",
    "            np.savez_compressed(os.path.join(PATH_TO_CORRELATIONS, LABEL, filename.replace(\".csv.gz\", \"_ref_probs.npz\")), y_prob_ref=y_prob_ref)\n",
    "\n",
    "        \n",
    "\n",
    "# ASSAYS_DATASETS[f'{LABEL}_AVG'] = AVG[LABEL]\n",
    "# # ASSAYS_DATASETS[f'{LABEL}_STD'] = STD[LABEL]\n",
    "\n",
    "# considered_datasets = len(ASSAYS_DATASETS[ASSAYS_DATASETS[LABEL]])\n",
    "# accepted_datasets = len(ASSAYS_DATASETS[(ASSAYS_DATASETS[LABEL]) & (ASSAYS_DATASETS[f'{LABEL}_AVG'] > 0.7)])\n",
    "# accepted_assays = len(set([tuple(i) for i in ASSAYS_DATASETS[(ASSAYS_DATASETS[LABEL]) & (ASSAYS_DATASETS[f'{LABEL}_AVG'] > 0.7)][['assay_id', 'activity_type', 'unit']].values]))\n",
    "\n",
    "# print(f\"Number of considered datasets: {considered_datasets}\")\n",
    "# print(f\"Number of accepted datasets: {accepted_datasets}\")\n",
    "# print(f\"Number of accepted assays: {accepted_assays}\")\n",
    "\n",
    "# rows = ASSAYS_DATASETS[ASSAYS_DATASETS[LABEL]][[\"assay_id\", \"activity_type\", \"unit\", \"expert_cutoff\", f\"{LABEL}_AVG\"]].values\n",
    "# for assay_id, activity_type, unit, expert_cutoff, auroc in rows:\n",
    "#     if auroc < 0.7:\n",
    "#         continue\n",
    "#     key = (assay_id, activity_type, unit)\n",
    "#     if key not in RESULTS[LABEL] or auroc > RESULTS[LABEL][key][1]:\n",
    "#             RESULTS[LABEL][key] = [expert_cutoff, auroc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afdaad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1277"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ad0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26bdaa7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12770.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEGATIVES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
