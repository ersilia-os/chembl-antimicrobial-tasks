{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0359bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89adaef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \".\"\n",
    "\n",
    "pathogen_code = \"mtuberculosis\"\n",
    "\n",
    "OUTPUT = os.path.join(root, \"..\", \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45aaff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_relation(ASSAY_DATA: pd.DataFrame, DIRECTION: int, CUT: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adjust relations in an assay DataFrame according to the biological direction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pd.DataFrame\n",
    "        Must contain the columns 'relation' and 'value'.\n",
    "    DIRECTION : int\n",
    "        +1 → higher = more active (e.g. % inhibition)\n",
    "        -1 → lower = more active (e.g. IC50, MIC)\n",
    "    CUT : float\n",
    "        Extreme value used to replace censored measurements\n",
    "        on the wrong side of the direction (min-1 or max+1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Copy of ASSAY_DATA with adjusted relation and value.\n",
    "    \"\"\"\n",
    "\n",
    "    df = ASSAY_DATA.copy()\n",
    "    rel = df[\"relation\"].astype(str)\n",
    "\n",
    "    if DIRECTION == +1:\n",
    "\n",
    "        # Higher = more active\n",
    "        mask_gt = rel == \">\"  # greater than\n",
    "        mask_lt = rel == \"<\"  # lower than\n",
    "\n",
    "        df.loc[mask_gt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_lt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_lt, \"value\"] = CUT\n",
    "\n",
    "    elif DIRECTION == -1:\n",
    "\n",
    "        # Lower = more active\n",
    "        mask_lt = rel == \"<\"  # lower than\n",
    "        mask_gt = rel == \">\"  # greater than\n",
    "\n",
    "        df.loc[mask_lt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_gt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_gt, \"value\"] = CUT\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise ValueError(f\"Invalid DIRECTION={DIRECTION}. Expected +1 or -1.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def disambiguate_compounds(ASSAY_DATA: pd.DataFrame, DIRECTION: int) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Select a single measurement per compound according to the biological direction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pd.DataFrame\n",
    "        Must contain the columns 'compound_chembl_id' and 'value'.\n",
    "        Assumes all relations have already been adjusted.\n",
    "    DIRECTION : int\n",
    "        +1 → higher = more active (e.g. % inhibition)\n",
    "        -1 → lower = more active (e.g. IC50, MIC)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A copy of ASSAY_DATA in which duplicated compounds \n",
    "        ('compound_chembl_id') are removed, keeping only the \n",
    "        most active measurement per compound (highest or lowest \n",
    "        depending on DIRECTION).\n",
    "    \"\"\"\n",
    "\n",
    "    if DIRECTION not in [1, -1]:\n",
    "        raise ValueError(\"DIRECTION must be +1 (higher = more active) or -1 (lower = more active).\")\n",
    "        \n",
    "    df = ASSAY_DATA.copy()\n",
    "\n",
    "    # Choose best measurement based on direction\n",
    "    if DIRECTION == -1:\n",
    "        # Lower = more active → keep minimum\n",
    "        df_sorted = df.sort_values(by=\"value\", ascending=True)\n",
    "    elif DIRECTION == 1:\n",
    "        # Higher = more active → keep maximum\n",
    "        df_sorted = df.sort_values(by=\"value\", ascending=False)\n",
    "\n",
    "    # Keep the best row per compound_chembl_id\n",
    "    df_best = df_sorted.drop_duplicates(subset=\"compound_chembl_id\", keep=\"first\")\n",
    "\n",
    "    return df_best.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33bc56a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned assays\n",
    "ASSAYS_CLEANED = pd.read_csv(os.path.join(root, \"..\", \"output\", pathogen_code, \"assays_cleaned.csv\"))\n",
    "\n",
    "# Define PATH to parameters\n",
    "PATH_TO_PARAMETERS = os.path.join(root, \"..\", \"output\", pathogen_code, 'parameters')\n",
    "\n",
    "TARGET_TYPE_CURATED = []\n",
    "\n",
    "# Iterating over assays\n",
    "for assay_id, activity_type, unit in ASSAYS_CLEANED[['assay_id', 'activity_type', 'unit']].values:\n",
    "\n",
    "    # Prepare filename\n",
    "    filename = \"_\".join([str(assay_id), str(activity_type), str(unit), 'parameters']) + \".json\"\n",
    "    \n",
    "    # Read JSON file\n",
    "    with open(os.path.join(PATH_TO_PARAMETERS, filename), \"r\") as file:\n",
    "        par = json.load(file)\n",
    "\n",
    "    # Store results\n",
    "    TARGET_TYPE_CURATED.append(par['target_type'])\n",
    "\n",
    "# Complete table\n",
    "ASSAYS_CLEANED['target_type_curated'] = TARGET_TYPE_CURATED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d9486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ChEMBL cleaned data for mtuberculosis...\n",
      "Number of activities for mtuberculosis: 702477\n",
      "Number of compounds for mtuberculosis: 131442\n",
      "Number of cleaned assays: 10521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:27<00:00, 11.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loading pathogen data\n",
    "os.makedirs(os.path.join(OUTPUT, pathogen_code, 'datasets'), exist_ok=True)\n",
    "print(f\"Loading ChEMBL cleaned data for {pathogen_code}...\")\n",
    "ChEMBL_pathogen = pd.read_csv(os.path.join(OUTPUT, pathogen_code, f\"{pathogen_code}_ChEMBL_cleaned_data.csv.gz\"), low_memory=False)\n",
    "print(f\"Number of activities for {pathogen_code}: {len(ChEMBL_pathogen)}\")\n",
    "print(f\"Number of compounds for {pathogen_code}: {len(set(ChEMBL_pathogen['compound_chembl_id']))}\")\n",
    "print(f\"Number of cleaned assays: {len(ASSAYS_CLEANED)}\")\n",
    "\n",
    "# Load expert cut-offs\n",
    "EXPERT_CUTOFFS = pd.read_csv(os.path.join(root, \"..\", \"config\", \"manual_curation\", \"expert_cutoffs.csv\"))\n",
    "EXPERT_CUTOFFS = {\n",
    "    (a, b, c, d): e\n",
    "    for a, b, c, d, e in EXPERT_CUTOFFS[\n",
    "        [\"activity_type\", \"unit\", \"target_type\", \"pathogen_code\", \"expert_cutoff\"]\n",
    "    ].values}\n",
    "\n",
    "# Define data ranges\n",
    "DATA_RANGES = []\n",
    "\n",
    "for assay_chembl_id, activity_type, unit, target_type, target_type_curated, activities, cpds, direction in tqdm(ASSAYS_CLEANED[['assay_id', 'activity_type', 'unit', 'target_type',\n",
    "                                                                                                        'target_type_curated', 'activities', 'cpds', 'direction']].values[:1000]):\n",
    "\n",
    "    # Loading assay data\n",
    "    cols = ['compound_chembl_id', 'canonical_smiles', 'activity_type', 'value', 'relation', 'unit', 'activity_comment', 'standard_text']\n",
    "    if type(unit) == str:\n",
    "        ASSAY_DATA = ChEMBL_pathogen[(ChEMBL_pathogen['assay_chembl_id'] == assay_chembl_id) & \n",
    "                                    (ChEMBL_pathogen['activity_type'] == activity_type) & \n",
    "                                    (ChEMBL_pathogen['unit'] == unit)].reset_index(drop=True)[cols]\n",
    "    else:\n",
    "        ASSAY_DATA = ChEMBL_pathogen[(ChEMBL_pathogen['assay_chembl_id'] == assay_chembl_id) & \n",
    "                                    (ChEMBL_pathogen['activity_type'] == activity_type) & \n",
    "                                    (ChEMBL_pathogen['unit'].isna())].reset_index(drop=True)[cols]\n",
    "    \n",
    "    # Counter relations\n",
    "    counter_relations = Counter(ASSAY_DATA['relation'].tolist())\n",
    "\n",
    "    # Get value to adjust relations\n",
    "    if direction == 1:\n",
    "        CUT = min(ASSAY_DATA['value'])\n",
    "    elif direction == -1:\n",
    "        CUT = max(ASSAY_DATA['value'])\n",
    "    else:\n",
    "        CUT = np.nan\n",
    "\n",
    "    # Get expert cut-off if exists\n",
    "    key = (activity_type, unit, target_type_curated, pathogen_code)\n",
    "    expert_cutoff = EXPERT_CUTOFFS[key] if key in EXPERT_CUTOFFS else np.nan\n",
    "\n",
    "    if direction in [+1, -1]:\n",
    "\n",
    "        original_number_activities = len(ASSAY_DATA)\n",
    "\n",
    "        # Adjust relation\n",
    "        ASSAY_DATA = adjust_relation(ASSAY_DATA, direction, CUT)\n",
    "\n",
    "        # Disambiguate duplicated compounds and returns 'sorted' data (depending on direction)\n",
    "        ASSAY_DATA = disambiguate_compounds(ASSAY_DATA, direction)\n",
    "\n",
    "        # Remove nans\n",
    "        assay_activities = [i for i in ASSAY_DATA['value'].tolist() if np.isnan(i) == False]\n",
    "\n",
    "        # Fully qualitative assay\n",
    "        if len(assay_activities) == 0:\n",
    "            assay_activities = [np.nan]\n",
    "            dataset_type = 'qualitative'\n",
    "        elif len(assay_activities) < len(ASSAY_DATA):\n",
    "            dataset_type = 'mixed'\n",
    "        else:\n",
    "            dataset_type = 'quantitative'\n",
    "\n",
    "        # Binarization with expert cut-off\n",
    "        if np.isnan(expert_cutoff) == False:\n",
    "            if direction == +1:\n",
    "                ASSAY_DATA[\"bin_quantitative\"] = (ASSAY_DATA[\"value\"] >= expert_cutoff).astype(int)\n",
    "            else:\n",
    "                ASSAY_DATA[\"bin_quantitative\"] = (ASSAY_DATA[\"value\"] <= expert_cutoff).astype(int)\n",
    "            positives = Counter(ASSAY_DATA['bin_quantitative'].tolist())[1]\n",
    "            ratio = round(positives / len(ASSAY_DATA), 5)\n",
    "        else:\n",
    "            # Dataset could not be binarized using values due to missing expert cut-off\n",
    "            ASSAY_DATA['bin_quantitative'] = [np.nan] * len(ASSAY_DATA)\n",
    "            positives = np.nan\n",
    "            ratio = np.nan\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Qualitative assay\n",
    "        dataset_type = 'qualitative'    \n",
    "\n",
    "        # Not binarizing a null-direction assay\n",
    "        ASSAY_DATA['bin_quantitative'] = [np.nan] * len(ASSAY_DATA)\n",
    "        positives = np.nan\n",
    "        ratio = np.nan\n",
    "        assay_activities = [np.nan]\n",
    "\n",
    "\n",
    "    # Getting qualitative bin\n",
    "    ASSAY_DATA['bin_qualitative'] = [np.nan for i in range(len(ASSAY_DATA))]\n",
    "    cond_nan = (ASSAY_DATA['activity_comment'] == 0) & (ASSAY_DATA['standard_text'] == 0)\n",
    "    cond_pos = (ASSAY_DATA['activity_comment'] == 1) | (ASSAY_DATA['standard_text'] == 1)\n",
    "    cond_neg = (ASSAY_DATA['activity_comment'] == -1) | (ASSAY_DATA['standard_text'] == -1)\n",
    "    conflict = cond_pos & cond_neg\n",
    "    if conflict.any():\n",
    "        raise ValueError(\n",
    "            \"Conflicting labels (contains both 1 and -1):\\n\"\n",
    "            + ASSAY_DATA.loc[conflict, [\"activity_comment\", \"standard_text\"]].head(20).to_string())\n",
    "    ASSAY_DATA.loc[cond_pos, \"bin_qualitative\"] = 1\n",
    "    ASSAY_DATA.loc[cond_neg, \"bin_qualitative\"] = 0\n",
    "\n",
    "    # Positives and negatives qualitative\n",
    "    positives_qual = Counter(ASSAY_DATA['bin_qualitative'].tolist())[1]\n",
    "    negatives_qual = Counter(ASSAY_DATA['bin_qualitative'].tolist())[0]\n",
    "\n",
    "    # Calculate data\n",
    "    min_ = round(np.min(assay_activities), 3)\n",
    "    p1 = round(np.percentile(assay_activities, 1), 3)\n",
    "    p25 = round(np.percentile(assay_activities, 25), 3)\n",
    "    p50 = round(np.percentile(assay_activities, 50), 3)\n",
    "    p75 = round(np.percentile(assay_activities, 75), 3)\n",
    "    p99 = round(np.percentile(assay_activities, 99), 3)\n",
    "    max_ = round(np.max(assay_activities), 3)\n",
    "\n",
    "    # Relations\n",
    "    equal = counter_relations[\"=\"]\n",
    "    lower = counter_relations[\"<\"]\n",
    "    higher = counter_relations[\">\"]\n",
    "\n",
    "    # Store data range\n",
    "    DATA_RANGES.append([assay_chembl_id, activity_type, unit, target_type, target_type_curated, activities, cpds, direction, equal, higher, \n",
    "                        lower, min_, p1, p25, p50, p75, p99, max_, expert_cutoff, positives, ratio, dataset_type, positives_qual, negatives_qual])\n",
    "\n",
    "    # Save data\n",
    "    if cpds >= 100:\n",
    "        ASSAY_DATA.to_csv(os.path.join(OUTPUT, pathogen_code, 'datasets', f\"{assay_chembl_id}_{activity_type}_{str(unit).replace('/', 'FwdS')}.csv.gz\"), index=False)\n",
    "\n",
    "DATA_RANGES = pd.DataFrame(DATA_RANGES, columns=[\"assay_id\", \"activity_type\", \"unit\", \"target_type\", \"target_type_curated\", \"activities\", \"cpds\", \"direction\", \n",
    "                                                 \"equal\", \"higher\", \"lower\", \"min_\", \"p1\", \"p25\", \"p50\", \"p75\", \"p99\", \"max_\", 'expert_cutoff', 'positives_quant', 'ratio_quant', \n",
    "                                                 'dataset_type', 'positives_qual', 'negatives_qual'])\n",
    "DATA_RANGES.to_csv(os.path.join(OUTPUT, pathogen_code, 'assays_data_ranges.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e5ad71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
