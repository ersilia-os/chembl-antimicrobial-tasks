{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed46bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".dataframe td, .dataframe th {\n",
       "    white-space: nowrap !important;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from IPython.display import display, HTML\n",
    "from scipy.stats import spearmanr\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import joblib\n",
    "import gzip\n",
    "import sys\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "pd.set_option(\"display.width\", 2000)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    ".dataframe td, .dataframe th {\n",
    "    white-space: nowrap !important;\n",
    "}\n",
    "</style>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4166f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_set_compounds(compounds):\n",
    "    \"\"\"\n",
    "    Return a reference set of ChEMBL compound IDs from a compounds DataFrame.\n",
    "\n",
    "    If the DataFrame has more than 10,000 rows, this returns a reduced reference\n",
    "    set consisting of the first 5,000 and the last 5,000 `compound_chembl_id`\n",
    "    values (as a list). Otherwise, it returns the full `compound_chembl_id`\n",
    "    column.\n",
    "    \"\"\"\n",
    "    if len(compounds) > 10000:\n",
    "        return compounds['compound_chembl_id'][:5000].tolist() + compounds['compound_chembl_id'][-5000:].tolist()\n",
    "    else:\n",
    "        return compounds['compound_chembl_id']\n",
    "    \n",
    "def load_ecfp_subset_by_chembl_id(h5_path, chembl_id_set):\n",
    "    \"\"\"Load a subset of ECFP (Morgan count) fingerprints by ChEMBL ID.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    h5_path : str\n",
    "        Path to the HDF5 file containing datasets \"SMILES\" and \"X_morgan\".\n",
    "    chembl_id_set : set[str] | iterable[str]\n",
    "        ChEMBL IDs to keep.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, np.ndarray]\n",
    "        Mapping {chembl_id: fingerprint (shape (nBits,))} for IDs present in the file.\n",
    "        IDs in `chembl_id_set` that are not found are silently ignored.\n",
    "    \"\"\"\n",
    "    chembl_id_set = set(chembl_id_set)\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        ids = f[\"SMILES\"][:, 3].astype(str)\n",
    "        idx = np.flatnonzero(np.isin(ids, list(chembl_id_set)))\n",
    "        fps = f[\"X_morgan\"][idx]\n",
    "    return {ids[i]: fp for i, fp in zip(idx, fps)}\n",
    "\n",
    "def load_ecfp_all(h5_path):\n",
    "    \"\"\"Load all ECFP (Morgan count) fingerprints.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    h5_path : str\n",
    "        Path to the HDF5 file containing datasets \"SMILES\" and \"X_morgan\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, np.ndarray]\n",
    "        Mapping {chembl_id: fingerprint (np.int8, shape (nBits,))}.\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        meta = f[\"SMILES\"][:, 3].astype(str)\n",
    "        fps  = f[\"X_morgan\"][:]  # Load ALL\n",
    "\n",
    "    return {cid: fp for cid, fp in zip(meta, fps)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf386f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define root directory\n",
    "# root = os.path.dirname(os.path.abspath(__file__))\n",
    "root = \".\"\n",
    "sys.path.append(os.path.join(root, \"..\", \"src\"))\n",
    "from default import DATAPATH, CONFIGPATH\n",
    "\n",
    "# Load pathogen info\n",
    "# pathogen_code = sys.argv[1]\n",
    "pathogen_code = 'mtuberculosis'\n",
    "df = pd.read_csv(os.path.join(CONFIGPATH, 'pathogens.csv'))\n",
    "row = df.loc[df[\"code\"].eq(pathogen_code)]\n",
    "if row.empty: \n",
    "    raise SystemExit(f\"Unknown code: {pathogen_code}\")\n",
    "pathogen = row.iloc[0][\"pathogen\"]\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT = os.path.join(root, \"..\", \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9bfa2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_A(df):\n",
    "    return (\n",
    "        df[\"dataset_type\"].isin([\"quantitative\", \"mixed\"])\n",
    "        & (df[\"cpds_qt\"] >= 1000)\n",
    "        & (df[\"pos_qt\"] >= 50)\n",
    "        & (df[\"ratio_qt\"].between(0.005, 0.5, inclusive=\"both\")))\n",
    "\n",
    "def condition_B(df):\n",
    "    return (\n",
    "        df[\"dataset_type\"].isin([\"qualitative\", \"mixed\"])\n",
    "        & (df[\"cpds_ql\"] >= 1000)\n",
    "        & (df[\"pos_ql\"] >= 50)\n",
    "        & (df[\"ratio_ql\"].between(0.005, 0.5, inclusive=\"both\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fcb9304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ECFP6s...\n"
     ]
    }
   ],
   "source": [
    "# Create path to correlations\n",
    "PATH_TO_CORRELATIONS = os.path.join(OUTPUT, pathogen_code, \"correlations\")\n",
    "os.makedirs(PATH_TO_CORRELATIONS, exist_ok=True)\n",
    "\n",
    "# Load assay data: cleaned, parameters and datasets\n",
    "ASSAYS_CLEANED = pd.read_csv(os.path.join(OUTPUT, pathogen_code, \"assays_cleaned.csv\"))\n",
    "ASSAYS_PARAMETERS = pd.read_csv(os.path.join(OUTPUT, pathogen_code, \"assays_parameters.csv\"))\n",
    "COLS = [\"assay_id\", \"activity_type\", \"unit\", \"target_type\", \"target_type_curated_extra\", \"cpds\", \n",
    "        \"direction\", \"dataset_type\", \"expert_cutoff\", \"pos_qt\", \"ratio_qt\", \"cpds_qt\", \"pos_ql\", \"ratio_ql\", \"cpds_ql\"]\n",
    "ASSAYS_DATASETS = pd.read_csv(os.path.join(OUTPUT, pathogen_code, \"assays_datasets.csv\"))[COLS]\n",
    "\n",
    "# Create reference set of compounds per pathogen\n",
    "compounds = pd.read_csv(os.path.join(OUTPUT, pathogen_code, \"compound_counts.csv.gz\"))\n",
    "REFERENCE_SET = get_reference_set_compounds(compounds)\n",
    "pd.DataFrame(REFERENCE_SET, columns=['reference_smiles']).to_csv(os.path.join(OUTPUT, pathogen_code, \"reference_set.csv.gz\"))\n",
    "\n",
    "# Get all compounds for pathogen\n",
    "compounds = set(compounds['compound_chembl_id'])\n",
    "print(f\"Loading ECFP6s...\")\n",
    "\n",
    "# Loading Morgan fingerprints\n",
    "PATH_TO_ECFPs = os.path.join(DATAPATH, \"chembl_processed\", \"ChEMBL_ECFPs.h5\")\n",
    "ecfps = load_ecfp_all(PATH_TO_ECFPs)\n",
    "\n",
    "# Prepare reference matrix of Morgan fingerprints\n",
    "X_REF = np.array([ecfps[cid] for cid in REFERENCE_SET if cid in ecfps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9f1a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KFoldTrain(X, Y, n_splits=4, n_estimators=100, random_state=42):\n",
    "    \"\"\"Stratified K-fold training/eval with RandomForest; returns mean AUROC and std.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        Feature matrix (n_samples, n_features).\n",
    "    Y : np.ndarray\n",
    "        Binary labels (n_samples,).\n",
    "    n_splits : int\n",
    "        Number of folds.\n",
    "    n_estimators : int\n",
    "        Number of trees in the random forest.\n",
    "    random_state : int\n",
    "        RNG seed (also used for fold shuffling).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[float, float]\n",
    "        (mean_auroc, std_auroc) rounded to 3 decimals.\n",
    "    \"\"\"\n",
    "    def init_RF():\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_features=\"sqrt\",\n",
    "            n_jobs=8,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    aurocs = []\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X, Y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "        rf = init_RF()\n",
    "        rf.fit(X_train, Y_train)\n",
    "        y_prob = rf.predict_proba(X_test)[:, 1]\n",
    "        aurocs.append(roc_auc_score(Y_test, y_prob))\n",
    "\n",
    "    return round(float(np.mean(aurocs)), 3), round(float(np.std(aurocs)), 3)\n",
    "\n",
    "def TrainRF(X, Y, n_estimators=100):\n",
    "    \"\"\"Train a RandomForestClassifier on all provided data and return the fitted model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        Feature matrix (n_samples, n_features).\n",
    "    Y : np.ndarray\n",
    "        Labels (n_samples,).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    RandomForestClassifier\n",
    "        Fitted classifier.\n",
    "    \"\"\"\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        max_features=\"sqrt\",\n",
    "        n_jobs=8,\n",
    "    )\n",
    "    rf.fit(X, Y)\n",
    "    return rf\n",
    "\n",
    "def load_data_from_zip(zip_path, filename):\n",
    "    \"\"\"Load a gzipped CSV file from a ZIP archive into a pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    zip_path : str\n",
    "        Path to the ZIP archive.\n",
    "    filename : str\n",
    "        Name of the gzipped CSV file inside the ZIP.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Loaded data.\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zip_path) as z:\n",
    "        with z.open(filename) as raw:\n",
    "            with gzip.open(raw, mode=\"rt\") as f:\n",
    "                df = pd.read_csv(f)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94300836",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG, STD = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce0619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assay ID: CHEMBL4649948, Activity type: PERCENTEFFECT, Unit: %, Cutoff: 25.0\n",
      "(86589, 2048) (86589,) Positives: 4405 (0.051%)\n"
     ]
    }
   ],
   "source": [
    "LABEL = \"A\"\n",
    "ASSAYS_DATASETS[LABEL] = condition_A(ASSAYS_DATASETS)\n",
    "\n",
    "AVG[LABEL] = []\n",
    "STD[LABEL] = []\n",
    "\n",
    "# Iterate over assays A\n",
    "for c, assay in ASSAYS_DATASETS.iterrows():\n",
    "\n",
    "    if assay.A is False:\n",
    "\n",
    "        AVG[LABEL].append(np.nan)\n",
    "        STD[LABEL].append(np.nan)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Load varibles\n",
    "        assay_id = assay.assay_id\n",
    "        activity_type = assay.activity_type\n",
    "        unit = assay.unit\n",
    "        expert_cutoff = assay.expert_cutoff\n",
    "        \n",
    "        # Load data\n",
    "        zip_path = os.path.join(OUTPUT, pathogen_code, \"datasets\", \"datasets_qt.zip\")\n",
    "        filename = \"_\".join([str(assay_id), str(activity_type), str(unit), \"qt\", f\"{expert_cutoff}.csv.gz\"])\n",
    "        df = load_data_from_zip(zip_path, filename)\n",
    "\n",
    "        # Prepare matrices\n",
    "        X = np.array(df['compound_chembl_id'].map(ecfps).to_list())\n",
    "        Y = np.array(df['bin'].tolist())\n",
    "\n",
    "        print(f\"Assay ID: {assay_id}, Activity type: {activity_type}, Unit: {unit}, Cutoff: {expert_cutoff}\")\n",
    "        print(X.shape, Y.shape, f\"Positives: {sum(Y)} ({round(sum(Y) / len(Y),3)}%)\")\n",
    "\n",
    "        # 4Fold Cros Validation\n",
    "        average_auroc, stds = KFoldTrain(X, Y, n_splits=4, n_estimators=10)\n",
    "        print(f\"Mean AUROC: {average_auroc} Â± {stds}\")\n",
    "        AVG[LABEL].append(average_auroc)\n",
    "        STD[LABEL].append(stds)\n",
    "\n",
    "        # If performance is good enough, train on full data and predict on reference set\n",
    "        if average_auroc > 0.7:\n",
    "            RF = TrainRF(X, Y, n_estimators=10)\n",
    "            y_prob_ref = RF.predict_proba(X_REF)[:, 1]\n",
    "            os.makedirs(os.path.join(PATH_TO_CORRELATIONS, LABEL), exist_ok=True)\n",
    "            np.savez_compressed(os.path.join(PATH_TO_CORRELATIONS, LABEL, filename.replace(\".csv.gz\", \"_ref_probs.npz\")), y_prob_ref=y_prob_ref)\n",
    "\n",
    "ASSAYS_DATASETS[f'{LABEL}_AVG'] = AVG[LABEL]\n",
    "ASSAYS_DATASETS[f'{LABEL}_STD'] = STD[LABEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac15701",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSAYS_DATASETS[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7880cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSAYS_DATASETS['B'] = condition_B(ASSAYS_DATASETS)\n",
    "ASSAYS_DATASETS.loc[ASSAYS_DATASETS[\"A_AVG\"] > 0.7, \"B\"] = False\n",
    "\n",
    "B_AVG, B_STD = [], []\n",
    "\n",
    "# Iterate over assays B\n",
    "for c, assay in ASSAYS_DATASETS.iterrows():\n",
    "\n",
    "    if assay.B is False:\n",
    "\n",
    "        B_AVG.append(np.nan)\n",
    "        B_STD.append(np.nan)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Load varibles\n",
    "        assay_id = assay.assay_id\n",
    "        activity_type = assay.activity_type\n",
    "        unit = assay.unit\n",
    "        expert_cutoff = assay.expert_cutoff\n",
    "        \n",
    "        # Load data\n",
    "        zip_path = os.path.join(OUTPUT, pathogen_code, \"datasets\", \"datasets_ql.zip\")\n",
    "        filename = \"_\".join([str(assay_id), str(activity_type), str(unit), \"ql\", f\"{expert_cutoff}.csv.gz\"])\n",
    "        df = load_data_from_zip(zip_path, filename)\n",
    "\n",
    "        # Prepare matrices\n",
    "        X = np.array(df['compound_chembl_id'].map(ecfps).to_list())\n",
    "        Y = np.array(df['bin'].tolist())\n",
    "\n",
    "        print(f\"Assay ID: {assay_id}, Activity type: {activity_type}, Unit: {unit}, Cutoff: {expert_cutoff}\")\n",
    "        print(X.shape, Y.shape, f\"Positives: {sum(Y)} ({round(sum(Y) / len(Y),3)}%)\")\n",
    "\n",
    "        # Shuffle systematically\n",
    "        rng = np.random.default_rng(42)   # fixed seed\n",
    "        idx = rng.permutation(len(Y))\n",
    "        X = X[idx]\n",
    "        Y = Y[idx]\n",
    "\n",
    "        # 4Fold Cros Validation\n",
    "        average_auroc, stds = KFoldTrain(X, Y)\n",
    "        A_AVG.append(average_auroc)\n",
    "        A_STD.append(stds)\n",
    "\n",
    "        # If performance is good enough, train on full data and predict on reference set\n",
    "        if average_auroc > 0.7:\n",
    "            RF = Train(X, Y)\n",
    "            y_prob_ref = RF.predict_proba(X_REF)[:, 1]\n",
    "            np.savez_compressed(os.path.join(PATH_TO_CORRELATIONS_A, filename.replace(\".csv.gz\", \"_ref_probs.npz\")), y_prob_ref=y_prob_ref)\n",
    "\n",
    "ASSAYS_DATASETS['B_AVG'] = B_AVG\n",
    "ASSAYS_DATASETS['B_STD'] = B_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f0084",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSAYS_DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a6fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f114ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5270dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
