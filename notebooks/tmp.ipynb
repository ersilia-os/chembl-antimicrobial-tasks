{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b6e064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def adjust_relation(ASSAY_DATA: pd.DataFrame, DIRECTION: int, CUT: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adjust relations in an assay DataFrame according to the biological direction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pd.DataFrame\n",
    "        Must contain the columns 'relation' and 'value'.\n",
    "    DIRECTION : int\n",
    "        +1 → higher = more active (e.g. % inhibition)\n",
    "        -1 → lower = more active (e.g. IC50, MIC)\n",
    "    CUT : float\n",
    "        Extreme value used to replace censored measurements\n",
    "        on the wrong side of the direction (min or max)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Copy of ASSAY_DATA with adjusted relation and value.\n",
    "    \"\"\"\n",
    "\n",
    "    df = ASSAY_DATA.copy()\n",
    "    rel = df[\"relation\"].astype(str)\n",
    "\n",
    "    if DIRECTION == +1:\n",
    "\n",
    "        # Higher = more active\n",
    "        mask_gt = rel == \">\"  # greater than\n",
    "        mask_lt = rel == \"<\"  # lower than\n",
    "\n",
    "        df.loc[mask_gt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_lt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_lt, \"value\"] = CUT\n",
    "\n",
    "    elif DIRECTION == -1:\n",
    "\n",
    "        # Lower = more active\n",
    "        mask_lt = rel == \"<\"  # lower than\n",
    "        mask_gt = rel == \">\"  # greater than\n",
    "\n",
    "        df.loc[mask_lt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_gt, \"relation\"] = \"=\"\n",
    "        df.loc[mask_gt, \"value\"] = CUT\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise ValueError(f\"Invalid DIRECTION={DIRECTION}. Expected +1 or -1.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def disambiguate_compounds(ASSAY_DATA: pd.DataFrame, DIRECTION: int) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Select a single measurement per compound according to the biological direction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pd.DataFrame\n",
    "        Must contain the columns 'compound_chembl_id' and 'value'.\n",
    "        Assumes all relations have already been adjusted.\n",
    "    DIRECTION : int\n",
    "        +1 → higher = more active (e.g. % inhibition)\n",
    "        -1 → lower = more active (e.g. IC50, MIC)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A copy of ASSAY_DATA in which duplicated compounds \n",
    "        ('compound_chembl_id') are removed, keeping only the \n",
    "        most active measurement per compound (highest or lowest \n",
    "        depending on DIRECTION).\n",
    "    \"\"\"\n",
    "\n",
    "    if DIRECTION not in [1, -1]:\n",
    "        raise ValueError(\"DIRECTION must be +1 (higher = more active) or -1 (lower = more active).\")\n",
    "        \n",
    "    df = ASSAY_DATA.copy()\n",
    "\n",
    "    # Choose best measurement based on direction\n",
    "    if DIRECTION == -1:\n",
    "        # Lower = more active → keep minimum\n",
    "        df_sorted = df.sort_values(by=\"value\", ascending=True)\n",
    "    elif DIRECTION == 1:\n",
    "        # Higher = more active → keep maximum\n",
    "        df_sorted = df.sort_values(by=\"value\", ascending=False)\n",
    "\n",
    "    # Keep the best row per compound_chembl_id\n",
    "    df_best = df_sorted.drop_duplicates(subset=\"compound_chembl_id\", keep=\"first\")\n",
    "\n",
    "    return df_best.reset_index(drop=True)\n",
    "\n",
    "def add_target_type_curated(ASSAYS_CLEANED, PATH_TO_PARAMETERS):\n",
    "    \"\"\"\n",
    "    Add a `target_type_curated` column to ASSAYS_CLEANED by reading curated assay\n",
    "    parameters from the consolidated CSV produced in Step 11.\n",
    "\n",
    "    For each row in ASSAYS_CLEANED, the function matches on the keys:\n",
    "        [`assay_id`, `activity_type`, `unit`]\n",
    "\n",
    "    and pulls the corresponding value from the `target_type_curated` column in\n",
    "    `assays_parameters.csv`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAYS_CLEANED : pandas.DataFrame\n",
    "        DataFrame containing at least the columns: `assay_id`, `activity_type`, `unit`.\n",
    "    PATH_TO_PARAMETERS : str\n",
    "        Path to the consolidated parameters CSV file (e.g., `assays_parameters.csv`).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The same dataframe with an added `target_type_curated` column (left-joined).\n",
    "        Rows with no match will have `target_type_curated` as NaN.\n",
    "    \"\"\"\n",
    "    # Load only the columns we need from the parameters table\n",
    "    PARAMETERS = pd.read_csv(PATH_TO_PARAMETERS, usecols=[\"assay_id\", \"activity_type\", \"unit\", \"target_type_curated\"])\n",
    "\n",
    "    # Match writer behavior from Step 11: missing units are stored as empty strings\n",
    "    ASSAYS_CLEANED = ASSAYS_CLEANED.copy()\n",
    "    ASSAYS_CLEANED[\"unit\"] = ASSAYS_CLEANED[\"unit\"].fillna(\"\")\n",
    "    PARAMETERS[\"unit\"] = PARAMETERS[\"unit\"].fillna(\"\")\n",
    "\n",
    "    # Check that everything in PARAMETERS actually maps to ASSAYS_CLEANED\n",
    "    if not PARAMETERS[[\"assay_id\",\"activity_type\",\"unit\"]].merge(\n",
    "        ASSAYS_CLEANED[[\"assay_id\",\"activity_type\",\"unit\"]],\n",
    "        on=[\"assay_id\",\"activity_type\",\"unit\"],\n",
    "        how=\"left\",\n",
    "        indicator=True\n",
    "    )[\"_merge\"].eq(\"both\").all():\n",
    "        raise ValueError(\"PARAMETERS contains keys not present in ASSAYS_CLEANED\")\n",
    "\n",
    "    # Merge curated target type onto the cleaned assays table\n",
    "    ASSAYS_CLEANED = ASSAYS_CLEANED.merge(PARAMETERS, on=[\"assay_id\", \"activity_type\", \"unit\"], how=\"left\", validate=\"1:1\")\n",
    "\n",
    "    return ASSAYS_CLEANED\n",
    "\n",
    "def load_expert_cutoffs(CONFIGPATH):\n",
    "    \"\"\"\n",
    "    Load expert cutoffs from the manual curation CSV and return them as a dictionary.\n",
    "\n",
    "    The CSV is expected at:\n",
    "        {CONFIGPATH}/manual_curation/expert_cutoffs.csv\n",
    "\n",
    "    The returned dictionary maps:\n",
    "        (activity_type, unit, target_type, pathogen_code) -> expert_cutoff\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    CONFIGPATH : str\n",
    "        Path to the config folder.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary of expert cutoffs keyed by\n",
    "        (activity_type, unit, target_type, pathogen_code).\n",
    "    \"\"\"\n",
    "    # Load expert cut-offs\n",
    "    EXPERT_CUTOFFS = pd.read_csv(os.path.join(CONFIGPATH, \"expert_cutoffs.csv\"))\n",
    "\n",
    "    EXPERT_CUTOFFS = {\n",
    "        (a, b, c, d): [float(k) for k in e.split(\";\")]\n",
    "        for a, b, c, d, e in EXPERT_CUTOFFS[\n",
    "            [\"activity_type\", \"unit\", \"target_type\", \"pathogen_code\", \"expert_cutoff\"]\n",
    "        ].values\n",
    "    }\n",
    "\n",
    "    return EXPERT_CUTOFFS\n",
    "\n",
    "def get_assay_data(ChEMBL_pathogen, assay_chembl_id, activity_type, unit, cols):\n",
    "    \"\"\"\n",
    "    Extract assay activity data for a given assay_chembl_id, activity_type, and unit.\n",
    "\n",
    "    If `unit` is a string, the function filters rows where `unit` matches exactly.\n",
    "    Otherwise, it filters rows where `unit` is missing (NaN).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ChEMBL_pathogen : pandas.DataFrame\n",
    "        DataFrame containing ChEMBL pathogen activity records.\n",
    "    assay_chembl_id : str\n",
    "        Assay ChEMBL ID to filter on.\n",
    "    activity_type : str\n",
    "        Activity type to filter on (e.g., IC50, MIC).\n",
    "    unit : str or None\n",
    "        Unit to filter on; if not a string, NaN units are selected.\n",
    "    cols : list\n",
    "        List of columns to return.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Filtered assay activity data with only the requested columns.\n",
    "    \"\"\"\n",
    "    if type(unit) == str:\n",
    "        ASSAY_DATA = ChEMBL_pathogen[\n",
    "            (ChEMBL_pathogen['assay_chembl_id'] == assay_chembl_id) &\n",
    "            (ChEMBL_pathogen['activity_type'] == activity_type) &\n",
    "            (ChEMBL_pathogen['unit'] == unit)\n",
    "        ].reset_index(drop=True)[cols]\n",
    "    else:\n",
    "        ASSAY_DATA = ChEMBL_pathogen[\n",
    "            (ChEMBL_pathogen['assay_chembl_id'] == assay_chembl_id) &\n",
    "            (ChEMBL_pathogen['activity_type'] == activity_type) &\n",
    "            (ChEMBL_pathogen['unit'].isna())\n",
    "        ].reset_index(drop=True)[cols]\n",
    "\n",
    "    return ASSAY_DATA\n",
    "\n",
    "def get_cut_value(ASSAY_DATA, direction):\n",
    "    \"\"\"\n",
    "    Get a cutoff value from ASSAY_DATA to adjust relations based on direction.\n",
    "\n",
    "    If direction == 1, returns the minimum value in ASSAY_DATA['value'].\n",
    "    If direction == -1, returns the maximum value in ASSAY_DATA['value'].\n",
    "    Otherwise, returns np.nan.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pandas.DataFrame\n",
    "        DataFrame containing a 'value' column with numeric assay values.\n",
    "    direction : int\n",
    "        Direction indicator:\n",
    "        - 1  -> use minimum value\n",
    "        - -1 -> use maximum value\n",
    "        - else -> np.nan\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Cutoff value computed from the 'value' column or np.nan.\n",
    "    \"\"\"\n",
    "    if direction == 1:\n",
    "        CUT = min(ASSAY_DATA['value'])\n",
    "    elif direction == -1:\n",
    "        CUT = max(ASSAY_DATA['value'])\n",
    "    else:\n",
    "        CUT = np.nan\n",
    "\n",
    "    return CUT\n",
    "\n",
    "def count_relations(ASSAY_DATA):\n",
    "    \"\"\"\n",
    "    Count relation operators in ASSAY_DATA['relation'].\n",
    "\n",
    "    Counts how many times each of the following appears:\n",
    "        \"=\" , \"<\" , \">\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pandas.DataFrame\n",
    "        DataFrame containing a 'relation' column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (equal, lower, higher) counts corresponding to \"=\", \"<\", \">\".\n",
    "    \"\"\"\n",
    "    counter_relations = Counter(ASSAY_DATA['relation'].tolist())\n",
    "    equal = counter_relations[\"=\"]\n",
    "    lower = counter_relations[\"<\"]\n",
    "    higher = counter_relations[\">\"]\n",
    "\n",
    "    return equal, lower, higher\n",
    "\n",
    "def get_assay_data_quantitative(ASSAY_DATA):\n",
    "    \"\"\"\n",
    "    Return only rows in ASSAY_DATA with non-missing quantitative values.\n",
    "\n",
    "    Filters ASSAY_DATA to keep rows where `value` is not NaN, and resets the index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ASSAY_DATA : pandas.DataFrame\n",
    "        DataFrame containing a 'value' column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Filtered dataframe containing only rows with non-null `value`.\n",
    "    \"\"\"\n",
    "    ASSAY_DATA_QUANTITATIVE = ASSAY_DATA[ASSAY_DATA['value'].isna() == False].reset_index(drop=True)\n",
    "    ASSAY_DATA_QUANTITATIVE = ASSAY_DATA_QUANTITATIVE.drop(columns=['text_flag'])\n",
    "    return ASSAY_DATA_QUANTITATIVE\n",
    "\n",
    "def get_assay_data_qualitative(ASSAY_DATA):\n",
    "\n",
    "    ASSAY_DATA_QUALITATIVE = ASSAY_DATA.copy()\n",
    "\n",
    "    # Aggregate to compound-level label\n",
    "    compound_labels = ASSAY_DATA_QUALITATIVE.groupby(\"compound_chembl_id\")[\"text_flag\"].apply(set)\n",
    "\n",
    "    # Detect compound-level conflicts (same compound has 1 and -1)\n",
    "    compound_ids = compound_labels.index.tolist()\n",
    "    label_sets = compound_labels.tolist()\n",
    "    compound_conflict = [((1 in s) and (-1 in s)) for s in label_sets]\n",
    "    if any(compound_conflict):\n",
    "        bad = [(cid, s) for cid, s, c in zip(compound_ids, label_sets, compound_conflict) if c][:20]\n",
    "        raise ValueError(\n",
    "            \"Conflicting compound labels (same compound has both 1 and -1 across rows):\\n\"\n",
    "            + \"\\n\".join([f\"{cid}: {s}\" for cid, s in bad]))\n",
    "\n",
    "    # Final compound label: 1 > -1 > 0\n",
    "    compound_final = [1 if 1 in s else (-1 if -1 in s else 0) for s in label_sets]\n",
    "    compound_final = dict(zip(compound_ids, compound_final))\n",
    "\n",
    "    # Assign back to all rows\n",
    "    ASSAY_DATA_QUALITATIVE[\"qualitative_label\"] = ASSAY_DATA_QUALITATIVE[\"compound_chembl_id\"].map(compound_final)\n",
    "\n",
    "    # Keep only one row per compound\n",
    "    ASSAY_DATA_QUALITATIVE = ASSAY_DATA_QUALITATIVE.drop_duplicates(subset=[\"compound_chembl_id\"]).reset_index(drop=True)\n",
    "\n",
    "    # Remove compounds labeled as 0\n",
    "    ASSAY_DATA_QUALITATIVE = ASSAY_DATA_QUALITATIVE[ASSAY_DATA_QUALITATIVE[\"qualitative_label\"] != 0].reset_index(drop=True)\n",
    "\n",
    "    # Binary label\n",
    "    ASSAY_DATA_QUALITATIVE[\"bin\"] = [0 if x == -1 else 1 for x in ASSAY_DATA_QUALITATIVE[\"qualitative_label\"].tolist()]\n",
    "\n",
    "    # Take only interesting columns\n",
    "    cols = [\"compound_chembl_id\", \"canonical_smiles\", \"activity_type\", \"unit\", \"text_flag\", \"qualitative_label\", 'bin'] \n",
    "    ASSAY_DATA_QUALITATIVE = ASSAY_DATA_QUALITATIVE[cols]\n",
    "\n",
    "    return ASSAY_DATA_QUALITATIVE\n",
    "    \n",
    "def set_variables_quantitative(ASSAY_DATA_QUANTITATIVE):\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \"\"\"\n",
    "\n",
    "    positives_quantitative = (ASSAY_DATA_QUANTITATIVE[\"bin\"] == 1).sum()\n",
    "    ratio_quantitative = round(positives_quantitative / len(ASSAY_DATA_QUANTITATIVE), 3)\n",
    "    compounds_quantitative = len(set(ASSAY_DATA_QUANTITATIVE['compound_chembl_id']))\n",
    "    activities_quantitative = ASSAY_DATA_QUANTITATIVE['value'].tolist()\n",
    "    assert compounds_quantitative == len(activities_quantitative)\n",
    "\n",
    "    return positives_quantitative, ratio_quantitative, compounds_quantitative, activities_quantitative\n",
    "\n",
    "def set_variables_qualitative(ASSAY_DATA_QUALITATIVE):\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \"\"\"\n",
    "    positives_qualitative = (ASSAY_DATA_QUALITATIVE[\"bin\"] == 1).sum()\n",
    "    ratio_qualitative = round(positives_qualitative / len(ASSAY_DATA_QUALITATIVE), 3)\n",
    "    compounds_qualitative = len(set(ASSAY_DATA_QUALITATIVE['compound_chembl_id']))\n",
    "    assert compounds_qualitative == len(ASSAY_DATA_QUALITATIVE)\n",
    "\n",
    "    return positives_qualitative, ratio_qualitative, compounds_qualitative\n",
    "\n",
    "def binarize_with_expert_cutoff(ASSAY_DATA_QUANTITATIVE, expert_cutoff, direction):\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \"\"\"\n",
    "    if direction == +1:\n",
    "        ASSAY_DATA_QUANTITATIVE[\"bin\"] = (ASSAY_DATA_QUANTITATIVE[\"value\"] >= expert_cutoff).astype(int)\n",
    "    else:\n",
    "        ASSAY_DATA_QUANTITATIVE[\"bin\"] = (ASSAY_DATA_QUANTITATIVE[\"value\"] <= expert_cutoff).astype(int)\n",
    "\n",
    "    return ASSAY_DATA_QUANTITATIVE\n",
    "\n",
    "def get_activity_stats_quantitative(activities_quantitative):\n",
    "    \"\"\"\n",
    "    Compute summary statistics for quantitative activities.\n",
    "\n",
    "    Calculates min, 1st percentile, 25th percentile, median (50th),\n",
    "    75th percentile, 99th percentile, and max, rounded to 3 decimals.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    activities_quantitative : array-like\n",
    "        Iterable of numeric activity values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (min_, p1, p25, p50, p75, p99, max_)\n",
    "    \"\"\"\n",
    "    min_ = round(np.min(activities_quantitative), 3)\n",
    "    p1 = round(np.percentile(activities_quantitative, 1), 3)\n",
    "    p25 = round(np.percentile(activities_quantitative, 25), 3)\n",
    "    p50 = round(np.percentile(activities_quantitative, 50), 3)\n",
    "    p75 = round(np.percentile(activities_quantitative, 75), 3)\n",
    "    p99 = round(np.percentile(activities_quantitative, 99), 3)\n",
    "    max_ = round(np.max(activities_quantitative), 3)\n",
    "\n",
    "    return min_, p1, p25, p50, p75, p99, max_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fb744d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ChEMBL cleaned data for mtuberculosis...\n",
      "Number of activities for mtuberculosis: 716150\n",
      "Number of compounds for mtuberculosis: 137607\n",
      "Number of cleaned assays: 10532\n"
     ]
    }
   ],
   "source": [
    "# Define root directory\n",
    "# root = os.path.dirname(os.path.abspath(__file__))\n",
    "root = \".\"\n",
    "sys.path.append(os.path.join(root, \"..\", \"src\"))\n",
    "from default import DATAPATH, CONFIGPATH\n",
    "\n",
    "# Load pathogen info\n",
    "# pathogen_code = sys.argv[1]\n",
    "pathogen_code = 'mtuberculosis'\n",
    "df = pd.read_csv(os.path.join(CONFIGPATH, 'pathogens.csv'))\n",
    "row = df.loc[df[\"code\"].eq(pathogen_code)]\n",
    "if row.empty: \n",
    "    raise SystemExit(f\"Unknown code: {pathogen_code}\")\n",
    "pathogen = row.iloc[0][\"pathogen\"]\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT = os.path.join(root, \"..\", \"output\")\n",
    "\n",
    "# Load cleaned assays\n",
    "ASSAYS_CLEANED = pd.read_csv(os.path.join(root, \"..\", \"output\", pathogen_code, \"assays_cleaned.csv\"))\n",
    "\n",
    "# Define PATH to parameters\n",
    "PATH_TO_PARAMETERS = os.path.join(root, \"..\", \"output\", pathogen_code, 'assays_parameters.csv')\n",
    "\n",
    "# Get curated target type\n",
    "ASSAYS_CLEANED = add_target_type_curated(ASSAYS_CLEANED, PATH_TO_PARAMETERS)\n",
    "\n",
    "# Loading pathogen data\n",
    "os.makedirs(os.path.join(OUTPUT, pathogen_code, 'datasets'), exist_ok=True)\n",
    "print(f\"Loading ChEMBL cleaned data for {pathogen_code}...\")\n",
    "ChEMBL_pathogen = pd.read_csv(os.path.join(OUTPUT, pathogen_code, f\"{pathogen_code}_ChEMBL_cleaned_data.csv.gz\"), low_memory=False)\n",
    "print(f\"Number of activities for {pathogen_code}: {len(ChEMBL_pathogen)}\")\n",
    "print(f\"Number of compounds for {pathogen_code}: {len(set(ChEMBL_pathogen['compound_chembl_id']))}\")\n",
    "print(f\"Number of cleaned assays: {len(ASSAYS_CLEANED)}\")\n",
    "\n",
    "# Load expert cut-offs\n",
    "EXPERT_CUTOFFS = load_expert_cutoffs(CONFIGPATH)\n",
    "\n",
    "# Get assay to index mapping\n",
    "assay_to_idx = defaultdict(list)\n",
    "for i, assay_id in enumerate(ChEMBL_pathogen[\"assay_chembl_id\"].to_numpy()):\n",
    "    assay_to_idx[assay_id].append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "664b517e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10532 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define data ranges\n",
    "DATA_RANGES = []\n",
    "\n",
    "for assay_chembl_id, activity_type, unit, target_type, target_type_curated, activities, nan_values, cpds, direction, act_flag, inact_flag in tqdm(ASSAYS_CLEANED[['assay_id', \n",
    "                                    'activity_type', 'unit', 'target_type','target_type_curated', 'activities', 'nan_values', 'cpds', 'direction', \n",
    "                                    'act_flag', 'inact_flag']].values[:]):\n",
    "\n",
    "    # Filtering [assay, activity_type, unit] data\n",
    "    cols = ['compound_chembl_id', 'canonical_smiles', 'activity_type', 'value', 'relation', 'unit', 'text_flag']\n",
    "    tmp_df = ChEMBL_pathogen.iloc[assay_to_idx[assay_chembl_id]]    \n",
    "    ASSAY_DATA = get_assay_data(tmp_df, assay_chembl_id, activity_type, unit, cols)\n",
    "    \n",
    "    # Count relations\n",
    "    equal, lower, higher = count_relations(ASSAY_DATA)\n",
    "\n",
    "    # Qualitative view\n",
    "    ASSAY_DATA_QUALITATIVE = get_assay_data_qualitative(ASSAY_DATA)\n",
    "\n",
    "    # Setting up some variables\n",
    "    if len(ASSAY_DATA_QUALITATIVE) > 0:\n",
    "        positives_qualitative, ratio_qualitative, compounds_qualitative = set_variables_qualitative(ASSAY_DATA_QUALITATIVE)\n",
    "    else:\n",
    "        positives_qualitative, ratio_qualitative, compounds_qualitative = [np.nan] * 3\n",
    "\n",
    "    # Quantitative view\n",
    "    ASSAY_DATA_QUANTITATIVE = get_assay_data_quantitative(ASSAY_DATA)\n",
    "\n",
    "    # Get expert cut-offs if existing\n",
    "    key = (activity_type, unit, target_type_curated, pathogen_code)\n",
    "    expert_cutoffs = EXPERT_CUTOFFS[key] if key in EXPERT_CUTOFFS else [np.nan]\n",
    "\n",
    "    # For each expert_cutoff\n",
    "    for expert_cutoff in expert_cutoffs:\n",
    "\n",
    "        # If expert cutoff is nan\n",
    "        if np.isnan(expert_cutoff) == True or direction not in [-1, +1]:\n",
    "\n",
    "            # Quantitative binarization is not possible\n",
    "            positives_quantitative = np.nan\n",
    "            ratio_quantitative = np.nan\n",
    "            compounds_quantitative = len(set(ASSAY_DATA_QUANTITATIVE['compound_chembl_id']))\n",
    "            activities_quantitative = len(ASSAY_DATA_QUANTITATIVE)\n",
    "            min_, p1, p25, p50, p75, p99, max_ = get_activity_stats_quantitative(activities_quantitative)\n",
    "\n",
    "            # Assess qualitative compounds\n",
    "            if np.isnan(compounds_qualitative):\n",
    "                dataset_type = 'none'\n",
    "            else:\n",
    "                dataset_type = 'qualitative'\n",
    "\n",
    "        else:\n",
    "\n",
    "            if len(ASSAY_DATA_QUANTITATIVE) > 0:\n",
    "\n",
    "                # Get value to adjust relations\n",
    "                CUT = get_cut_value(ASSAY_DATA, direction)\n",
    "\n",
    "                # Adjust relation\n",
    "                ASSAY_DATA_QUANTITATIVE = adjust_relation(ASSAY_DATA_QUANTITATIVE, direction, CUT)\n",
    "\n",
    "                # Disambiguate duplicated compounds and returns 'sorted' data (depending on direction)\n",
    "                ASSAY_DATA_QUANTITATIVE = disambiguate_compounds(ASSAY_DATA_QUANTITATIVE, direction)\n",
    "\n",
    "                # Binarization with expert cut-off\n",
    "                ASSAY_DATA_QUANTITATIVE = binarize_with_expert_cutoff(ASSAY_DATA_QUANTITATIVE, expert_cutoff, direction)\n",
    "\n",
    "                # Setting up some variables\n",
    "                positives_quantitative, ratio_quantitative, compounds_quantitative, activities_quantitative = set_variables_quantitative(ASSAY_DATA_QUANTITATIVE)\n",
    "\n",
    "                # Get activity stats\n",
    "                min_, p1, p25, p50, p75, p99, max_ = get_activity_stats_quantitative(activities_quantitative)\n",
    "\n",
    "                if np.isnan(compounds_qualitative):\n",
    "                    dataset_type = 'quantitative'\n",
    "                else:\n",
    "                    dataset_type = 'mixed'\n",
    "\n",
    "\n",
    "            else:\n",
    "                if np.isnan(compounds_qualitative):\n",
    "                    ValueError(\"Dataset does not have numerical values nor activity flags. By definition, this is not possible at this stage. Please revise.\")\n",
    "                else:\n",
    "                    dataset_type = 'qualitative'\n",
    "\n",
    "        # Store data range\n",
    "        DATA_RANGES.append([assay_chembl_id, activity_type, unit, target_type, target_type_curated, activities, nan_values, cpds, direction, act_flag, inact_flag, equal, higher, lower, dataset_type, \n",
    "                            expert_cutoff, positives_quantitative, ratio_quantitative, compounds_quantitative, min_, p1, p25, p50, p75, p99, max_, positives_qualitative, \n",
    "                            ratio_qualitative, compounds_qualitative])\n",
    "\n",
    "    break\n",
    "\n",
    "\n",
    "DATA_RANGES = pd.DataFrame(DATA_RANGES, columns=[\"assay_id\", \"activity_type\", \"unit\", \"target_type\", \"target_type_curated\", \"activities\", \"nan_values\", \"cpds\", \"direction\", \n",
    "                                                    'act_flag', 'inact_flag', \"equal\", \"higher\", \"lower\", \"dataset_type\", \"expert_cutoff\", \"pos_qt\", \n",
    "                                                    \"ratio_qt\", \"cpds_qt\", \"min_\", \"p1\", \"p25\", \"p50\", \"p75\", \"p99\", \"max_\", \"pos_ql\", \"ratio_ql\", \"cpds_ql\"])\n",
    "# DATA_RANGES.to_csv(os.path.join(OUTPUT, pathogen_code, 'assays_data.csv'), index=False)\n",
    "\n",
    "\n",
    "#         # Save data only if number of compounds is >= 100\n",
    "#         dataset_name = f\"{assay_chembl_id}_{activity_type}_{str(unit).replace('/', 'FwdS')}\"\n",
    "#         if compounds_quantitative >= 1 and np.isnan(expert_cutoff) == False:\n",
    "#             ASSAY_DATA_QUANTITATIVE.to_csv(os.path.join(OUTPUT, pathogen_code, 'datasets', f\"{dataset_name}_qt.csv.gz\"), index=False)\n",
    "#         if compounds_qualitative >= 1:\n",
    "#             ASSAY_DATA_QUALITATIVE.to_csv(os.path.join(OUTPUT, pathogen_code, 'datasets', f\"{dataset_name}_ql.csv.gz\"), index=False)\n",
    "#         # if compounds_quantitative >= 100 and np.isnan(expert_cutoff) == False:\n",
    "#         #     ASSAY_DATA_QUANTITATIVE.to_csv(os.path.join(OUTPUT, pathogen_code, 'datasets', f\"{dataset_name}_qt.csv.gz\"), index=False)\n",
    "#         # if compounds_qualitative >= 100:\n",
    "#         #     ASSAY_DATA_QUALITATIVE.to_csv(os.path.join(OUTPUT, pathogen_code, 'datasets', f\"{dataset_name}_ql.csv.gz\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcdcbf76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assay_id</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>unit</th>\n",
       "      <th>target_type</th>\n",
       "      <th>target_type_curated</th>\n",
       "      <th>activities</th>\n",
       "      <th>nan_values</th>\n",
       "      <th>cpds</th>\n",
       "      <th>direction</th>\n",
       "      <th>act_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>min_</th>\n",
       "      <th>p1</th>\n",
       "      <th>p25</th>\n",
       "      <th>p50</th>\n",
       "      <th>p75</th>\n",
       "      <th>p99</th>\n",
       "      <th>max_</th>\n",
       "      <th>pos_ql</th>\n",
       "      <th>ratio_ql</th>\n",
       "      <th>cpds_ql</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL4649948</td>\n",
       "      <td>PERCENTEFFECT</td>\n",
       "      <td>%</td>\n",
       "      <td>UNCHECKED</td>\n",
       "      <td>ORGANISM</td>\n",
       "      <td>93555</td>\n",
       "      <td>0</td>\n",
       "      <td>86589</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1122.89</td>\n",
       "      <td>-39.791</td>\n",
       "      <td>-10.3</td>\n",
       "      <td>-1.066</td>\n",
       "      <td>7.879</td>\n",
       "      <td>58.95</td>\n",
       "      <td>120.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL4649948</td>\n",
       "      <td>PERCENTEFFECT</td>\n",
       "      <td>%</td>\n",
       "      <td>UNCHECKED</td>\n",
       "      <td>ORGANISM</td>\n",
       "      <td>93555</td>\n",
       "      <td>0</td>\n",
       "      <td>86589</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1122.89</td>\n",
       "      <td>-39.791</td>\n",
       "      <td>-10.3</td>\n",
       "      <td>-1.066</td>\n",
       "      <td>7.879</td>\n",
       "      <td>58.95</td>\n",
       "      <td>120.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL4649948</td>\n",
       "      <td>PERCENTEFFECT</td>\n",
       "      <td>%</td>\n",
       "      <td>UNCHECKED</td>\n",
       "      <td>ORGANISM</td>\n",
       "      <td>93555</td>\n",
       "      <td>0</td>\n",
       "      <td>86589</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1122.89</td>\n",
       "      <td>-39.791</td>\n",
       "      <td>-10.3</td>\n",
       "      <td>-1.066</td>\n",
       "      <td>7.879</td>\n",
       "      <td>58.95</td>\n",
       "      <td>120.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        assay_id  activity_type unit target_type target_type_curated  \\\n",
       "0  CHEMBL4649948  PERCENTEFFECT    %   UNCHECKED            ORGANISM   \n",
       "1  CHEMBL4649948  PERCENTEFFECT    %   UNCHECKED            ORGANISM   \n",
       "2  CHEMBL4649948  PERCENTEFFECT    %   UNCHECKED            ORGANISM   \n",
       "\n",
       "   activities  nan_values   cpds  direction  act_flag  ...     min_      p1  \\\n",
       "0       93555           0  86589        1.0         0  ... -1122.89 -39.791   \n",
       "1       93555           0  86589        1.0         0  ... -1122.89 -39.791   \n",
       "2       93555           0  86589        1.0         0  ... -1122.89 -39.791   \n",
       "\n",
       "    p25    p50    p75    p99    max_  pos_ql  ratio_ql  cpds_ql  \n",
       "0 -10.3 -1.066  7.879  58.95  120.27     NaN       NaN      NaN  \n",
       "1 -10.3 -1.066  7.879  58.95  120.27     NaN       NaN      NaN  \n",
       "2 -10.3 -1.066  7.879  58.95  120.27     NaN       NaN      NaN  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_RANGES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
